%=========================================================================

\chapter{Úvod} % #####################################################################################

Žijeme v době, kdy se internet stal nedílnou součástí každodenního života a s internetem už nepracují
pouze klasické počítače, ale do popředí se také dostávají mobilní zařízení, které meziročně
zaznamenávají více než $50\%$ nárůst. Dalším druhem zařízení, jež se začínají připojovat,
jsou vestavěné systémy patřící do trendu nazývaného internet věcí.
Rychlostí s jakou přibývají nový uživatelé internetu a zařízení vyžadující přístup k počítačovým sítím
se neustále zvyšují požadavky na rychlost, se kterou data prochází počítačovými
sítěmi a z toho vyplývající požadavky na rychlost zpracování síťového provozu.
Největší požadavky jsou kladeny na zařízení starajících se o řízení internetového provozu na páteřních linkách.
Mezi tyto zařízení lze zařadit směrovače, které řídí datové toky mezi jednotlivými sítěmi,
přepínače starající se o řízení toků dat uvnitř autonomních sítí a
systémy pro detekci (IDS\footnote{Intrusion detection system}) a prevenci (IPS\footnote{Intrusion prevention system})
síťových útoků, které analyzují obsah každého paketu procházejícího sítí.

Páteřní spoje v době psaní této práce dosahují rychlostí v řádech desítek gigabitů
za sekundu a z toho vyplývají požadavky na rychlost zpracování síťových dat. Nicméně je důležité, aby stejné rychlosti zpracování dosahovaly všechna zařízení na páteřních spojích,
protože počítačová sít je pouze tak rychlá, jak rychlá je její nejpomalejší část, tzv. úzké hrdlo.

Z těchto vlastností vycházejí požadavky na stále efektivnější algoritmy zpracovávající časově kritické operace.
Časově kritické operace jsou takové operace, jež při zpracování síťového provozu trvají nejdelší dobu, a rozbor
takovýchto operací je součástí této práce. Z těchto operací jsou vybrány a rozvedeny operace
hledání řetězců a regulárních výrazů, analýza a extrakce hlaviček paketů a klasifikace paketů, speciálně pak jednodimenzionální klasifikace dle cílové IP adresy, hledání nejdelšího shodného prefixu.

Přínosem této práce je implementace algoritmů provádějících zmíněné časově kritické operace v podobě knihovny,
která bude využita výzkumnou skupinou ANT na Fakultě Informačních technologií Vysokého učení technického v Brně
pro vytváření bezpečnostních systémů a aplikací.

V kapitole \ref{chapter:theoretical} jsou popsány síťové modely a vrstvy těchto modelů,
nad nimiž jsou operace této knihovny implementovány, dále jsou popsány časově kritické operace prováděné
prvky v počítačových sítích. Kapitola \ref{chapter:api} popisuje návrh veřejného rozhraní vytvořené knihovny
pro operace zmíněné v kapitole \ref{chapter:theoretical}, způsoby použití této knihovny a možnosti rozšíření
o další časově kritické operace. V kapitole \ref{chapter:results} jsou vizualizovány a diskutovány
výsledky, jichž se podařilo dosáhnout při implementaci zmíněných operací a to na dvou hlavních platformách, Intel a ARM.
Kapitola \ref{chapter:conclusion} shrnuje dosažené výsledky a nastiňuje další možný vývoj této knihovny.

\chapter{Teoretický rozbor}\label{chapter:theoretical} % ###########################################################

Tato kapitola poskytuje teoretické informace, jež tvoří základ této práce.
V první části je popsán síťový model ISO/OSI a jeho vrstvy důležité z pohledu této práce.
V druhé části jsou pak podrobněji rozebrány jednotlivé časově kritické operace a největší důraz je
kladen na jednodimenzionální klasifikaci paketů, vyhledání nejdelšího shodného prefixu.


\section{Síťové modely}\label{section:models} % #######################################################################
Zpracování dat síťového provozu je rozděleno do několika úrovní. Tyto úrovně jsou popsány síťovými modely.
Základním modelem je ISO/OSI, který slouží pro abstraktní rozdělení operací zpracování síťových dat a využití
našel pouze v akademické sféře. V reálných počítačových sítích pak dominuje model TCP/IP, který má oproti
ISO/OSI modelu menší počet vrstev. Model ISO/OSI je rozdělen na sedm vrstev. V pořadí od nejnižší úrovně to
jsou vrstvy fyzická, linková, síťová, transportní, relační, prezentační a aplikační. Pro tuto práci jsou
podstatné pouze první čtyři vrstvy. Ty jsou detailněji popsány v následující části. Na obrázku \ref{fig:layers} je
znázorněn průchod jednoho datového paketu odeslaného ze stanice A na cílovou stanici B jednotlivými vrstvami modelu ISO/OSI. Jak je z obrázku patrné, tak různé druhy síťových zařízení pracují s různými vrstvami.

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=.25]{fig/layers.pdf}
	\caption{Znázornění průchodu dat počítačovou sítí v modelu ISO/OSI}
    \label{fig:layers}
\end{figure}

\begin{description}
\item[Fyzická vrstva]\label{layers:physical} % ##################################
je nejnižší vrstva ISO/OSI modelu a pracuje s daty na úrovni bitů. Stará se o
jejich přenos po přenosovém médiu. Protokoly této vrstvy definují signály reprezentující data,
a tudíž jde o protokoly implementované již v hardware síťových zařízení.

\item[Linková vrstva]\label{layers:link} % ###################################################################
je druhá nejnižší ISO/OSI modelu. Tato vrstva se stará o datovou komunikaci
obecně mezi několika uzly, které jsou přímo spojeny. Spojení může být jak fyzickým vodičem, tak i
bezdrátovou technologií. Nejrozšířenější technologií pro fyzické spoje je Ethernet IEEE 802.3 a pro bezdrátové spoje
je to standard IEEE 802.11. Datová jednotka na linkové vrstvě se nazývá rámec a nese v sobě kromě
zapouzdřených dat vyšších vrstev také informace o kontrolním součtu dat a adresování pomocí MAC adres.
MAC adresa je adresa fyzického zařízení, které pracuje na této vrstvě.
Adresování MAC adresou slouží pro identifikaci zařízení, které se nacházejí ve stejné počítačové síti,
a za hranici této sítě se již používá IP adresace, která je vysvětlena v následujícím odstavci.
Síťová zařízení pracující na této vrstvě se nazývají přepínače (angl. \textit{switch}).
Úkolem přepínačů je odeslat vstupní data portem, který vede k cílovému zařízení.

\item[Síťová vrstva]\label{layers:network} % ###############################################################
se stará o adresaci zařízení připojených do internetu pomocí síťových adres a o směrování paketů.
Nejrozšířenějším protokolem této vrstvy je protokol IP, jež existuje ve dvou verzích a to IPv4 a IPv6.
Síťová vrstva umožňuje komunikovat zařízením, které nejsou spojeny přímo, ale existuje mezi nimi jedna nebo více cest
napříč různými počítačovými sítěmi.
Prvky pracující na této vrstvě jsou nazývány směrovače (angl. \textit{router}) a pracují s datovou strukturou zvanou
datagramy, jež obsahují právě IP adresy jednoznačně určující zdrojové a cílové zařízení. Směrování paketů
je věnována kapitola \ref{section:lpm}.

\item[Transportní vrstva]\label{layers:transport} % #########################################################
umožňuje adresovat aplikace zodpovědné za přenášená data. Datová struktura této vrstvy
je nazývána segment. Mezi dominující protokoly patří TCP a UDP. Hlavním rozdílem mezi těmito protokoly
je zaručení spolehlivého doručení a vytváření trvanlivých spojení, které poskytuje pouze TCP.
UDP naopak spolehlivé doručení negarantuje, ale díky tomu je tento protokol jednodušší.
Situace, ve kterých pozitiva jako
nižší režie přebijí zápory, je hlavně přenos dat v reálném čase. To je například streamování videa,
přenos hlasu technologie VoIP nebo přenos informací do online her.
Zpracování dat na úrovni transportní vrstvy a všech vyšších vrstev není implementováno na síťových
zařízeních starajících se přenos dat po síti.

\end{description}

\section{Časově kritické operace} % ############################################################################
Pod pojmem časově kritické operace se rozumí takové operace, které zabírají nejvíce výpočetního
času při zpracování jednoho paketu a typicky je nutné provádět je na více síťových zařízeních.
Těmito zařízeními mohou být směrovače, přepínače, firewally a také systémy
oddělené od řízení síťového provozu jako například sondy monitorující síťový provoz nebo analyzátory,
které mohou hledat signatury útoků v datových tocích.

Mezi časově kritické operace rozebrané v této práci patří klasifikace paketů a velký důraz je kladen na
jednodimenzionální klasifikaci dle cílové IP adresy, vyhledávání nejdelšího shodného prefixu.
Tato operace je využívána pro prohledávání směrovací tabulky směrovačů pro určení nejvhodnější cesty, kterou
bude paket pokračovat při své cestě k cílovému zařízení.
Další z operací je analýza a extrakce hlaviček paketů, která je využívána v již zmíněné klasifikaci paketů,
kde je nutné z hlavičky paketu extrahovat všechny informace, dle kterých bude paket klasifikován.
Dalšími z rozebíraných operací je hledání řetězců a hledání regulárních výrazů.
Poslední dvě zmíněné operace slouží především pro detekci útoků v systémech IDS (z angl. \textit{intrusion detection system})
a pro prevenci útoků v systémech IPS (z angl. \textit{intrusion prevention system}). Jedná se o operace sloužící
pro hloubkové prohledávání paketů (angl. \textit{Deep Packet Inspection}). Toto prohledávání na rozdíl od ostatních operací
pracuje s datovým obsahem paketů a ne jenom s hlavičkami paketu. Z toho vychází časová náročnost,
neboť místo vyhodnocení hlavičky paketu, jež čítá 19 bytů pro IPv4 a 40 bytů pro IPv6 je nutno
projít veškerá data, jejichž velikost se typicky pohybuje v rozmezí $1 - 1500B$.

Informace zde použité vycházejí z publikací \cite{bspl}, \cite{tbm}, \cite{aho}, \cite{gigabit-networking}, \cite{phe-design} a \cite{meduna}.

\subsection{Klasifikace paketů}

Klasifikace paketů je operace rozhodující o dalším zpracování paketu.
Výsledkem klasifikace pak může být rozhodnutí, zda daný paket může projít do
dalšího vyhodnocování nebo zda pochází nebo směřuje do sítě, která není dovolena.
Této klasifikace se využívá například pro povolení pouze určitého rozsahu zdrojových IP adres
pro omezení přístupu do podnikové sítě nebo pro blokování paketů snažících se přistupovat
ke službám, které jsou povoleny pouze pro specifická zařízení.

Data využívané pro klasifikaci se skládají z položek hlavičky paketu, pravidla a priority.
Nejčastěji využívanou klasifikací je klasifikace skládající se z pětice položek IP hlavičky
a to zdrojové adresy, cílové adresy, zdrojového portu, cílového portu a protokolu transportní vrstvy.
Obsahem klasifikačních pravidel pak mohou být přesně specifikované hodnoty, rozsahy nebo prefixy.
Prefixy jsou obecnějším zápisem specifických hodnot i rozsahů, neboť rozsah lze přepsat v nejhorším
případě na $2N - 2$ prefixů \cite{clasification-prefix}, kde $N$ odpovídá počtu bitů reprezentující rozsah. V případě specifické hodnoty je to prefix pouze jeden o bitové délce stejné jako reprezentovaná hodnota.

Klasifikace je prováděna jako vyhledání každé definované položky v množině reprezentující hodnoty
této položky definované v klasifikátoru a poté výběr pravidla s nejvyšší prioritou z kartézského součinu množin
obsahující vyhovující hodnoty jednotlivých položek.

Tato práce se zabývá pouze jednodimenzionální klasifikací paketů, jež je založena na klasifikaci dle cílové IP
adresy, hledání nejdelšího shodného prefixu, operace sloužící pro prohledávání směrovacích tabulek směrovačů.

\subsection{Hledání nejdelšího shodného prefixu}\label{section:lpm} % #######################################
Problém hledání nejdelšího shodného prefixu se rozumí jednodimenzionální klasifikace paketů dle
jejich cílové IP adresy, která může být jak verze 4, tak verze 6.
Hledání nejdelšího shodného prefixu je operace, která je prováděna
na síťových prvcích zvaných směrovače. Tyto prvky jsou umístěny na každém rozhraní dvou a více
počítačových sítí. Cílem směrovačů je nalézt nejvhodnější cestu, kterou bude směrován příchozí paket.
Struktura reprezentující uložené směrovací informace se nazývá směrovací tabulka.
Tato tabulka ukládá informace o dostupných sítích (jejich prefixech), délce těchto prefixů a rozhraní,
kterým se lze do odpovídající sítě dostat. Příklad směrovací tabulky je zobrazen v tabulce \ref{tab:routing-table}

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|}
    \hline
    Prefix        & Délka prefixu & Rozhraní \\ \hhline{|=|=|=|}
    147.228.0.0   & 14            & eth0       \\ \hline
    147.228.128.0 & 17            & eth0       \\ \hline
    \end{tabular}
    \caption{Příklad směrovací tabulky}
    \label{tab:routing-table}
\end{table}

S velkým rozmachem počítačových sítí v poslední dekádě dochází k velkému nárůstu směrovacích informací a z toho vycházející nárůst velikosti směrovacích tabulek. Jako jedno z řešení pro zmenšení směrovacích tabulek byl navržen takzvaný supernetting, který agreguje směrovací záznamy
sdílející stejné rozhraní a mající společnou část prefixu do jednoho záznamu.
Pokud vezmeme v úvahu výše uvedenou tabulku, tak při použití supernettingu by byly oba záznamy sloučeny
v jeden, který by vypadal takto: $147.228.0.0/14~eth0$.
Tím je dosaženo zmenšení směrovacích tabulek, nicméně i s využitím supernettingu zůstává hledání nejdelšího shodného
prefixu časově kritickou operací.

Prefix ve směrovací tabulce je interně reprezentován jako posloupnost nul a jedniček (binární vyjádření jeho hodnoty) s hvězdičkou na konci, která značí, že všechny adresy, jejichž začátek je shodný s částí před hvězdičkou, odpovídají tomuto prefixu.
Jako příklad mějme prefix $A = 1001*$ jež odpovídá adresám začínajícím $1001$, tedy $10010*$ i $10011*$.
Nicméně ve směrovací tabulce může být uložen i prefix B $10010*$, který sdílí první čtyři bity své adresy
s výše uvedeným prefixem $A$ a v případě, že je zpracovávána adresa začínající hodnotou $10010$ je z pohledu směrování
nutno vyhodnotit prefix B jako nejdelší shodný a poté paket správně směrovat. V případě $10011$ je však nejdelším
shodným prefixem pravidlo A a tudíž nesmí dojít k vyhodnocení prefixu B jako nejdelšího.
Z toho důvodu je nutné ve směrovací tabulce uchovávat i informace o délce prefixu.
Tato informace slouží pro rozhodnutí, jaké pravidlo směrovací tabulky odpovídá nejdelšímu shodnému prefixu.
Délka prefixu může nabývat hodnot $1-32$ pro adresy typu
IPv4 a $1-128$ pro adresy typu IPv6.
Z výše uvedených informací a příkladů vyplývá,
že je nutné rozlišovat, zda existující prefix reprezentuje adresu verze IPv4 nebo IPv6,
jinak by mohlo docházet k vyhodnocení nejdelšího shodného prefixu pro adresu IPv4
jako prefix verze IPv6, což by mělo za následek nevalidní směrování paketů.
Jako příklad může sloužit následující směrovací tabulka, ve které je první pravidlo
verze IPv4 a druhé IPv6. Při vyhledání nejdelšího shodného prefixu v této tabulce by nebylo možné určit jaké pravidlo je to správné.
Pro rozlišení o jaký druh prefixu se jedná je možno použít dva přístupy, rozlišení na úrovni
záznamů směrovacích tabulek nebo rozlišením na úrovni směrovacích tabulek. V této práci je zvoleno rozlišení
na úrovní směrovacích tabulek.

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|l|}
    \hline
    Prefix & Délka prefixu & Rozhraní \\ \hhline{|=|=|=|=|}
    $100*$ & 3 & eth0 \\ \hline
    $100*$ & 3 & eth3 \\ \hline
    \end{tabular}
    \caption{Příklad směrovací tabulky}
\end{table}

Pro hledání nejdelšího shodného prefixu existuje velké množství algoritmů, které jsou popsány v \cite{tbm}.
Většina z nich je založena na procházení stromové struktury. Každý algoritmus má jiné paměťové nároky
a dosahuje jiných rychlostí. Z toho důvodu je při výběru vhodného algoritmu nutné
volit kompromis mezi rychlostí a paměťovou náročností.
V případě, že jde o implementaci na architektuře FPGA, bude důraz pravděpodobně kladen na paměťovou náročnost
a to z důvodu, že tyto čipy mají omezenou kapacitu paměti. Na architekturách vycházejících z x86 je naopak kladen důraz
na rychlost zpracování z důvodu obecných procesorů, které nejsou specializovány na zpracování těchto operací
a dosahují tak delší doby zpracování.

První algoritmus hledání nejdelšího shodného prefixu byl založen na naivním procházení lineárního
seznamu. Doba vyhledávání pomocí tohoto algoritmu byla závislá na počtu uložených prefixů a její
časová složitost byla $O(N)$, což při dnešních rychlostech spojů umožňuje procházet směrovací tabulku
obsahující pouze malý počet záznamů.

Algoritmy rozebrané v této kapitole vycházejí z obecně vícebitového stromu,
jež je rozšířením binárního stromu na více než dva potomky.
Hodnota klíče uzlu v obecném vícebitovém stromu není přímo zanesena do uzlu jako jedna z jeho položek,
ale odpovídá cestě stromem od kořene k aktuálnímu uzlu.
Těmito algoritmy je binární vyhledávání na délce prefixu a TreeBitmap.
Binární vyhledávání na délce prefixu používá binární strom pro interní reprezentaci směrovacích
informací a pro vyhledávání využívá struktury hašovací tabulky, ve které jsou uloženy všechny existující uzly
binárního stromu.
TreeBitmap je algoritmus založený na vícebitovém stromu a vyznačuje se tím,
že pro uložení prefixu využívá zakódované bitmapy a každý uzel stromu může uchovávat informace pro větší počet bitů prefixu, díky čemuž dosahuje menších paměťových nároků.
Dosažené výsledky pro různý počet bitů jsou vizualizovány v kapitole \ref{section:results-lpm}.


\subsubsection{TreeBitmap} % #####################################################################################

Algoritmus TreeBitmap je založen na datové struktuře vícebitového stromu, v němž jsou uloženy směrovací informace.
Hlavní myšlenkou tohoto algoritmu je uložení potomků uzlu a směrovacích pravidel na jednom paměťovém místě, což znamená, že stačí uchovávat pouze jednu
adresu reprezentující paměťové místo, kde se uzly nacházejí, a index pro určení jaký uzel se má vybrat. Právě
hodnota indexů je zakódovaná do bitmap.
Výhodou tohoto zakódování informací je zmenšení paměťových nároků pro uložení každého uzlu stromové struktury.
Další specifickou vlastností algoritmu TreeBitmap je zpracování několika bitů adresy v jednom kroku.
Počet zpracovaných bitů je nazýván střída a právě velikost střídy určuje počet bitů prefixu zakódovaných do jednoho uzlu stromu.

Každý uzel stromové struktury obsahuje dvě bitmapy, interní a externí, které slouží pro zakódování indexů.
Interní bitmapa slouží pro zakódování informací, jaké prefixy a jim odpovídající pravidla se nacházejí v aktuálním uzlu.
Externí bitmapa pak uchovává informace o existujících cestách do dalších úrovní stromové struktury.
Příklad zakódovaných bitmap pro střídu 2 je zobrazen v tabulce \ref{tab:tbm-bitmaps}.
Další položkou uzlu je ukazatel na paměťové místo, kde jsou uloženy potomci uzlu, a ukazatel na pole obsahující směrovací pravidla, jež odpovídají adresám reprezentovaných tímto uzlem.

\begin{table}
	\center
    \begin{tabular}{|l||c|c|c|c|c|c|c|}
    \hline
    Prefix & $*$ & $0*$ & $1*$ & $00*$ & $01*$ & $10*$ & $11*$ \\ \hhline{|=#=|=|=|=|=|=|=|}
    Interní bitmapa & 0 & 1 & 0 & 0 & 0 & 1 & 1 \\ \hline
    \multicolumn{4}{|l|}{Externí bitmapa} & 1 & 0 & 1 & 0 \\ \hline
    \end{tabular}
    \caption{Příklad bitmap algoritmu TreeBitmap}
    \label{tab:tbm-bitmaps}
\end{table}

Algoritmus vyhledávání spočívá v procházení stromu od kořenu a zjišťování, zda
existuje prefix odpovídající zpracované části adresy. Částí adresy se rozumí N bitů, jež jsou brány postupně
od nejvýznamnějších bitů hledané adresy až po nejméně významné.
Jako první operace hledání nejdelšího shodného prefixu se extrahují bity adresy na pozici odpovídající
aktuální hloubce zanoření ve stromu a provede se operace zjištění, zda je pro část této adresy uloženo
směrovací pravidlo. To je zjištěno z interní bitmapy na pozici, jež odpovídá délce a hodnotě extrahovaných bitů.
Pozice v interní bitmapě je vypočítána jako $2^{N} - 1 + x$, kde $N$ reprezentuje počet bitů (velikost střídy v první iteraci nad daným uzlem) a $x$
je dekadickou reprezentací extrahovaných bitů.
Pokud je na této pozici
hodnota "1", je uloženo pravidlo na indexu spočítatelným jako \texttt{ones(bitmap, position)} v poli pravidel.
Toto pravidlo pak reprezentuje dočasný nejlepší výsledek. Pokud je na vypočítané
pozici v interní bitmapě hodnota "0"~je opakován výpočet pozice s hodnotou $N$ sníženou o jedna a bitovou hodnotou
oříznutou o nejméně významný bit. Tato operace se opakuje tak dlouho, dokud není nalezena pozice
s hodnotou "1"
nebo dokud není $N$ nulové. Jako druhá operace je provedeno hledání následovníků ve stromové struktuře
reprezentující specifičtější prefixy. To je provedeno jako zjištění přítomnosti hodnoty "1" v externí
bitmapě na pozici, jejíž hodnota je dekadickou reprezentací extrahovaných bitů. V případě přítomnosti
"1" na této pozici je proveden přechod do další úrovně stromové struktury a celý postup se opakuje.
Pokud je na této pozici hodnota "0" je vyhledávání ukončeno a jako výsledek je navrácena hodnota
dočasného nejlepšího výsledku, která odpovídá pravidlu, jež patří k nejdelšímu shodnému nalezenému
prefixu. Celý algoritmus je popsán pseudokódem v algoritmu \ref{alg:treebitmap}.

Pro výpočet indexu do polí obsahující pravidla a následovníky se používá funkce
\texttt{ones(bitmap, position)}, jež
spočítá počet bitů s hodnotou "1" v dané bitmapě a to od pozice 0 do pozice \texttt{position}.

Jeden uzel stromu TreeBitmap je vizualizován na obrázku \ref{fig:tbm-node} a jeho bitmapy odpovídají tabulce
\ref{tab:tbm-bitmaps}. Uzly zbarvené černě
jsou uzly, pro které je definováno směrovací pravidlo.

\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=.55]{fig/tbm.pdf}
    \caption{Jeden uzel algoritmu TreeBitmap}
    \label{fig:tbm-node}
\end{figure}

\begin{algorithm}[H]
    \SetAlgorithmName{Algoritmus}{}{}
	node $\leftarrow$ tbm-root\;
	longest-match-node $\leftarrow$ tbm-root\;
	longest-match-index $\leftarrow$ 0\;
	position $\leftarrow$ 0\;
	\Repeat{BIT(parent.external, bits)}
	{
		bits $\leftarrow$ get-stride-bits(ip, position)\;
		position $\leftarrow$ position + STRIDE\;


		\If{internal-index(node.internal, bits)}
		{
			longest-match-node = node\;
			longest-match-index = internal-index(node.internal, bits)\;
		}

		index $\leftarrow$ ones(node.external, bits)\;
		parent $\leftarrow$ node\;
		node $\leftarrow$ node.external[index]\;
	}
	\Return longest-match-node.rule[logest-match-index]\;
	\caption{Hledání nejdelšího shodného prefixu algoritmem TreeBitmap}
    \label{alg:treebitmap}
\end{algorithm}

\subsubsection{Binární vyhledávání na délce prefixu} % ###########################################################

Algoritmus binárního vyhledávání na délce prefixu vychází z binárního stromu, přidává
operaci propagování listů (angl. \textit{leaf-pushing}) a zavádí efektivnější prohledávání založené na hašovací
tabulce.
Struktura uzlu je rozšířena o položky prefix, délka prefixu a typ uzlu.
Typy uzlu jsou dva a to interní uzel mající právě dva potomky a uzel reprezentující pravidlo, který nemá žádné potomky.
Mimo binárního stromu používá tento algoritmus i hašovací tabulku, do které jsou zaneseny všechny uzly
stromu a jako hodnota pro hašovací funkci je použita hodnota prefixu v daném uzlu. Tato struktura
je poté využívána pro hledání nejdelšího shodného prefixu.


Operace propagace listů je operace zaručující, že existují právě dva následovníci uzlu (typ internal) nebo neexistuje žádný (typ prefix).
Pokud dojde ke stavu, že existuje právě jeden následovník uzlu, je operací propagování uzlů
vytvořen i druhý uzel a je do něj zaneseno pravidlo, jež obsahuje nadřazený uzel.
Ukázku stromu před operací propagace listů je možno vidět na obrázku \ref{bspl-not-pushed}
a po provedení této operace na obrázku \ref{bspl-pushed}.

\begin{figure}[!htbp]
    \begin{floatrow}
        \ffigbox{
        \includegraphics[scale = 0.5]{fig/bspl-not-pushed.pdf}}
            {\caption{Strom před leaf-pushingem}\label{bspl-not-pushed}}
        \ffigbox{\includegraphics[scale = 0.5]{fig/bspl-pushed.pdf}}
            {\caption{Strom po provedení leaf-pushingu}\label{bspl-pushed}}
    \end{floatrow}
\end{figure}


Vyhledávání nejdelšího shodného prefixu v hašovací tabulce se skládá z následujících kroků.
Jako první je provedeno hledání celé IP adresy, tedy všech 32 bitů v případě IPv4 nebo 128 bitů pro IPv6.
Pokud je vyhledání úspěšné a nalezený prvek je typu prefix, pak je pravidlo tohoto uzlu navráceno
jako nejdelší shodný prefix. V případě, kdy nalezený prvek je typu internal nebo není nalezen žádný prvek, dojde ke změně délky prefixu o hodnotu $2^{N - krok}$, kde $N = 5$ pro IPv4 a $N = 7$ pro IPv6.
V případě nalezení uzlu typu internal je délka adresy zvýšena o tuto hodnotu.
Pokud není nalezen žádný prvek tak je délka adresy snížena o tuto hodnotu.
Tento postup se opakuje, dokud není nalezen prvek typu prefix nebo je hodnota změny prefixu rovna nule.
Postup hledání je zapsán pseudokódem v algoritmu \ref{alg:bspl}.
Příklad vyhledávání konkrétního prefixu ve směrovací tabulce \ref{tab:bspl-table-example} je popsán v tabulce \ref{tab:bspl-example}.

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|}
    \hline
    Prefix        & Délka prefixu & Pravidlo \\ \hhline{|=|=|=|}
    147.228.0.0   & 14            & P1       \\ \hline
    147.228.128.0 & 17            & P2       \\ \hline
    \end{tabular}
    \caption{Příklad směrovací tabulky}
    \label{tab:bspl-table-example}
\end{table}

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|r|l|r|l|}
    \hline
    Prefix & Délka & Uzel & Změna délky & Výsledek \\ \hhline{|=|=|=|=|=|}
    147.228.128.54 & 32 & Nenalezen & -16 &  \\ \hline
    147.228.0.0 & 16 & Interní & +8 &  \\ \hline
    147.228.128.0 & 24 & Nenalezen & -4 &  \\ \hline
    147.228.128.0 & 20 & Nenalezen & -2 &  \\ \hline
    147.228.128.0 & 18 & Nenalezen & -1 &  \\ \hline
    147.228.128.0 & 17 & Prefix & 0 & P2 \\ \hline
    \end{tabular}
    \caption{Příklad vyhledání nejdelšího shodného prefixu}
    \label{tab:bspl-example}
\end{table}

Operace vyhledání nejdelšího prefixu při využití binárního vyhledávání na délce prefixu má časovou
složitost při ideální hašovací funkci $\log_2{N}$, kde $N$ je počet bitů adresy. Z principu algoritmu vyplývá, že nejhorší výsledky z časového hlediska bude dosahovat
při shodě s prefixem, jehož délka je liché číslo. V takovém případě bude nutné projít všemi iteracemi vyhledávání.
Počet kroků v případě IPv4 bude 5 a v případě IPv6 adresy to pak bude 7.
Zde je vidět že i v případě čtyřikrát delší adresy se počet kroků pro vyhledání prefixu zvedne pouze o dva,
což neplatí pro algoritmus TreeBitmap, který musí projít v nejhorším případě až čtyřikrát více
uzlů aby nalezl odpovídající prefix.

\begin{algorithm}
    \SetAlgorithmName{Algoritmus}{}{}
	prefix-length $\leftarrow$ ip-length\;
	prefix-change $\leftarrow$ ip-length\;
	\Repeat{prefix-change $>$ 0}
	{
		bits $\leftarrow$ get-prefix-bits(ip, prefix-length)\;
		item $\leftarrow$ hash-table.get(bits)\;
		prefix-change $\leftarrow$ prefix-change $\gg$ 1\;

		\lIf{item == NULL}{prefix-length $\leftarrow$ prefix-length - prefix-change}
		\lElseIf{item.type == PREFIX}{prefix-length $\leftarrow$ prefix-length + prefix-change}
		\lElse{break}
	}
	\lIf{item == NULL}{\Return bspl-root.default-rule}
    \Return{item.rule}
    \caption{Hledání nejdelšího shodného prefixu s využitím binárního vyhledávání na délce prefixu}
    \label{alg:bspl}
\end{algorithm}

\subsection{Hledání řetězců} % ###################################################################

Jednou z častých operací při zpracování síťového provozu je hledání řetězců, jež je využíváno pro detekci
signatur útoků na počítačové sítě, detekci malware a blokování dat obsahujících zakázaná klíčová slova.
Hledání řetězců je ověřování, zda se jedno a více definovaných klíčových slov vyskytuje ve vstupních
datech. V případě počítačových sítí se vstupními daty rozumí datových obsah paketů.

Pokud se oprostíme od počítačových sítí, tak dalším využitím hledání řetězců může být
vyhledávání klíčových slov v textových dokumentech, což bylo podnětem pro vznik
algoritmu autorů Aho a Corasickové, kteří tímto způsobem zrychlili prohledávání
textových dokumentů až $5\times$. Alternativou k algoritmu Aho-Corasick může být považován
algoritmus autorů Rabin–Karp \cite{rabin-karp}, který má ovšem průměrnou časovou složitost $O(m+n)$,
zatímco pro Aho-Corasick je tato složitost nejhorší možná. Algoritmem vycházejícím z Aho-Corasick
a Boyer–Moore \cite{boyer-moore}
je Commentz-Walter \cite{walter}, jehož časová složitost však v nejhorším případě dosahuje $O(m*n)$.
Algoritmem na nějž se soustředí část této práce je právě Aho-Corasick.
Tento algoritmus používá pro nalezení výskytu klíčového slova konceptu konečného automatu.

Konstrukce konečného automatu reprezentujícího klíčová slova je prováděna postupně a to tím způsobem,
že je v automatu hledán již existující prefix vkládaného klíčového slova. Od výsledku tohoto hledání
se pak vychází v dalších krocích, jež jsou následující:

\begin{description}
    \item[Klíčové slovo $\leq$ Existující] ~\\
    v tomto případě je pouze vloženo další pravidlo k uzlu reprezentujícímu poslední znak vkládaného
    klíčového slova
    \item[Klíčové slovo $>$ Existující] ~\\
    v tomto případě je rozšířena již existující cesta a do posledního
    uzlu této cesty je přiřazeno odpovídající pravidlo.
\end{description}

Po dokončení operace přidávání klíčových slov je provedeno generování tzv. \textit{failure} přechodů.
\textit{Failure} přechod je mapováním přechodu, který je proveden v případě, že pro vstupní symbol neexistuje
přechod z aktuálního stavu. \textit{Failure} přechod pak reprezentuje prefix klíčových slov,
které jsou podřetězcem aktuálně procházeného klíčového slova.
Generování \textit{failure} cesty je definováno iterativně a to následujícím způsobem:
Pro počáteční uzel je \textit{failure} cesta definována jako přechod do sebe sama.
Pro každý uzel v úrovni 1 je \textit{failure} cesta definována jako přechod do počátečního stavu.
Pro každou další úroveň je možné \textit{failure} přechod zjistit z validních přechodů stavů v nižších úrovních.

Příkladem procházení automatu a hledání klíčových slov může sloužit následující příklad reprezentovaný tabulkami
\ref{tab:pm-keywords} a \ref{tab:pm-match} při vstupních datech \texttt{ship}.

\begin{table}[!htbp]
    \center
    \begin{tabular}{|l|l|}
    \hline
    Klíčové slovo & Pravidlo \\ \hhline{|=|=|}
    she & 1  \\ \hline
    hi & 2 \\ \hline
    \end{tabular}
    \caption{Klíčová slova}
    \label{tab:pm-keywords}
\end{table}

Automat reprezentující tyto klíčová slova je zobrazen na obrázku \ref{fig:ac}.
Plnou čarou jsou znázorněny možné přechody, přerušovanou čarou \textit{failure} přechody,
černě jsou vybarveny stavy značící klíčové slovo
a zelenou
je znázorněn průchod automatem pro vstupní data \texttt{ship}.

\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=.55]{fig/ac.pdf}
    \caption{Automat obsahující klíčová slova \texttt{she} a \texttt{hi}}
    \label{fig:ac}
\end{figure}

Symbol $[]$ reprezentuje počáteční stav a $[xyz]$ reprezentuje posloupnost stavů $x$, $y$ a $z$, jež odpovídá cestě od
počátečního stavu do aktuálního stavu.

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|}
    \hline
    Aktuální symbol & Akce automatu & Výsledek \\ \hhline{|=|=|=|}
    s & [] $\overset{s}{\rightarrow}$ [s] &  \\ \hline
    h & [s] $\overset{h}{\rightarrow}$ [sh] & \\ \hline
    i & $\nexists$ [sh] $\overset{i}{\rightarrow}$ [shi], [sh] $\overset{\epsilon}{\rightarrow}$ [h], [h] $\overset{i}{\rightarrow}$ [hi] & \texttt{hi} \\ \hline
    p & $\nexists$ [hi] $\overset{p}{\rightarrow}$ [hip], [hi] $\overset{\epsilon}{\rightarrow}$ [], [] $\overset{p}{\rightarrow}$ [] &  \\ \hline
    \end{tabular}
    \caption{Prohledávání algoritmem Aho-Corasick}
	\label{tab:pm-match}
\end{table}


Algoritmus procházení vstupních dat je popsán pseudokódem v \ref{alg:aho} a vychází z \cite{aho}.

\begin{algorithm}[!htbp]
    \SetAlgorithmName{Algoritmus}{}{}
	state = start-state\;
	\For{position $\leftarrow$ 0 \KwTo text.length}
	{
		\lWhile{(pos $\leftarrow$ goto(state, text[position])) == FAIL}{state $\leftarrow$ state.failure}
		\lIf{state.isMatch}{\Return state.keyword}
        state $\leftarrow$ state.next[pos]\;
	}
	\Return NOT-MATCH\;
	\caption{Algoritmus procházení textu a hledání podřetězců}
    \label{alg:aho}
\end{algorithm}

\subsection{Hledání regulárních výrazů}\label{sec:regex} % ############################################

Hledání regulárních výrazů je, podobně jako hledání řetězců, operace sloužící pro detekci signatur
síťových útoků a detekci škodlivého software v obsahu datových paketů v systémech IDS a IPS.
Algoritmy pro hledání regulárních výrazů v rámci této práce jsou založeny na transformaci
regulárních výrazů na konečné automaty.
V této práci jsou rozebrány deterministické a nedeterministické konečné automaty.

Než se dostaneme k popisu jednotlivých druhů konečných automatů je potřeba definovat, co jsou to regulární
výrazy a jaké operace je s nimi možno provádět.

Nechť $r$ a $s$ jsou regulární výrazy značící jazyky $L_R$ a $L_S$.
Regulární výrazy nad abecedou $\Sigma$ a jazyky které značí, jsou definovány následovně:

\begin{itemize}
    \item{$\emptyset$ je RV značící prázdnou množinu (prázdný jazyk)}
    \item{$\epsilon$ je RV značící jazyk ${\epsilon}$}
    \item{$a$, kde $a \in \Sigma$ je RV značící jazyk ${a}$}
    \item{$r\cdot s$ je RV značící jazyk $L = L_R L_S$}
    \item{$r+s$ je RV značící jazyk $L = L_S \cup L_S$}
    \item{$r*$ je RV značící jazyk $L = L_{R*}$}
\end{itemize}

Nedeterministický konečný automat se od nedeterministického konečného automatu
liší existencí $\epsilon$-přechodů. $\mathcal{E}$-přechod umožňuje přejít do dalšího stavu konečného
automatu bez nutnosti zpracovat vstupní symbol.
Tvorba deterministického konečného automatu vychází z již existujícího nedeterministického
konečného automatu a tento proces je zván determinizace. Determinizace odstraňuje $\epsilon$-přechody
pomocí operací \textit{move} a \textit{$\epsilon$-closure}.

Při průchodu deterministický konečným automatem je možné zpracovat právě jeden znak vstupu v
každé iteraci. Algoritmus projde všemi aktivními stavy a zjišťuje,
zda existuje přechod pro aktuální znak na vstupu z aktuálního stavu
a pokud existuje, tak je proveden přechod. V případě, že takový přechod neexistuje, tak je zpracovávaný stav
označen jako neaktivní a v dalším kroku již není zpracováván. V případě nedeterministického
konečného automatu jsou navíc pro každý zpracovávaný stav aktivovány všechny stavy, kterých lze dosáhnout
$\epsilon$-přechodem. Algoritmus procházení deterministickým konečným automatem je popsán pseudokódem \ref{alg:dfa}.
Procházení nedeterministického automatu je popsáno pseudokódem \ref{alg:nfa}.

\begin{algorithm}
    \SetAlgorithmName{Algoritmus}{}{}
    position $\leftarrow 0$\;
    \While{length $>$ position}
    {
        symbol $\leftarrow$ input[position]\;
        states.push(root)\;

        \While{state $\leftarrow$ states.pop()}
        {
            \lIf{state.accepting} {\Return state.rule}
            \lIf{state.key[symbol]}{states-new.push(state.next[symbol])}
        }

        swap(states, states-new)\;
        position $\leftarrow position + 1$\;
    }
    \caption{Procházení vstupních dat pro deterministický konečný automat}
    \label{alg:dfa}
\end{algorithm}

\begin{algorithm}
    \SetAlgorithmName{Algoritmus}{}{}
    position $\leftarrow 0$\;
    \While{length $>$ position}
    {
        symbol $\leftarrow$ input[position]\;
        states.push(root)\;

        \While{state $\leftarrow$ states.pop()}
        {
            \lIf{state.accepting} {\Return state.rule}
            \lFor{ i $\leftarrow$ 0 \KwTo i $<$ state.epsilon\_count}{states.push(state.epsilon[i])}
            \lIf{state.key[symbol]}{states-new.push(state.next[symbol])}

        }

        swap(states, states-new)\;
        position $\leftarrow position + 1$\;
    }
    \caption{Procházení vstupních dat pro nedeterministický konečný automat}
    \label{alg:nfa}
\end{algorithm}

\subsection{Analýza a extrakce hlaviček paketů} % ###################################################

Extrakce hlaviček paketů je operace prováděná na každém síťovém zařízení,
neboť právě na základě hodnot položek hlavičky paketu je rozhodnuto,
jak má být paket zpracován. Z toho vyplývá závislost rychlosti všech operací pracujících s položkami hlaviček na linkové, síťové a transportní vrstvě na rychlosti extrakce a analýzy hlaviček.
Vstupními daty této operace jsou hlavičky datových struktur na vrstvě linkové, síťové a transportní.
Výstupem je množina hodnot, jež byly cílem analýzy a extrakce.
Parsování probíhá sekvenčně, neboť protokol dané vrstvy je uveden v hlavičce na vrstvě o úroveň níže.
Operaci je možno rozdělit na dva kroky. Prvním krokem je lokalizace požadované hlavičky ve vstupních datech
a druhým je pak extrakce této hodnoty.
Jedním ze způsobů používaných pro lokalizace hlavičky paketů je použití orientovaných acyklických grafů zvaných parsovací grafy,
kde vrcholy reprezentují typy hlaviček a hrany reprezentují posloupnost hlaviček.
Příklad takového grafu lze najít na obrázku \ref{fig:parse-graph}.


\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=1]{fig/parse-graph.pdf}
    \caption{Parsovací graf}
    \label{fig:parse-graph}
\end{figure}

\chapter{Návrh API knihovny}\label{chapter:api} % #################################################################

Cílem návrhu API knihovny \texttt{fastnet} je vhodně zapouzdřit implementované operace a to takovým způsobem,
aby je bylo možné používat bez znalosti využívaných algoritmů. Dalším cílem návrhu je připravit API tak,
aby bylo možné rozšiřovat množinu algoritmů implementující dané operace při zachování
stejného API.
Každá z funkcí navrženého API pro jednotlivé operace umožňuje pracovat s více datovými sadami, jež reprezentující
data dané operace. To byl také jeden z požadavků při návrhu API. Kořenový prvek je
explicitně předáván do funkcí provádějící jednotlivé operace namísto jeho uložení uvnitř knihovny. Jedinou výjimkou
jsou inicializační funkce, které právě vytvářejí kořenovou strukturu.

Knihovna \texttt{fastnet} je rozdělena na několik menších knihoven, kde každá knihovna implementuje
jednu operaci používanou při zpracování síťového provozu.
Tímto návrhem je dosaženo snadné rozšiřitelnosti o další operace,
jako například extrakce informací z hlaviček paketů a klasifikaci paketů.
Další výhodou tohoto rozdělení je možnost snadno vytvořit a používat jednotlivé knihovny samostatně nebo v různých kombinacích nezahrnující všechny operace.
To se může hodit pro zařízení, která mají velmi limitované paměťové úložiště a jejich účelem
je řešit pouze část ze zmíněných operací.

Veřejné rozhraní celé knihovny se skládá z veřejných rozhraní jednotlivých knihoven.
Tyto rozhraní jsou popsány v následujících kapitolách.
Pro knihovnu je navržena struktura hlavičkových souborů pro jednotlivé knihovny.
Jako výchozí hlavičkový soubor je použit \texttt{types.h},
který obsahuje definice datových struktur pro všechny algoritmy v knihovně, které musí být
viditelné i z veřejného rozhraní. Dalším souborem je \texttt{types-precompiled.h},
který je generován z \texttt{types.h}. Toto generování se provádí před samotným překladem knihovny
a výsledek je závislí na zvoleném algoritmu.
Soubor \texttt{common.h} je hlavičkový soubor společný pro všechny algoritmy v knihovně a \texttt{<algorithm>.h}
pak obsahuje deklarace specifické pro právě jeden konkrétní algoritmus.
Soubor \texttt{<library-operation>.h} je pak hlavičkový soubor, který tvoří veřejné rozhraní ke knihovním funkcím.
Závislost jednotlivých souborů je znázorněna na obrázku \ref{fig:header-dependecies}.

\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=.25]{fig/header-dependencies.pdf}
    \caption{Diagram závislostí hlavičkových souborů}
    \label{fig:header-dependecies}
\end{figure}

Je navrženo API pro operace klasifikace paketů \ref{api:pc}, hledání nejdelšího shodného prefixu
\ref{api:lpm}, hledání řetězců \ref{api:pm}, hledání regulárních výrazů \ref{api:regex} a analýzu a
extrakci hlaviček paketů \ref{api:phe}. V kapitole \ref{api:extension} je rozebrána možnost rozšíření této knihovny o další operace a v kapitole \ref{api:usage} je popsáno jakým způsobem je možné sestavit celou knihovnu nebo její jednotlivé
části.
\section{Klasifikace paketů}\label{api:pc} % #######################################################

Pro klasifikaci paketů jsou navrženy čtyři základní funkce a jedna datová struktura.
Tato struktura je nazvána \texttt{set} a obsahuje položky \texttt{rule} pro uložení pravidla,
které odpovídá kombinaci ostatních položek, \texttt{dst} pro uložení cílové IP adresy,
\texttt{src} pro uložení zdrojové adresy, \texttt{protocol} pro uložení typu transportního protokolu,
tedy TCP nebo UDP a \texttt{port} pro uložení cílového portu.
Výběr těchto položek vychází z nejčastějšího použití právě těchto položek a také z
neexistující implementace této operace, která by vyžadovala definování zbylých položek.

Funkce pro práci se strukturou pro klasifikaci paketů jsou: \texttt{init} pro inicializaci
vyhledávacích struktur, \texttt{add} pro přidání klasifikačního pravidla, \texttt{update}
pro aktualizaci odpovídajícího pravidla, \texttt{remove} pro smazání odpovídajícího pravidla
a nakonec \texttt{destroy} pro uvolnění veškeré paměti zabírané strukturami pro provádění klasifikace
paketů.

Všechny zmíněné funkce a jedna datové struktura jsou navrženy ve dvou verzích a to pro IPv4 a IPv6.
Tyto funkce se od sebe liší pouze prefixem, kde pro IPv4 je použit prefix \texttt{pc\_} a pro
IPv6 pak \texttt{pc6\_}. Důvodem, proč jsou jednotlivé funkce a struktura rozděleny tímto
způsobem, je odlišná velikost adres a nutnost rozlišovat pro jako verzi IP protokolu se klasifikace provádí,
neboť prefixy adres se mohou shodovat pro obě verze IP.

Všechny funkce vyjma \texttt{init} očekávají jako první argument strukturu typu \texttt{root},
která obsahuje veškeré informace o klasifikačních pravidlech. Jako u ostatních operací
je tato struktura uváděna explicitně a to umožňuje vytvářet více klasifikátorů v jednom programu.

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/pc/pc.h}

\section{Vyhledání nejdelšího shodného prefixu}\label{api:lpm} %########################################

Pro operaci vyhledání nejdelšího shodného prefixu jsou připraveny funkce
\texttt{init}, \texttt{add}, \texttt{update}, \texttt{remove} a \texttt{destroy}.
Dále je navržena struktura pro uložení kořene všech datových struktur, \texttt{root}.
Všechny zmíněné funkce a datová struktura existují ve dvou verzích pro práci s jednotlivými
verzemi protokolu IP. Odlišeny jsou prefixem, který je \texttt{lpm\_} pro IPv4 a
\texttt{lpm6\_} pro IPv6.

Funkce \texttt{init} slouží pro vytvoření kořenového uzlu datových struktur a
nastavení výchozího pravidla, které je vybráno, pokud není nalezen žádný odpovídající prefix.
Návratovou hodnotou této funkce je ukazatel na kořen datové struktury, jež je parametrem
všech ostatní funkcí provádějící operace v rámci vyhledání nejdelšího shodného prefixu.
Funkce \texttt{add} slouží pro přidání prefixu a pravidla odpovídajícímu tomuto prefixu.
Funkce \texttt{update} slouží pro aktualizaci pravidla daného prefixu.
Funkce \texttt{remove} odstraňuje zvolený prefix z vyhledávací struktury.
Funkce \texttt{destroy} slouží pro uvolnění paměti alokované všemi výše zmíněnými funkcemi
a po provedení této funkce již není možné provádět další operace nad danou strukturou.

Funkce pro vložení, smazání a aktualizaci pravidel a prefixů také obsahují parametr
prefix, který je buď IPv4 nebo IPv6 adresa. Dalším parametrem těchto funkcí je délka prefixu,
aby bylo možné odlišit jednotlivé prefixy od sebe.

Funkce pro vložení prefixu pracuje pouze s jedním prefixem a je prováděna okamžitě.
Tento návrh vychází z předpokladu, že knihovna bude používána i v prostředí s dynamickými směrovacími
protokoly jako například RIP, OSPF nebo BGP, které při změně směrovacích informací v případě BGP
zasílají aktualizace s novými informacemi nebo jsou tyto změny
zasílány periodicky v případě protokolu RIP.

Hašovací funkce je v této implementaci použita Jenkins \cite{jenkins}. Volba hašovací funkce
může mít vliv na rychlost vyhledávání. To je patrné z principu hašovací tabulky, kde se
kolizní záznamy uchovávají v lineárním seznamu, a v případě stejných hodnot generovaných
hašovací funkcí pro všechny vstupní hodnoty by bylo vyhledávání omezeno na procházení
lineárního seznamu.

Použitý algoritmus lze volit při sestavení knihovny pro vyhledání nejdelšího shodného prefixu
zapsáním následujícího příkazu \texttt{make ALG=<alg>}, kde hodnota \texttt{<alg>} může nabývat
hodnot \texttt{tbm} pro volbu TreeBitmap a \texttt{bspl} pro binární vyhledávání na délce prefixu.
V případě sestavování celé knihovny je možné zapsat \texttt{make LPM=<alg>} v příslušném adresáři.
Při volbě algoritmu TreeBitmap je pak volitelný parametr \texttt{STRIDE=<N>}, jež určuje velikost
střídy. Tuto volbu je možné použít v obou příkazech.

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/lpm/lpm.h}
Specifikaci datových struktur lze nalézt v soubor \texttt{/lib/src/lpm/types.h}


\section{Hledání řetězců}\label{api:pm} % ####################################################################

Pro hledání řetězců je navrženo několik datových struktur, mezi které patří
struktura pro uložení právě jednoho stavu konečného automatu \texttt{\_ac\_state},
struktura reprezentující jeden konečný automat \texttt{pm\_root} a struktura \texttt{pm\_keyword}
pro uložení klíčového slova, jeho délky a jemu odpovídající pravidlo.


Pro hledání řetězců jsou podobně jako pro vyhledání nejdelšího shodného prefixu navrženy a implementovány
následující funkce.

\begin{itemize}
    \item{\texttt{pm\_init} pro inicializaci datových struktur}
    \item{\texttt{pm\_match} pro hledání prvního klíčové slova vyskytujícího se ve vstupních datech}
    \item{\texttt{pm\_match\_next} pro hledání dalších klíčových slov}
    \item{\texttt{pm\_add} pro vložení množiny klíčových slov}
    \item{\texttt{pm\_update} pro změnu pravidla odpovídající danému klíčovému slovu}
    \item{\texttt{pm\_remove} pro smazání klíčového slova}
    \item{\texttt{pm\_destroy} pro uvolnění veškeré paměti, jež byla alokována}
\end{itemize}

Všechny výše zmíněné funkce vyjma \texttt{pm\_init} a \texttt{pm\_match\_next} očekávají jako první parametr strukturu typu \texttt{pm\_root},
která je základním prvkem pro vyhledávání a právě do této struktury
jsou uložena všechna klíčová slova a jejich pravidla.

Hledání řetězců funkcí \texttt{pm\_match} skončí svůj průchod konečný automatem v momentě nálezu první shody
s libovolným klíčovým slovem zadaným při volání \texttt{pm\_add}.
V případě, že není nalezena žádná shoda
s definovanými klíčovými slovy v řetězci, je vrácen výsledek \texttt{false}.
Čtvrtým parametrem funkce \texttt{pm\_match} může být hodnota \texttt{NULL} nebo odkaz na datovou strukturu
\texttt{pm\_result}. V případě \texttt{NULL} argumentu již nelze procházet textem a hledat další shody.
Pokud je zadán odkaz na existující strukturu \texttt{pm\_result} je možné procházet celým textem a ukládat
všechny nalezené shody s klíčovými slovy funkcí \texttt{pm\_match\_next}.

Jednotlivé položky struktury \texttt{pm\_result} pro veřejné použití jsou

\begin{itemize}
    \item{\texttt{rule} - pole obsahující všechny nalezená klíčová slova}
    \item{\texttt{count} - počet nalezených klíčových slov}
    \item{\texttt{position} - pozice kde byl nalezen výskyt klíčového slova}
\end{itemize}

Pro práci se strukturou \texttt{pm\_result} jsou v navrženy a implementovány následující operace:

\begin{itemize}
    \item{\texttt{pm\_result\_init} pro vytvoření této struktury}
    \item{\texttt{pm\_result\_destroy} pro uvolnění paměti alokované pro tuto strukturu}
\end{itemize}


Funkce \texttt{pm\_add} očekává jako druhý parametr pole struktur \texttt{pm\_keyword}, kde každá struktura
obsahuje položky vstupního klíčové slova, délku tohoto slova a pravidlo odpovídající tomuto slovu. Důvodem pro tento návrh je časově náročná funkce generování
\textit{failure} přechodů, které umožňují detekovat kratší klíčové slovo i v případě, že již je
zahájeno porovnávání delšího slova, jak je možno vidět na následujícím příkladu. Tabulka \ref{tab:ac:substr}
obsahuje definovaná klíčová slova a obrázek \ref{fig:ac:substr} znázorňuje část odpovídající konečného automatu
pro klíčové slovo \texttt{she}, které v sobě obsahuje klíčové slovo \texttt{he}.
\begin{table}[!htbp]
    \center
    \begin{tabular}{|l|l|}
    \hline
    Klíčové slovo & Pravidlo \\ \hhline{|=|=|}
    she & 1  \\ \hline
    he & 2 \\ \hline
    \end{tabular}
    \caption{Klíčová slova}
    \label{tab:ac:substr}
\end{table}

\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=0.5]{fig/ac-substr.pdf}
    \caption{Konečný automat reprezentující \ref{tab:ac:substr}}
    \label{fig:ac:substr}
\end{figure}


Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/pm/pm.h}
Specifikaci datových struktur lze nalézt v soubor \texttt{/lib/src/pm/types.h}

\section{Hledání regulárních výrazů}\label{api:regex}  % ##########################################################

Rozhraní pro hledání regulárních výrazů navržené a implementované v knihovně \texttt{fastnet:regex}
rozšiřuje množinu operací prováděných s regulárními výrazy zmíněných v \ref{sec:regex} o následující zápisy operací:

\begin{itemize}
    \item{$[abc]$ je výčet znaků, které se na vstupu mohou vyskytnout a automat je v aktuální stavu dokáže zpracovat. Je to zkrácený tvar zápisu $(a|b|c)$}
    \item{$a+$ je definováno jako $1..N$ opakování}
    \item{$a?$ je definováno jako $0..1$ opakování}
    \item{$.$ je definována jako libovolný symbol}
\end{itemize}

Pokud se v definici regulárního výrazu vyskytuje jeden z řídících znaků regulárních výrazů
je nutno tento znak escapovat, to znamená přidat před něj zpětné lomítko.
Zpětné lomítko samotné se pak zapíše jako dvě zpětná lomítka. Operace konkatenace je uvažována implicitně.

Pro hledání regulárních výrazů jsou navrženy a implementovány dva způsoby hledání,
deterministický a nedeterministický konečný automat.
Z toho důvodu jsou odlišeny všechny funkce dle typu konečného automatu, který je použit.
Pro použití deterministického konečného automatu je to \texttt{dfa} a pro nedeterministický
je to \texttt{nfa}.

Navrženy jsou následující funkce:

\begin{itemize}
    \item{\texttt{regex\_<type>\_construct} pro vytvoření regulárního výrazu}
    \item{\texttt{regex\_<type>\_match} pro hledání regulárního výrazu ve vstupních datech}
    \item{\texttt{regex\_<type>\_destroy} a uvolnění paměti zabrané regulárním výrazem}
\end{itemize}
% REGEXDFA =================================================================================

Pro vytvoření regulárních výrazů je podobně jako u hledání řetězců
použita pomocná struktura \texttt{regex\_pattern}, která je předávána do funkce \texttt{regex\_<type>\_construct}
a jež obsahuje pole regulárních výrazů, z nichž se má vytvořit jeden regulární výraz reprezentovaný konečným automatem.
Výsledný konečný automat, ať už deterministický nebo nedeterministický, je výsledek spojení jednotlivých
konečných automatů pro každý regulární výraz. Tím je umožněna detekce několika
regulární výrazů v jednom průchodu vstupními daty i s přesnou identifikací jaký regulární
výraz byl ve vstupních datech nalezen.

Důvodem proč jsou navrženy obě možnosti pro hledání regulárních výrazů je až teoreticky exponenciální nárůst
počtu stavů deterministického konečného automatu, což může být nežádoucí a je vhodnější
zaměnit rychlost deterministického konečného automatu za menší paměťové nároky nedeterministického konečného automatu.

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD v souboru \texttt{/lib/src/regex/regex.h}
Specifikaci datových struktur lze nalézt v soubor \texttt{/lib/src/regex/types.h}

\section{Analýza a extrakce hlaviček paketů}\label{api:phe} %#####################################################

Pro tuto operaci byla navržena jedna funkce a jedna struktura.
Touto strukturou je \texttt{phe\_item} typu \texttt{union}, jehož položky
se vzájemně překrývají. Důvodem pro tento návrh je předem neznámý počet extrahovaných hodnot a jejich typů.
Navrženou funkcí je funkce \texttt{phe\_get}, jež jako první parametr očekává
vstupní data, jako druhý ukazatel na pole \texttt{phe\_item},
kam se budou ukládat jednotlivé extrahované hodnoty, a další argumenty jsou hodnoty reprezentující jednotlivé
položky hlaviček a jejich číselná hodnota odpovídá počtu bytů
od začátku datové struktury paketu.

Některé základní položky využívané při klasifikaci paketů a jejich vzdálenosti od počátku hlavičky
jsou uvedeny v tabulce \ref{tab:phe}.

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|}
    \hline
    Význam & Název & offset \\ \hhline{|=|=|=|}
    Verze & IP\_VERSION & 0 \\ \hline
    Zdrojová IP adresa pro IPv4 & IPv4\_SRC & 12 \\ \hline
    Cílová IP adresa pro IPv4 & IPv4\_DST & 16 \\ \hline
    Zdrojový port TCP & TCP\_SRC\_PORT\ & 0 \\ \hline
    Cílový port TCP & TCP\_DST\_PORT & 2 \\ \hline
    \end{tabular}
	\caption{Položky IP paketu a jejich pojmenování pro extrakci a analýzu}
    \label{tab:phe}
\end{table}

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/phe/phe.h}


\section{Rozšíření knihovny}\label{api:extension} % ############################################

Pro rozšíření knihovny je nutné přidat soubory implementující danou operaci
do adresáře \texttt{lib/src/<operation>/} a upravit soubor \texttt{Makefile} v nadřazeném adresáři.
Dále je vhodné vytvořit testovací program a sadu testů, kterou je možné automatizovaně spouštět a vyhodnocovat.
Tyto soubory pak umístit do adresáře \texttt{lib/test/<operation>/}.
Další vhodnou součástí operace je benchmark pro vyhodnocení rychlosti jednotlivých
implementací dané operace. Zdrojové soubory pro provádění benchmarků se ukládají do složky \texttt{lib/bench/<operation>/}.

\section{Použití knihovny}\label{api:usage} % #######################################################################
Celou knihovnu je možné sestavit příkazem \texttt{make all} v hlavním adresáři knihovny.
Při provedení tohoto příkazu bude celá knihovna sestavena bez debugovacích informací a s vypuštěním všech
volání makra \texttt{assert}, které slouží pro kontrolu platnosti definovaných podmínek.
Výsledkem sestavení je soubor knihovny \texttt{fastnet.a} nacházející se v adresáři \texttt{lib/src/}.
Jako vedlejší produkt překladu vzniknou i knihovny implementující jednotlivé operace a budou umístěny
v příslušných složkách \texttt{lib/src/<operation>/<operation>.a}.
Dalšími cíli pro program \texttt{make} jsou:

\begin{itemize}
    \item{\texttt{test} - spustí automatické testování všech částí knihovny}
    \item{\texttt{bech} - spustí benchmarky všech částí knihovny}
    \item{\texttt{doc} - vygeneruje programovou dokumentaci ke všem částem knihovny}
    \item{\texttt{clean} - smaže všechny soubory vytvořené překladem}
\end{itemize}

Knihovny reprezentující jednotlivé operace je možné sestavit příkazem \texttt{make}
v odpovídajícím adresáři. Pro překlad s debugovacími informacemi je možno využít cíl sestavení
\texttt{make lib}.

\chapter{Výsledky}\label{chapter:results} % ##########################################################################
Tato kapitola shrnuje a vizualizuje dosažené výsledky při implementaci jednotlivých operací.
Benchmarky byly provedeny na procesoru Intel(R) Core(TM) i3-2310M CPU @ 2.10GHz a pro architekturu ARM na desce SoCrates\footnote{http://www.devboards.de/en/home/boards/product-details/article/socrates/} s procesorem ARM Cortex-A9.

\section{Hledání nejdelšího shodného prefixu}\label{section:results-lpm} % ####################################################################

Hledání nejdelšího shodného prefixu bylo testováno na celkem pěti vstupních sadách dat, které
se liší počtem záznamů směrovací tabulky. Data byla převzata z volně dostupných dat RIPE\footnote{https://www.ripe.net/}.
Počet záznamů směrovacích tabulek, verze IP adres a délky prefixů jsou popsány v tabulce \ref{tab:lpm-input}.
Dosažené výsledky pro jednotlivé sady dat jsou vizualizovány v grafech \ref{fig:lpm-ipv4} pro sady IPv4 a
\ref{fig:lpm-ipv6} pro sady IPv6 na platformě Intel a v grafech \ref{fig:lpm-ipv4-arm} a \ref{fig:lpm-ipv6-arm} pro
platformu ARM.

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|l|l|}
    \hline
    Název & Počet adres & Nejkratší prefix & Nejdelší prefix & Verze IP \\ \hhline{|=|=|=|=|=|}
    1k & $1000$ & 13 & 31 & IPv4 \\ \hline
    10k & $10000$ & 8 & 32 & IPv4 \\ \hline
    100k & $100000$ & 8 & 32 & IPv4 \\ \hline
    1k & $1000$ & 23 & 128 & IPv6 \\ \hline
    10k & $10000$ & 19 & 128 & IPv6 \\ \hline
    \end{tabular}
	\caption{Směrovací tabulky pro testování}
    \label{tab:lpm-input}
\end{table}

Vyhledávání ve směrovací tabulce bylo prováděno oproti $1000$ IP adresám odpovídající verze. Tyto adresy byly vybrány
ze záznamů směrovacích tabulek použitých pro testování.

\begin{figure}[H]
	\centering
	\includegraphics[scale=1]{fig/lpm-ipv4.pdf}
	\caption{Rychlost hledání nejdelšího shodného prefixu pro IPv4 na platformě Intel}
    \label{fig:lpm-ipv4}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{fig/lpm-ipv4-arm.pdf}
    \caption{Rychlost hledání nejdelšího shodného prefixu pro IPv4 na platformě ARM}
    \label{fig:lpm-ipv4-arm}
\end{figure}

Benchmark byl proveden pro algoritmy TreeBitmap (v grafu označeno jako \texttt{tbm-střída}) ve velikostech střídy $1-8$ a pro binární vyhledávání na délce prefixu (v grafu označeno jako \texttt{bspl-1}).
Jak je možno vyčíst z uvedených grafů, tak nejlepších výsledků bylo dosaženo pro TreeBitmap s velikostí
střídy nastavenou na $5$ bitů a to jak pro IPv4 tak i pro IPv6.

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=1]{fig/lpm-ipv6.pdf}
	\caption{Rychlost hledání nejdelšího shodného prefixu pro IPv6 na platformě Intel}
    \label{fig:lpm-ipv6}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=1]{fig/lpm-ipv6-arm.pdf}
    \caption{Rychlost hledání nejdelšího shodného prefixu pro IPv6 na platformě ARM}
    \label{fig:lpm-ipv6-arm}
\end{figure}

Pro testování algoritmu binárního vyhledávání na délce prefixu byla zvolena velikost hašovací tabulky
stejná jako počet záznamů směrovací tabulky pro zvolenou sadu dat. Tento přístup byl zvolen z důvodu významného vlivu
velikosti hašovací tabulky na rychlost samotného vyhledávání.
V případě nastavení velikosti hašovací tabulky na $100$ prvků byl algoritmus vyhledávání v tabulce obsahující
 $100 000$ záznamů $400\times$ pomalejší.


Dalším důležitým faktorem pro efektivnost implementace je velikost datových struktur, která je
závislá na velikosti střídy pro algoritmus TreeBitmap a také na počtu směrovacích pravidel.
Velikost struktury jednoho uzlu v závislosti na počtu směrovacích pravidel je ovlivněna následujícím způsobem.
Do 256 záznamů zabírá pravidlo pouze $1B$, do 65536 záznamů pak $2B$ a pro více než 65536 pak celé $4B$ pro uložení právě jednoho pravidla. Rozdíl mezi uložení $65536$ adres a $65537$ adres pak bude činit
$200KB$. Velikost uzlů stromu pro zvolené algoritmy v závislosti na počtu záznamů směrovací tabulky
je popsán v tabulce \ref{tab:lpm-input}.

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|l|l|}
    \hline
    & & \multicolumn{3}{l|}{Velikost pro počet směrovacích pravidel} \\ \hline
    Algoritmus & Velikost střídy & $< 256$ & $< 65536$ & $\geq 65536$\\ \hhline{|=|=|=|=|=|}
    TBM & 1 & $24B$ & $25B$ & $28B$ \\ \hline
    TBM & 2 & $24B$ & $25B$ & $28B$\\ \hline
    TBM & 3 & $24B$ & $25B$ & $28B$\\ \hline
    TBM & 4 & $24B$ & $25B$ & $28B$\\ \hline
    TBM & 5 & $32B$ & $33B$ & $36B$\\ \hline
    TBM & 6 & $40B$ & $41B$ & $44B$\\ \hline
    TBM & 7 & $64B$ & $65B$ & $68B$\\ \hline
    TBM & 8 & $112B$ & $113B$ & $116B$\\ \hline
    BSPL & --- & $48B$ & $49B$ & $52B$\\ \hline
    \end{tabular}
	\caption{Velikosti datových struktur v závislosti na počtu směrovacích pravidel a velikosti střídy}
    \label{tab:lpm-input}
\end{table}

Jak je možné vyčíst z výše uvedené tabulky, tak i přestože nejrychlejší implementací je TreeBitmap se střídou 5, tak v případě omezené paměti by bylo vhodnější zvolit kompromis mezi rychlostí a paměťovou náročností v podobě
TreeBitmap s velikostí střídy 4, který dosahuje nejmenší možné velikosti datové struktury a zároveň nejlepších výsledků pro danou velikost datové struktury.

\section{Hledání řetězců} % #####################################################################################
Testování efektivity implementace hledání řetězců bylo provedeno na dvou vstupních testovacích sadách,
kde první sada \texttt{fallbacks} obsahuje slova s výskytem stejných písmen, tudíž při tvorbě konečného automatu bude
docházet ke generování \textit{failure} přechodů, jež budou poté procházeny. Druhá testovací sada \texttt{no-fallbacks}
obsahuje slova, která neobsahují stejná písmena. Výsledky dosažené pro jednotlivé testovací sady jsou
vizualizovány v grafu \ref{fig:pm} pro platformu Intel a \ref{fig:pm-arm} pro platformu ARM. Testování probíhalo na datových paketech odchycených z komunikace osobního počítače. Testovací sady obsahují klíčová slova používaná v protokolu HTTP\footnote{Hyper-text transfer protocol}.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{fig/pm.pdf}
    \caption{Rychlost hledání řetězců na platformě Intel}
    \label{fig:pm}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=1]{fig/pm-arm.pdf}
    \caption{Rychlost hledání řetězců na platformě ARM}
    \label{fig:pm-arm}
\end{figure}

Jak je možné vyčíst z grafu tak sada obsahující \textit{failure} přechody dosahuje mírně horších výsledků,
což je způsobeno delším zpracování znaku, pro který neexistuje validní přechod v aktuálním stavu konečného automatu.

Velikost každého stavu konečného automatu je v této implementaci $48B$
a podobně jako hledání nejdelšího shodného prefixu je závislá na počtu vložených pravidel.

\section{Hledání regulárních výrazů} % ###############################################################################

Jak je vidět na v grafech \ref{fig:regex} a \ref{fig:regex-arm} tak hledání regulárních výrazů pomocí deterministického konečného automatu je rychlejší více než dvakrát.
Tento rozdíl v rychlosti je způsobený nutností procházení $\epsilon$-přechodů.
Procházení založené na deterministickém konečném automatu tímto problémem netrpí,
neboť při zpracování každého vstupního symbolu dojde k přechodu do dalšího stavu.
Benchmark byl prováděn na datech reprezentující síťovou komunikaci osobního počítače a jako
regulární výrazy byly použity výrazy definující URL adresu a stavové kódy HTTP protokolu.

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=0.8]{fig/regex.pdf}
	\caption{Rychlost hledání regulárních výrazů na platformě Intel}
    \label{fig:regex}
\end{figure}


\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=0.8]{fig/regex-arm.pdf}
    \caption{Rychlost hledání regulárních výrazů na platformě ARM}
    \label{fig:regex-arm}
\end{figure}
Velikost datových struktur pro jednotlivé stavy konečného automatu pro deterministický a nedeterministický
automat je znázorněna v tabulce \ref{tab:regex-size}.

\begin{table}[!htbp]
    \center
    \begin{tabular}{|l|l|}
    \hline
    Typ automatu & Velikost stavu\\ \hhline{|=|=|}
    deterministický  & $24B$\\ \hline
    nedeterministický & $40B$\\ \hline
    \end{tabular}
    \caption{Velikosti stavů konečného automatu}
    \label{tab:regex-size}
\end{table}

\chapter{Závěr}\label{chapter:conclusion} % ########################################################################
Cílem této práce bylo popsat a navrhnout aplikační programové rozhraní časově kritických operací využívaných v oblasti
počítačových sítí.
Teoretické základy, ze kterých tato práce vychází, jsou rozvedeny v kapitole \ref{chapter:theoretical}.
Mezi vybrané časově kritické operace patří klasifikace paketů a speciálně pak jednodimenzionální klasifikace paketů
dle cílové IP adresy, hledání nejdelšího shodného prefixu. Pro tuto operaci jsou popsány
algoritmy binárního vyhledávání na délce prefixu a TreeBitmap.
Mezi další rozvedené operace patří hledání řetězců a pro tuto operaci je popsán
algoritmus autorů Aho a Corasickové. Další z operací je hledání regulárních výrazů
za použití konečných automatů, konkrétně deterministického a nedeterministického.
Poslední popsanou operací je analýza a extrakce hlaviček.
Pro každou popsanou operaci je navrženo API popsané v kapitole \ref{chapter:api}.

V kapitole \ref{chapter:results} jsou diskutovány výsledky dosažené
při implementaci operací hledání nejdelšího shodného prefixu, hledání řetězců a hledání regulárních
výrazů. Pro hledání nejdelšího shodného prefixu vychází jako nejrychlejší implementace algoritmu
TreeBitmap s velikostí střídy 5. Tohoto výsledku bylo dosaženo na několika datových sadách,
jež vycházejí ze směrovacích tabulek reálný směrovačů.
Pro operaci hledání řetězců bylo experimentování prováděno na síťovém provozu zachyceném
při komunikaci osobního počítače. Jako vzorek
testovaných klíčových slov bylo využito klíčových slov definovaných pro HTTP.
Při experimentování s regulárními výrazy byly jako vstupní data použita stejná data jako pro hledání řetězců,
a jako regulární výrazy byly použity takové regulární výrazy, které dokáží identifikovat URL\footnote{Uniform resource locator} adresu a stavový kód HTTP protokolu. Pro regulární výrazy bylo dosaženo
více než dvojnásobné rychlosti zpracování při využití deterministických konečných automatů
oproti použití nedeterministických konečných automatů.

Jako kroky navazující na tuto práci je možné implementovat zbývající operace, pro které je navrženo API, ale nebyla provedena implementace. Těmito operacemi je klasifikace paketů a analýza a extrakce hlaviček paketů.

Ze specifikace požadavků na implementaci knihovny vychází požadavek na běh knihovny v prostředí
vestavěných systémů, které disponují omezeným operační paměti, a z toho
důvodu by jedním z dalších kroků mohlo být testování s omezenou velikostí operační paměti.
Je nutné ověřit, že knihovna bude reagovat správným způsobem na nedostatek paměti a nezpůsobí pád systému,
v rámci kterého je spouštěna.

Jako dalším možným rozšířením je návrh API a poté implementace vláknového zpracování, které bude
umožňovat zřetězené zpracování jednotlivých operací.
