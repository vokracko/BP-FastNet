%=========================================================================

\chapter{Úvod} % #####################################################################################

Žijeme v době kdy se internet stal nedílnou součástí každodenního života a s internetem už nepracují
pouze klasické počítače, ale do popředí se také dostávají mobilní zařízení, které meziročně
zaznamenávají více než $50\%$ nárůst. Dalším druhem zařízení jež se začínají připojovat
jsou vestavěné systémy patřící do trendu nazývaného internet věcí.
S rychlostí jakou přibývají zařízení vyžadující přístup k internetu ale i s jeho rozšiřováním
do zemí zatím nedotčených se neustále zvyšují požadavky na rychlost, se kterou data prochází počítačovými
sítěmi a z toho vyplývající požadavky na rychlost zpracování síťového provozu a to zejména na zařízeních
starajících se o řízení internetového provozu na páteřních linkách. Mezi tyto
zařízení lze zařadit směrovače (routery), které řídí datové toky mezi jednotlivými sítěmi,
přepínače (switche) starající se o řízení toků dat uvnitř autonomních sítí a
systémy pro detekci (IDS\footnote{Intrusion detection system}) a prevenci (IPS\footnote{Intrusion prevention system})
síťových útoků, které analyzují obsah každého paketu procházejícího sítí.

Páteřní spoje v době psaní této práce dosahují rychlostí v řádech desítek gigabitů
za sekundu a z toho vyplývají požadavky na rychlost zpracování síťových dat. Při těchto rychlostech
jsou tradiční procesory schopny vykonat pouze desítky instrukcí, což nestačí na provedení všech potřebných
operací. Nicméně je důležité aby stejné rychlosti zpracování dosahovaly všechna zařízení na páteřních spojích,
protože počítačová sít je pouze tak rychlá, jak rychlá je její nejpomalejší část, tzv. úzké hrdlo.

Z těchto vlastností vycházejí požadavky na stále efektivnější algoritmy zpracovávající časově kritické operace.
Časově kritické operace jsou takové operace, jež při zpracování síťového provozu trvají nejdelší dobu a rozbor
těchto operací je součástí této práce. Z těchto operací jsou vybrány a rozvedeny operace
hledání řetězců a regulárních výrazů, analýza a extrakce hlaviček paketů a klasifikace paketů, speciálně pak jednodimenzionální klasifikace dle cílové IP adresy, hledání nejdelšího shodného prefixu.

Přínosem této knihovny je vlastní implementace zmíněných časově kritických operací, která bude
využita výzkumnou skupinou ANT na Fakultě Informačních technologií Vysokého učení technického v Brně
pro vytváření bezpečnostních aplikací a systémů.
Pro knihovnu je navržen a implementován obecný princip vláknového zpracování použitelný pro všechny
zmíněné operace, který umožňuje řetězit požadavky na zpracování do vyrovnávacích pamětí a jednotlivé operace
provádět plynule za sebou bez nutnosti zasahovat do datových struktur nebo toku řízení.

V kapitole \ref{chapter:theoretical} jsou popsány síťové modely a vrstvy těchto modelů,
nad nimiž jsou operace této knihovny implementovány, dále jsou popsány časově kritické operace prováděné
prvky v počítačových sítích. Kapitola \ref{chapter:api} popisuje návrh veřejného rozhraní vytvořené knihovny
pro operace zmíněné v kapitole \ref{chapter:theoretical}, způsoby použití této knihovny a možnosti rozšíření
o další časově kritické operace. V kapitole \ref{chapter:results} jsou vizualizovány a diskutovány
výsledky, jichž se podařilo dosáhnout v implementaci této knihovny a to na dvou hlavních platformách, Intel a ARM.
Kapitola \ref{chapter:conclusion} shrnuje dosažené výsledky a nastiňuje další možný vývoj této knihovny
a to jak z hlediska rozšiřování repertoáru implementovaných operací tak i z pohledu dalších optimalizací
a testování ve scénářích odpovídajících používání knihovny v reálných systémech.

\chapter{Teoretický rozbor}\label{chapter:theoretical} % ###########################################################

Tato kapitola poskytuje teoretické informace ze kterých vychází další kapitoly.
V první části je popsán síťový model ISO/OSI a jeho vrstvy důležité z pohledu této práce.
V druhé části jsou pak podrobněji rozebrány jednotlivé časově kritické operace a největší důraz je
kladen na jednodimenzionální klasifikaci paketů, vyhledání nejdelšího shodného prefixu.


\section{Síťové modely}\label{section:models} % #######################################################################
Zpracování dat síťového provozu je rozděleno do několika úrovní. Tyto úrovně jsou popsány síťovými modely.
Základním modelem je ISO/OSI, který slouží pro abstraktní rozdělení operací zpracování síťových dat a využití
našel pouze v akademické sféře. V reálných počítačových sítích pak dominuje model TCP/IP, který má oproti
ISO/OSI modelu menší počet vrstev. Modelu ISO/OSI je rozdělen na sedm vrstev. V pořadí od nejnižší úrovně to
jsou vrstvy fyzická, linková, síťová, transportní, relační, prezentační a aplikační. Pro tuto práci jsou
podstatné pouze první čtyři vrstvy. Ty jsou detailněji popsány v kapitolách \ref{layers:physical},
\ref{layers:link}, \ref{layers:network} a \ref{layers:transport}. Na obrázku \ref{fig:layers} je
znázorněn průchod jednoho datového paketu odeslaného ze stanice A s cílovou adresou stanice B jednotlivými vrstvami modelu ISO/OSI. Jak je z obrázku patrné tak různé druhy síťových zařízení pracují s různými vrstvami.

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=.25]{fig/layers.pdf}
	\caption{Znázornění průchodu dat počítačovou sítí v modelu ISO/OSI}
\end{figure}\label{fig:layers}

\begin{description}
\item[Fyzická vrstva / Vrstva síťového rozhraní]\label{layers:physical} % ##################################
je nejnižší vrstva ISO/OSI modelu a pracuje s daty na úrovni bitů. Stará se o
jejich přenos po přenosovém médiu. Protokoly této vrstvy definují signály reprezentující data
a tudíž jde o protokoly implementované již v hardware síťových zařízení.

\item[Linková vrstva]\label{layers:link} % ###################################################################
je druhá nejnižší ISO/OSI modelu. Tato vrstva se stará o datovou komunikaci
obecně mezi několika uzly, které jsou přímo spojeny. Spojení může být jak fyzickým vodičem tak i
bezdrátovou technologií. Nejrozšířenější technologií pro fyzické spoje je Ethernet IEEE 802.3 a pro bezdrátové spoje
je to standard IEEE 802.11. Datová jednotka na linkové vrstvě se nazývá rámec a nese v sobě kromě
zapouzdřených dat vyšších vrstev také informace o kontrolním součtu dat a adresování pomocí MAC adres.
MAC adresa je adresa fyzického zařízení, které pracuje na této vrstvě.
Adresování MAC adresou slouží pro identifikaci zařízení, které se nacházejí ve stejné počítačové síti
a za hranici této sítě se již používá IP adresace, která je vysvětlena v následujícím odstavci.
Síťová zařízení pracující na této vrstvě se nazývají přepínače (angl. switch). Úkolem přepínačů je zjistit MAC adresu cílové stanice a přeposlat data portem vedoucím k cílového zařízení.

\item[Síťová vrstva]\label{layers:network} % ###############################################################
se stará o unikátní adresaci zařízení připojených do internetu pomocí IP adres a o směrování paketů.
Umožňuje tak komunikovat zařízením, které nejsou spojeny přímo, ale existuje mezi nimi jedna nebo více cest.
Prvky pracující na této vrstvě jsou nazývaný směrovače (angl. router) a pracují s datovou strukturou zvanou
datagramy, jež obsahují právě IP adresy jednoznačně určující zdrojové a cílové zařízení. Směrování paketů
je věnována kapitola \ref{section:lpm}

\item[Transportní vrstva]\label{layers:transport} % #########################################################
pracuje s datovou strukturou zvanou segmenty.
Segmenty obsahují informace jako je kontrolní součet pro zajištění integrity dat,
pořadové číslo rámce pro spojení dat, která byla na cestě k cíli rozdělena na více částí a také obsahuje čísla portů
pro určení uživatelských aplikací, která data odeslala a která je na druhém konci má přijmout.
Na transportní vrstvě se používají dva protokoly a to TCP a UDP. Hlavním rozdílem mezi těmito protokoly
je zaručení spolehlivého doručení, které poskytuje pouze TCP. Situace ve kterých pozitiva jako
nižší režie přebijí zápory je hlavně přenos dat v reálném čase. To je například streamování videa,
přenos hlasu technologie VoIP a přenos informací do online her.
Zpracování dat na úrovni transportní vrstvy a všech vyšších vrstev není implementováno na síťových
zařízeních starajících se přenos dat po síti. Jediná zařízení, které implementují zpracování
dat těchto vrstev jsou koncová zařízení.

\end{description}

\section{Časově kritické operace} % ############################################################################
Pod pojmem časově kritické operace se rozumí takové operace, které zabírají nejvíce výpočetního
času při zpracování jednoho paketu a typicky je nutné provádět je na více síťových zařízeních.
Těmito zařizeními mouhou být směrovače, přepínače, firewally a také systémy
oddělené od řízení síťového provozu jako například sondy pouze monitorující síťový provoz nebo analyzátory,
které mohou hledat signatury útoků v datových tocích.
Mezi časově kritické operace rozebrané v této práci patří klasifikace paketů a velký důraz je kladen na
jednodimenzionální klasifikaci dle cílové IP adresy, vyhledávání nejdelšího shodného prefixu.
Tato operace je využívána pro prohledávání směrovací tabulky směrovačů pro určení nejvhodnější cesty jakou
bude paket pokračovat při své cestě k cílovému zařizení.
Další z operací je analýza a extrakce hlaviček paketů, která je využívána v již zmíněné klasifikaci,
kde je nutné z hlavičky paketu extrahovat všechny informace dle který bude paket klasifikován.
Dalšími z rozebíraných operací je hledání podřetězců a hledání regulárních výrazů.
Poslední dvě zmíněné operace slouží především pro detekci útoků v systémech IDS (intrusion detection system)
a pro prevenci útoků v systémech IPS (intrusion prevention system). Jedná se o operace sloužící
pro hloubkové prohledávání paketů (Deep Packet Inspection). Toto prohledávání na rozdíl od ostatních operací
pracuje s datovým obsahem paketů a ne jenom s hlavičkami paketu. Z toho vychází časová náročnost,
neboť místo vyhodnocení hlavičky paketu jež čítá 19 bytů pro IPv4 a 40 bytů pro IPv6 je nutno
projít veškerá data, jejichž velikost se typicky pohybuje v rozmezí $1 - 1500B$.

\subsection{Klasifikace paketů}

Klasifikace paketů je operace rozhodující o dalším zpracování paketu.
Výsledkem klasifikace pak může být rozhodnutí, zda daný paket může projít do
dalšího vyhodnocování nebo zda pochází nebo směřuje do sítě jež není dovolena.
Této klasifikace se využívá například pro povolení pouze určitého rozsahu zdrojových IP adres
pro omezení přístupu do podnikové sítě nebo pro blokování paketů snažících se přistupovat
ke službám jež jsou zakázány.

Data využívané pro klasifikaci se skládají z ntice položek hlavičky paketu, pravidla a priority.
Nejčastěji využívanou klasifikací je klasifikace skládající se z pětice položek IP hlavičky
a to zdrojové adresy, cílové adresy, zdrojového portu, cílového portu a protokolu transportní vrstvy.
Obsahem klasifikačních pravidel pak mohou být přesně specifikované hodnoty, rozsahy nebo prefixy.
Prefixy jsou obecnějším zápisem specifických hodnot i rozsahů, neboť rozsah lze přepsat v nejhorším
případě na $2N - 2$ prefixů, kde N odpovídá počtu bitů reprezentující rozsah. V případě specifické hodnoty
je to prefix pouze jeden o bitové délce stejné jako reprezentovaná hodnota.

Klasifikace je prováděna jako vyhledání každé definované položky v množině reprezentující hodnoty
této položky a poté výběr pravidla s nejvyšší priritou z kartézského součinu těchto množin.

Tato práce se zabývá pouze jednodimenzionální klasifikací založenou na cílové IP adrese, hledání
nejdelšího shodného prefixu, operace sloužící pro prohledávání směrovacích tabulek směrovačů
rozvedené v následující kapitole.

\subsection{Hledání nejdelšího shodného prefixu}\label{section:lpm} % #######################################
Problém hledání nejdelšího shodného prefixu se rozumí jednodimenzionální klasifikace paketů dle
jejich cílové IP adresy, která může být jak verze 4, tak verze 6.
Hledání nejdelšího shodného prefixu je operace, která je prováděna
na síťových prvcích zvaných směrovače. Tyto prvky jsou umístěny na každém rozhraní dvou a více
počítačových sítích. Jejich cílem je nalézt nejvhodnější cestu, kterou směrovat příchozí paket.
Struktura reprezentující uložené směrovací informace se nazývá směrovací tabulka.
Tato tabulka ukládá informace o dostupných sítích (jejich prefixech), délce tohoto prefixu a rozhraní,
kterým se lze do odpovídající sítě dostat. Příklad směrovací tabulky je zobrazen v tabulce \ref{tab:routing-table}

\begin{table}[!htbp]
	\label{tab:routing-table}
	\center
    \begin{tabular}{|l|l|l|}
    \hline
    Prefix        & Délka prefixu & Rozhraní \\ \hline
    147.228.0.0   & 14            & eth0       \\ \hline
    147.228.128.0 & 17            & eth0       \\ \hline
    \end{tabular}
    \caption{Příklad směrovací tabulky}
\end{table}

S velkým rozmachem počítačových sítí v poslední dekádě dochází k velkému nárůstu směrovacích informací a
pro zmenšení směrovacích tabulek byl navržen takzvaný supernetting, který agreguje směrovací záznamy
sdílející stejné rozhraní a mající společnou část prefixu do jednoho záznamu.
Pokud vezmeme v úvahu výše uvedenou tabulku tak při použití supernettingu by byly oba záznamy sloučeny
v jeden, který by vypadal takto: $147.228.0.0/14, eth0$.
Tím je dosaženo zmenšení směrovacích tabulek, nicméně i s využitím supernettingu zůstává hledání nejdelšího shodného
prefixu časově kritickou operací.
Pro snadnější porozumění bude v následující části používán binární zápis prefixů.

Prefix ve směrovací tabulce je reprezentován jako posloupnost nul a jedniček s hvězdičkou na konci,
která značí že všechny adresy, jejichž začátek je shodný s částí před hvězdičkou, odpovídají tomuto prefixu.
Jako příklad uvedu prefix A $1001*$ jež odpovídá adresám začínajícím $1001$, tedy $10010*$ i $10011*$.
Nicméně ve směrovací tabulce může být uložen i prefix B $10010*$, který sdílí první čtyři bity své adresy
s výše uvedeným prefixem A a v případě, že přijde paket začínající hodnotou $10010$ je z pohledu směrování
nutno vyhodnotit prefix B jako nejdelší shodný a poté paket správně směrovat. V případě $10011$ je však nejdelším
shodným prefixem pravidlo A a tudíž nesmí dojít k vyhodnocení prefixu B jako nejdelšího.
Z toho důvodu je nutné ve směrovací tabulce uchovávat i informace o délce prefixu.
Tato informace poté slouží pro rozhodnutí, jaké pravidlo směrovací tabulky má nejdelší shodný prefix.
Délka prefixu může nabývat hodnot $1-32$ pro adresy typu
IPv4 a $1-128$ pro adresy typu IPv6.
Z výše uvedených informací a příkladů vyplývá,
že je nutné rozlišovat zda existující prefix reprezentuje adresu verze IPv4 nebo IPv6,
jinak by mohlo docházet k vyhodnocení nejdelšího shodného prefixu pro adresu IPv4
jako jiný prefix verze IPv6, což by mělo za následek nevalidní směrování paketů.
Jako příklad může sloužit následující směrovací tabulka, ve které je první pravidlo
verze IPv4 a druhé IPv6 a při vyhledání by nebylo možné určit jaké pravidlo je to správné.

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|l|}
    \hline
    Prefix & Délka prefixu & Rozhraní \\ \hline
    $100*$ & 3 & eth0 \\ \hline
    $100*$ & 3 & eth3 \\ \hline
    \end{tabular}
    \caption{Příklad směrovací tabulky}
\end{table}

Pro hledání nejdelšího shodného prefixu existuje velké množství algoritmů, které jsou popsány v \cite{tbm}
Většina z nich je založena na procházení stromové struktury. Každý algoritmus má jiné paměťové nároky
a dosahuje jiných rychlostí. Z toho důvodu je při výběru vhodného algoritmu nutné
volit kompromis mezi rychlostí a paměťovou náročností.
V případě že jde o implementaci na architektuře FPGA důraz bude pravděpodobně kladen na paměťovou náročnost
a to z důvodu, že tyto čipy mají omezenou kapacitu paměti. Na architekturách vycházejících z x86 je naopak kladen důraz
na rychlost zpracování z důvodů obecných procesorů, které nejsou specializovány na zpracování těchto operací
a dosahují tak delší doby zpracování.

První algoritmus hledání nejdelšího shodného prefixu byl založen na naivním procházení lineárního
seznamu. Doba vyhledávání pomocí tohoto algoritmu byla závislá na počtu uložených prefixů a její
časová složitost byla $O(N)$, což při dnešních rychlostech umožňuje procházet směrovací tabulku
obsahující pouze malý počet záznamů.

Algoritmy rozebrané v této kapitole vycházejí z obecně n-árního stromu,
jež je rozšířením binárního stromu na více než dva potomky.
Těmito algoritmy je binární vyhledávání na délce prefixu a TreeBitmap.
Binární vyhledávání na délce prefixu používá binární strom pro interní reprezentaci směrovacích
informací a pro vyhledávání využívá struktury hašovací tabulky, ve které jsou uloženy všechny existující uzly
binárního stromu.
TreeBitmap je algoritmus založený na obecném n-árním stromu a vyznačuje se tím,
že pro uložené prefixu využívá zakódované bitmapy, které umožňuje procházet stromem
po více než jednom bitu a dosahuje tak menší paměťových nároků.
Dosažené výsledky pro různé n jsou vizualizovány v kapitole \ref{section:results-lpm}.


\subsubsection{TreeBitmap} % #####################################################################################

Algoritmus TreeBitmap je založen na datové struktuře n-ární stromu, v němž jsou uloženy směrovací informace.
Hlavní myšlenkou je uložení všech uzlů na jednom paměťovém místě, což znamená že stačí uchovávat pouze jednu
adresu reprezentující paměťové místo, kde se uzly nacházejí, a index pro určení jaký uzel se má vybrat.
Výhodou tohoto zakódování informací je zmenšení paměťových nároků pro uložení každého uzlu stromové struktury.
Další specifickou vlastností algoritmu TreeBitmap je zpracování několika bitů adresy v jednom kroku.
Počet zpracovaných bitů je nazýván střída a právě velikost střídy je stupněm n-árního stromu.

Každý uzel stromové struktury obsahuje dvě bitmapy, interní a externí, které slouží pro zakódování indexů.
Interní bitmapa slouží pro zakódování informací, jaké prefixy se nacházejí v aktuálním uzlu.
Externí bitmapa pak uchovává informace o existujících cestách do nižších vrstev stromové struktury.
Příklad zakódovaných bitmap je zobrazen v tabulce \ref{tab:tbm-bitmaps}.
Dalšími položkami uzlu je ukazatel na pole následujících uzlů a ukazatel na pole obsahující směrovací pravidla.

\begin{table}
	\center
	\label{tab:tbm-bitmaps}
    \begin{tabular}{|l||c|c|c|c|c|c|c|}
    \hline
    Prefix & $*$ & $0*$ & $1*$ & $00*$ & $01*$ & $10*$ & $11*$ \\ \hhline{|=#=|=|=|=|=|=|=|}
    Interní bitmapa & 0 & 1 & 0 & 0 & 0 & 1 & 1 \\ \hline
    \multicolumn{4}{|l|}{Externí bitmapa} & 1 & 0 & 1 & 0 \\ \hline
    \end{tabular}
    \caption{Příklad bitmap algoritmu TreeBitmap}
\end{table}

Algoritmus vyhledávání spočívá v procházení stromu od kořenu a zjišťování, zda
existuje prefix odpovídající zpracované části adresy. Částí adresy se rozumí N bitů, jež jsou brány postupně
od nejvýznamnějších bitů hledané adresy až po nejméně významné.
Jako první operace hledání nejdelšího shodného prefixu se extrahují bity adresy na pozici odpovídající
aktuální hloubce zanoření ve stromu a provede se operace zjištění, zda je pro část této adresy uloženo
směrovací pravidlo. To je zjištěno z interní bitmapy na pozici, jež odpovídá délce a hodnotě extrahovaných bitů.
Pozice interní bitmapy je vypočítána jako $2^{N} - 1 + x$, kde $N$ reprezentuje hodnotu střídy a $x$
dekatickou hodnotu extrahovaných bitů.
Pokud se na této pozici
nachází hodnota "1", je uloženo pravidlo na indexu spočítatelným jako $ones(bitmap, position)$ v poli pravidel.
Toto pravidlo pak reprezentuje dočasný nejlepší výsledek. Pokud je na vypočítaném
pozici v interní bitmapě hodnota "0" je opakován výpočet pozice s hodnotou $N$ sníženou o jedna a bitovou hodnotou
oříznutou o nejméně významný bit. Tato operace se opakuje tak dlouho, dokud není nalezen existující pozice
v externí bitmapě s hodnotou "1"
nebo dokud není N nulové. Jako druhá operace je provedeno hledání následovníků ve stromové struktuře
reprezentující specifičtější prefixy. To je provedeno jako zjištění přítomnosti hodnoty "1" v externí
bitmapě na pozici, jejíž hodnota je dekadickou reprezentací extrahovaných bitů. V případě přítomnosti
"1" na této pozici je proveden přechod do další úrovně stromové struktury a celý postup se opakuje.
Pokud je na této pozici hodnota "0" je vyhledávání ukončeno a jako výsledek je navrácena hodnota
dočasného nejlepšího výsledku, která odpovídá pravidlu jež patří k nejdelšímu shodnému nalezenému
prefixu. Celý algoritmus je popsán v pseudokódu v algoritmu \ref{alg:treebitmap}.

Pro výpočet indexu do polí obsahující pravidla a následovníky se používá funkce
\texttt{ones(bitmap, position)}, jež
spočítá počet bitů s hodnotou "1" v dané bitmapě a to od pozice 0 do pozice \texttt{position}.

Jeden uzel stromu TreeBitmap je vizualizován na obrázku \ref{fig:tbm-node}. Uzly zbarvené černě
jsou uzly pro které je definováno směrovací pravidlo.

\begin{figure}[!htbp]
	\label{fig:tbm-node}
	\centering
	\includegraphics[scale=.55]{fig/tbm.pdf}
	\caption{Jeden uzel algortimu TreeBitmap}
\end{figure}

\begin{algorithm}[H]
	\label{alg:treebitmap}
	\KwData{tbm-root, ip, ip-length}
	\KwResult{routing rule}
	node $\leftarrow$ tbm-root\;
	longest-match-node $\leftarrow$ tbm-root\;
	longest-match-index $\leftarrow$ 0\;
	position $\leftarrow$ 0\;
	\Repeat{BIT(parent.external, bits)}
	{
		bits $\leftarrow$ get-stride-bits(ip, position)\;
		position $\leftarrow$ position + STRIDE\;


		\If{internal-index(node.internal, bits)}
		{
			longest-match-node = node\;
			longest-match-index = internal-index(node.internal, bits)\;
		}

		index $\leftarrow$ ones(node.external, bits)\;
		parent $\leftarrow$ node\;
		node $\leftarrow$ node.external[index]\;
	}
	\Return longest-match-node.rule[logest-match-index]\;
	\caption{Hledání nejdelšího shodného prefixu algoritmem TreeBitmap}
\end{algorithm}

\subsubsection{Binární vyhledávání na délce prefixu - Binary search on prefix length} % ###################################################################

Prefixy jsou pouze v konečných listech
Hašování:
	prefix - konec
	nonprefix - rozšířit
	nic - zmenšit

\begin{figure}[!htbp]
	\begin{floatrow}
		\ffigbox{
		\includegraphics[scale = 0.5]{fig/bspl-not-pushed.pdf}}
			{\caption{Strom před leaf-pushingem}\label{bspl-not-pushed}}
		\ffigbox{\includegraphics[scale = 0.5]{fig/bspl-pushed.pdf}}
			{\caption{Strom po provedení leaf-pushingu}\label{bspl-pushed}}
	\end{floatrow}
\end{figure}

Algoritmus binary search on prefix length je založen binárním vyhledávání neboli na metodě
půlení intervalů. Vyhledávání půlením intervalů
se ve své první iteraci pokusí vyhledat shodný prefix celé délky, tedy 32 bitů pro IP adresu
verze protokolu IPv4 a 128 bitů pro IP verze 6.

Mějme směrovací tabulku obsahující tyto informace:

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|}
    \hline
    Prefix        & Délka prefixu & Pravidlo \\ \hline
    147.228.0.0   & 14            & P1       \\ \hline
    147.228.128.0 & 17            & P2       \\ \hline
    \end{tabular}
    \caption{Příklad směrovací tabulky}
\end{table}

Vyhledávání směrovací cesty pro adresu 147.229.128.54 bude procházet následujícími kroky

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|l|}
    \hline
    Prefix & Délka prefixu  & Změna prefixu & Průběžný výsledek \\ \hline
    147.228.128.54 & 32 & 16 & Nenalezeno, zmenšit délku \\ \hline
    147.228.0.0 & 16 & 8 & Nenalezeno, zvětšit délku \\ \hline
    147.228.128.0 & 24 & 4 & Nenalezeno, zmenšit délku \\ \hline
    147.228.128.0 & 20 & 2 & Nenalezeno, zmenšit délku \\ \hline
    147.228.128.0 & 18 & 1 & Nenalezeno, zmenšit délku \\ \hline
    147.228.128.0 & 17 & 0 & Nalezeno, vrátit P2 \\ \hline
    \end{tabular}
    \caption{Příklad vyhledání nejdelšího shodného prefixu}
\end{table}

Operace vyhledání nejdelšího prefixu při využití algoritmu binary search on prefix length má časovou
složitost $\log{2}{N}$, kde \texttt{N} je počet bitů adresy. V případě IPv4 adresy je to 32 bitů a pro IPv6
adresu je to 128 bitů. Z principu algoritmu vyplývá, že nejhorší výsledky z časového hlediska bude dosahovat
při shodě prefixu, který byl zadán s lichou délkou. V tomto případě bude nutné projít všemi kroky.
Počet kroků v případě IPv4 bude 5 a v případě IPv6 adresy to pak bude 7.
Zde je vidět že i v případě čtyřikrát delší adresy se počet kroků pro vyhledání prefixu zvedne pouze o dva,
což neplatí pro algoritmus TreeBitmap, který musí projít v nejhorším případě až čtyřikrát více
uzlů aby nalezl odpovídající prefix.
\cite{bspl}

\begin{algorithm}
	\KwData{bspl-root, hash-table, ip, ip-length}
	\KwResult{routing rule}
	prefix-length $\leftarrow$ ip-length\;
	prefix-change $\leftarrow$ ip-length\;
	\Repeat{prefix-change $>$ 0}
	{
		bits $\leftarrow$ get-prefix-bits(ip, prefix-length)\;
		item $\leftarrow$ hash-table.get(bits)\;
		prefix-change $\leftarrow$ prefix-change $\gg$ 1\;

		\If{item == NULL}{prefix-length $\leftarrow$ prefix-length - prefix-change\;}
		\ElseIf{item.type == PREFIX}{prefix-length $\leftarrow$ prefix-length + prefix-change\;}
		\lElse{break}
	}
	\lIf{item == NULL}{\Return bspl-root.default-rule}
	\caption{Hledání nejdelšího shodného prefixu algoritmem Binary search on prefix length}
\end{algorithm}

\paragraph{Co zmínit}
- leaf-pushing?

\subsection{Hledání řetězců} % ###################################################################

Zjistit časovou a paměťovou složitost

V počítačových sítích je často vyžadováno hledání řetězců v síťovém provozu ať už z důvodu monitorování
nebo blokování provozu, který obsahuje určité řetězce. Blokování může probíhat na úrovni obsahu, například
blokování určitých webových stránek ať už z důvodů rodičovské kontroly nebo například omezení provozu
netýkajícího se výuky ve školních sítích. Dále může jít o blokování určitého druhu síťového provozu,
který obsahuje nedovolené nebo podezřelé signatury.

Hledání řetězců ověřování, zda se množina klíčových slov vyskytuje ve vstupních datech.
V případě počítačových sítí se vstupními daty rozumí obsah datových paketů a klíčovými slovy
signatury známých počítačových útoků a malware.

Pokud se oprostíme od počítačových sítí tak dalším využitím hledání řetězců může být například
vyhledávání klíčových slov v textových dokumentech, což byl prvotní impuls pro vznik
algoritmu autorů Aho a Corasickové, kteří tímto způsobem zrychlili prohledávání
textových dokumentů až $5\times$. Alternativou k algoritmu Aho-Corasick může být požadován
algoritmus autorů Rabin–Karp \cite{rabin-karp}, který má ovšem horší průměrnou časovou složitost, $O(m+n)$,
zatímco Aho-Corasick je tato složitost nejhorší možná. Algoritmem postaveným na Aho-Corasick
a Boyer–Moore \cite{boyer-moore}
je Commentz-Walter \cite{walter}, jehož časová složitost však v nejhorším případě dostahuje $O(m*n)$
důvodem pro vznik těchto algoritmů je hledání v textových datech. I z tohoto důvodu vznikl
algoritmus Aho-Corasick, který je v této knihovně implementován a původně byl navržen
právě pro hledání klíčových slov v odborných publikacích.

Pro hledání řetězců je implementován algoritmus autorů Aho a Corasickové. Tento algoritmus používá pro zjištění shody s podřetězcem konceptu konečného automatu. Při každé iteraci algoritmu se provede přechod o jeden znak.


Mějme definována klíčová slova \texttt{she} a \texttt{hi} a provádějme hledání těchto slov ve vstupních
datech \texttt{ship}.

\begin{table}[!htbp]
	\center
	\label{tab:pm-paper}
    \begin{tabular}{|l|p{8cm}|l|}
    \hline
    Aktuální symbol & Akce automatu & Výsledek \\ \hline
    s & přechod ze základního stavu do stavu [s] & - \\ \hline
    h & přechod ze stavu [s] do stavu [sh] & - \\ \hline
    i & neexistuje přechod z [sh] do [shi],
    vydá se failure cestou,
    kde existuje přechod z [h] do [hi] & Nalezeno slovo \texttt{hi} \\ \hline
    p & neexistuje přechod z [hi] do [hip],
    přechod do failure stavu,
    kterým je základní stav & - \\ \hline
    \end{tabular}
	\caption{Prohledávání algoritmem Aho-Corasick}
\end{table}


Algoritmus procházení vstupních dat je rozepsán v \ref{alg:aho} a vychází z \cite{aho}.

\begin{algorithm}
	\KwData{start-state, text}
	\KwResult{keyword}
	state = start-state\;
	\For{position $\leftarrow$ 0 \KwTo text.length}
	{
		\lWhile{goto(state, text[position]) == FAIL}{state $\leftarrow$ state.failure}
		\lIf{state.isMatch}{\Return state.keyword}
	}
	\Return NOT-MATCH\;
	\caption{Algoritmus procházení textu a hledání podřetězců}
\end{algorithm}\label{alg:aho}

Při chybě alokace se smaže celá struktura konečného automatu, neexistuje předpoklad na dynamické přidávání pravidel za běhu programu

\subsection{Hledání regulárních výrazů} % ############################################

Operace regulárních výrazů jsou následující

\begin{itemize}
	\item{$\emptyset$ je regulární výraz reprezentující prázdnou množinu}
	\item{$\epsilon$ je regulární výraz reprezentující $\{\epsilon\}$}
	\item{$a, a \in \Sigma$ je regulární výraz reprezentující $\{a\}$}
	\item{$(r \cdot s)$ je regulární výraz reprezentující $RS$}
	\item{$(r | s)$ je regulární výraz reprezentující $R \cup S$}
	\item{$(r*)$ je regulární výraz reprezentující R*}
 % todo zdroj https://books.google.cz/books?id=s7gEErax71cC&vq=determinization&hl=cs&source=gbs_navlinks_s
\end{itemize}

Znak operace konkatenace % TODO přidat referenci na item nahoře
se část vynechává a je uvažován implicitně.

Regulární výrazy implementované v této knihovně rozšiřují množinu operací tři nové druhy zápisu,
které jsou pouze pohodlněji zapsatelná a nijak nerozšiřují výrazové možnosti regulárních výrazů.

\begin{itemize}
	\item{$[abc]$ je výčet znaků, které se na vstupu mohou vyskytnout a automat je v aktuální stavu dokáže zpracovat. Je to zkrácený tvar zápisu $(a|b|c)$}
	\item{$a+$ je definováno jako pozitivní iterace, tedy $1..N$ opakování}
	\item{$a?$ je definováno jako $0..1$ iterací}
\end{itemize}

Regulární jazyky se podobně jako \ref{section:pm} používají pro monitorování a blokování dat procházejících
počítačovými sítěmi. Zařízení využívající těchto operací jsou typicky firewally, a to jak hardwarové tak i jejich
softwarové implementace.

Při chybě alokace se smaže celá struktura regulárního výrazu, neexistuje předpoklad na
dynamické přidávání regulárních výrazů za běhu programu.


Způsoby hledání regulárních výrazů existují tři:
nedeterministické konečné automaty $O(n*m)$
deterministické konečné automaty $O(n)$
delay dfa \cite{delay-dfa}

\subsection{Analýza a extrakce hlaviček paketů} % ###################################################

Extrakce hlaviček paketů je velmi častá operace.
V případě hledání nejdelšího shodného prefixu je potřeba nejprve provést extrakci
cílové adresy a až poté je možné zahájit vyhledávaní cesty, kterou bude paket směrován.
Z toho vyplývá přímá závislost rychlosti všech operací pracující s položkami hlavičky jak paketů
na úrovní síťové vrstvy \ref{layers:network} tak i rámců na úrovni linkové vrstvy \ref{layers:link}
a segmentů na úrovni transportní vrstvy \ref{layers:transport}.

V rámci výzkumu byly navrženy způsoby hardwarové akcelerace na zařízeních typu FPGA \cite{ant-phe}

V rámci LPM je stačí extrahovat pouze jednu položku IP hlaviček,
nicméně v obecné klasifikaci paketů jsou potřeba i další položky jako zdrojová adresa,
cílový port, typ transportního protokolu.



\chapter{Návrh API knihovny}\label{chapter:api} % #################################################################

Každá knihovna umožňuje pracovat s více objekty kdy kořen není uložen implicitně
uvnitř jednotlivých knihoven ale je navracen funkce pro inicializace a poté je explicitně
předáván do každé funkce, která s touto strukturou pracuje.

Knihovna \texttt{fastnet} je navržena jako množina menších knihoven, kde každá knihovna implementuje
jednu operaci používanou při zpracování síťového provozu.
Tímto návrhem je dosaženo snadné rozšiřitelnosti o další operace, jako například extrakce informací z hlaviček paketů
\i{Packet header extraction} nebo klasifikace paketů \texttt{packet clasification}.
Mezi implementované operace patří vyhledání nejdelšího shodného prefix \texttt{longest prefix match} \ref{},
hledání podřetězců \texttt{pattern matching} a regulární výrazy \texttt{regular expressions}.
Pro vyhledání nejdelšího shodného prefixu jsou implementovány algoritmy
\texttt{Binary search on prefix length}\ref{bspl} a \texttt{Tree Bitmap}\ref{tbm}.
Hledání podřetězců je implementováno algoritmem \texttt{Aho-Corasick}\ref{ac}.
Regulární výrazy jsou řešeny nedeterministickým i deterministickým konečným automatem.

Další výhodou tohoto rozdělení je možnost snadno vytvořit a používat jednotlivé pod-knihovny samostatně.
To se může hodit pro zařízení, která mají velmi limitované paměťové úložiště a jejich účelem
je řešit pouze jednu ze zmíněných operací.

Veřejné rozhraní knihovny se skládá z veřejných rozhraní jednotlivých podknihoven.
Tyto rozhraní jsou popsány v následujících podkapitolách.

\section{Klasifikace paketů} % #################################################################################

Pro klasifikaci paketů jsou navrženy čtyři základní funkce a jedna datová struktura.
Tato struktura je nazvána \texttt{pc\_set} a obsahuje položky \texttt{rule} pro uložení pravidla,
které bude odpovídat kombinaci ostatních položek, \texttt{dst} pro uložení cílové IP adresy,
\texttt{src} pro uložení zdrojové adresy, \texttt{protocol} pro uložení typu transportního protokolu,
tedy TCP nebo UDP a \texttt{port} pro uložení cílového portu.
Funkce pro práci se strukturou pro klasifikaci paketů jsou: \texttt{pc\_init} pro inicializaci
vyhledávacích struktur, \texttt{pc\_add} pro přidání klasifikačního pravidla, \texttt{pc\_update}
pro aktualizaci odpovídajícího pravidla, \texttt{pm\_remove} pro smazání odpovídajícího pravidla
a nakonec \texttt{pc\_destory} pro uvolnění veškeré paměti zabírané strukturami pro provádění klasifikace
paketů.

Všechny funkce mají svého dvojníka pro práci v adresy ve verzi IPv6 a liší se pouze prefixem,
kde místo \texttt{pm\_} mají \texttt{pm6\_}.

Každá funkce kromě \texttt{pc\_init} očekává jako první argument strukturu typu \texttt{pc\_root},
která obsahuje veškeré informace a konkrétních klasifikačních pravidlech. Jako u ostatních operací
je tato struktura osamostatněna a to umožňuje vytvářet více klasifikátorů v jednom programu.

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/phe/phe.h}
hlavičkové soubory jsou rozděleny na veřejné a privátní rozhraní, kde privátní rozhraní je používáno pouze uvnitř knihovny. Hierarchickou strukturu je možné vidět na obrázku \ref{fig:header-dependecies}.

Jako výchozí hlavičkový soubor je použit types.h, který obsahuje definice datových struktur pro všechny algoritmy v podknihovně, které musí být viditelné i z veřejného rozhraní. Dalším souborem je types-precompiled.h, který je generován z types.h při překladu když se vybírá používaný algoritmus. common.h je hlavičkový soubor společný pro všechny algoritmy v podknihovně a algorithm.h pak obsahuje deklarace právě pro jeden konkrétní algoritmus.
sublib.h je pak hlavičkový soubor, který tvoří veřejné rozhraní ke knihovním funkcím.

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/pc/pc.h}


\section{Vyhledání nejdelšího shodného prefixu}

Hledání nejdelšího shodného prefixu je rozděleno na operace nad verzemi IPv4 a IPv6.

Pro operaci vyhledání nejdelšího shodného prefixu jsou připraveny funkce pro inicializace datových struktur
\texttt{lpm\_init}, pro vložení nového prefixu \texttt{lpm\_add}, aktualizaci existujícího prefixu
\texttt{lpm\_update}, smazání existujícího prefixu \texttt{lpm\_remove} a zrušení všech alokovaných
datových struktur \texttt{lpm\_destroy}. Jak již bylo zmíněno je nutno uchovávat zvlášť tabulky
pro IPv4 a IPv6 adresy a z toho důvodu jsou existují všechny výše uvedené funkce i ve variantě
pro IPv6. Jediným rozdílem pak je že je všechny funkce a datové struktury mají místo prefixu
\texttt{lpm\_} prefix \texttt{lpm6\_}.

Všechny funkce kromě \texttt{lpm\_init} pracují s parametrem typu \texttt{lpm\_root}, který reprezentuje
celou datovou strukturu. Tato implementace vychází z požadavku mít možnost využívat více routovací
tabulek nebo tyto struktury využít pro jiné typy klasifikace.

Funkce pro vložení, smazání a aktualizaci pravidel a prefixů také obsahují parametr
prefix, který je buď IPv4 nebo IPv6 adresa. Dalším parametrem těchto funkcí je délka prefixu,
aby bylo možné odlišit jednotlivé prefixy od sebe. Tam může dojít ke kolizi pokud existuje
prefix $1*$ o délce jedna a prefix $10000*$ o délce pět, neboť tyto prefixu budou reprezentovány stejným
číslem, neboť v binární kódu máme pouze dvě hodnoty a není možné určit třetí stav jako X,
nezajímá nás/není důležité.

Funkce pro vložení prefixu pracuje s pouze s jedním prefixem a je prováděna okamžitě.
Tento návrh vychází z předpokladu, že knihovna bude používána i v prostředí s dynamickými routovacími
protokoly jako například RIP, OSPF nebo BGP, které při změně směrovacích informací v případě OSPF (zjistit jak to je)
zasílají aktualizace s novými informacemi na všechny sousední routery nebo jsou tyto změny zasílány periodicky
v případě protokolu RIP.

Hašovací funkce je v této implementaci použita Jenkins \cite{jenkins}. Volba správné hašovací funkce
má má velký vliv na rychlost vyhledávání. V případě kolizí je to omezeno zase na procházení lineárního
seznamu a z časové složitosti $O(\log{2}{N}$, kde N reprezentuje délku adresy, tedy 32 nebo 128 bitů,
se stává $O(N)$, kde N reprezentuje počet záznamů routovací tabulky.

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/lpm/lpm.h}
Specifikaci datových struktur lze nalézt v soubor \texttt{/lib/src/lpm/types.h}


\section{Hledání řetězců} % #####################################################################################

Tak jak jsou regulární výrazy implementovány tak jsou case-sensitive, to je možné změnit
přidáním volání ischar a tolower při vytváření a procházení výrazů

Pro hledání řetězců jsou podobně jako pro vyhledání nejdelšího shodného prefixu implementovány
funkce pro inicializaci datové struktury \texttt{pm\_init}, vložení klíčových slov do
dané struktury \texttt{pm\_add}, změnu pravidla odpovídající danému klíčovému slovu
\texttt{pm\_update}, smazání klíčového slova \texttt{pm\_remove} a funkce pro uvolnění
paměti alokované pro vyhledávání \texttt{pm\_destroy}.

Všechny výše zmíněné funkce očekávají jako první parametr strukturu typu \texttt{pm\_root},
která je základním prvkem pro vyhledávání a právě do této struktury
jsou uložena všechna klíčová slova a jejich pravidla. Důvodem proč tato struktura není globální
proměnnou uvnitř knihovny je požadavek na možnost mít více prohledávacích struktur
a mít možnost explicitně zvolit oproti jaké struktuře klíčových slov se budou vstupní data porovnávat.

Hledání podřetězců \texttt{pm\_match} skončí svůj průchod konečný automatem v momentě nálezu první shody
s libovolným podřetězcem zadaným při volání \texttt{pm\_add}. Vpřípadě, že není nalezena žádná shoda
se vstupními podřetězci je vrácen výsledek \texttt{false}.

Čtvrtým parametrem funkce \texttt{pm\_match} může být \texttt{NULL} nebo odkaz na datovou strukturu
\texttt{pm\_result}. V případě \texttt{NULL} argumentu již nelze procházet textem a hledat další shody.
Pokud je zadán odkaz na existující strukturu \texttt{pm\_result} je možné procházet celým textem a ukládat
všechny nalezené shody s podřetězci. Jednotlivé položky struktury \texttt{pm\_result} jsou.

Pro uložení výsledků procházení textu je možné používat různé proměnné typu \texttt{pm\_result}
a je jen na programátory konkrétní aplikace jaký postup zvolí.

Pro práci se strukturou \texttt{pm\_result} jsou v knihovně \texttt{pm} implementovány následující operace:
\texttt{pm\_result\_init} pro vytvoření této struktury a \texttt{pm\_result\_destroy} pro
uvolnění paměti alokované pro tuto strukturu. Položkami této struktury jsou údaje o pozici v textu,
kde bylo nalezena klíčová slova uložená v položce \texttt{rule} o velikost \texttt{count},
aktuální stav, ve které se konečný automat nachází a to z důvodu možného volání
\texttt{pm\_match\_next}, kdy vyhledávání naváže na místě kde předchozí vyhledávání skončilo.

Pro vkládání podřetězců je vytvořena vlastní datová struktura, a pole těchto struktur je předáváno do funkce
\texttt{pm\_add}. Důvodem pro tuto implementaci namísto přidávání jednotlivých podřetězců samostatně
je relativně časově náročné procházení stavového automatu a generování tzv. failure přechodů,
které je nutné provést po každé změně datové struktury.

Funkce \texttt{pm\_add} očekává jako druhý parametr pole struktur \texttt{pm\_keyword}, kde každá struktura
obsahuje položky vstupního klíčové slova v binární podobě, délku tohoto slova a pravidlo odpovídající tomuto slovu, oproti kterým se budou porovnávat vstupní data. Důvodem proč je předáváno pole dat a ne jednotlivé položky
jako u hledání nejdelšího shodného prefixu je z důvodu neexistence synchronizační mechanismů
v prostředí IPS a IDS. Dalším důvodem pro tento návrh je časově náročná funkce generování
tzv. failure přechodů, které umožňují detekovat kratší klíčové slovo i v případě, že již je
zahájeno porovnávání delšího slova jak je možno vidět na následujícím příkladu.

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/pm/pm.h}
Specifikaci datových struktur lze nalézt v soubor \texttt{/lib/src/pm/types.h}

\section{Hledání regulárních výrazů}  % #####################################################################################
Tak jak jsou regulární výrazy implementovány tak jsou case-sensitive, to je možné změnit
přidáním volání ischar \& tolower při vytváření a procházení výrazů

Knihovna \texttt{regex} implementující regulární výrazy nabízí dvě možnosti pro procházení
vstupních dat a to deterministický \texttt{dfa} a nedeterministický konečný automat \texttt{nfa}.
Z toho důvodu jsou odlišeny všechny funkce dle typu konečného automatu, který je použit.
Oproti hledání nejdelšího shodného prefixu \ref{} nejsou tyto implementace od sebe odlišeny
různými soubory neboť deterministické automaty vycházejí z nedeterministický a pouze používají
determinaci.

Pro nedeterministické konečné automaty to jsou následující funkce.

Pro deterministické konečné automaty jsou to tyto funkce.
% REGEXDFA =================================================================================

Pro vytvoření regulárních výrazů je podobně jako u hledání podřetězců \ref{}
použita pomocná struktura \texttt{regex\_pattern}, která je předávána do funkcí \texttt{regex\_[nfa|dfa]\_construct}.
Výsledný konečný automat, ať už deterministický nebo nedeterministický je výsledek spojení jednotlivých
konečných automatů pro každý regulární výraz. Tím je umožněna detekce shody několika
regulární výrazů v jednom průchodu vstupními daty i s přesnou identifikací jaký regulární
výraz se shoduje se vstupními daty. To je také jedním z důvodů proč nejsou použity regulární výrazy ze standardní
knihovny jazyka C.
Další důvody pro vlastní implementaci regulární výrazů je možnost zvolit nejvhodnější algoritmus pro danou operaci.
Mějme na paměti že determinizací může dojít až k exponenciální nárůstu stavů konečného automatu, což může problém
zvláště při použití specializovaných HW implementací, kde je možno narazit na paměťové limity.
Dalším důvodem je převod implementace do akcelerovaného hardware.

%REGEX PATTERN =================================================================================

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD v souboru \texttt{/lib/src/regex/regex.h}
Specifikaci datových struktur lze nalézt v soubor \texttt{/lib/src/regex/types.h}

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=.25]{fig/header-dependencies.pdf}
	\caption{Diagram závislostí hlavičkových souborů}
\end{figure}\label{fig:header-dependecies}

\section{Analýza a extrakce hlaviček paketů - Header parsing} % ##############################################################################

V knihovně je již navrženo API pro operaci extrakci informací z hlaviček paketů. Tyto
funkce ovšem nejsou implementovány


Funkce dokáže zpracovat variabilní počet argumentů.
Hodnotami pro variabilní argumenty jsou hodnoty typu \texttt{enum}, kde každá hodnot odpovídá
právě jedné položce hlavičky IP paketu a její číselná hodnota odpovídá počtu bytů
od začátku datové struktury IP paketu.

Pro nejefektivnější zpracování je nutné volit pořadí těchto parametrů stejné jako je jejich reálná
posloupnost ve struktuře paketu.

V případě hardwarové akcelerace této operace je pak možné zvolit přístup takový,
že první parametr bude obsahovat reálnou vzdálenost od začátku paketu a každý další parametr
pak bude obsahovat pouze reálnou vzdálenost od předcházejícího parametru. Tento rozdíl
půjde snadno vypočítat jako rozdíl aktuálního parametru a předchozího parametru.
Některé základní položky využívané při klasifikaci paketů a jejich vzdálenosti v bytech
jsou uvedeny v tabulce \ref{tab:phe}

\begin{table}[!htbp]
	\center
	\label{tab:phe}
    \begin{tabular}{|l|l|l|}
    \hline
    Význam & Název & offset \\ \hline
    Verze & IP\_VERSION & 0 \\ \hline
    Zdrojová IP adresa pro IPv4 & IP\_SRC & 12 \\ \hline
    Cílová IP adresa pro IPv4 & 8 IP\_DST & 16 \\ \hline
    Cílový port pro IPv4 & PORT\_DST & 22 \\ \hline
    Protokol pro IPv4 & PROTO & 8 \\ \hline
    \end{tabular}
	\caption{Položky IP paketu a jejich pojmenování pro extrakci a analýzu}
\end{table}

\texttt{phe\_item} je struktura typu union, kde jsou všechny položky uloženy na stejném paměťovém místě
a jejich interpretace je odvozená dle typu položky, ke které je přistoupeno.

Navržené funkce nesou názvy \texttt{phe\_get} pro práci s pakety IPv4 a \texttt{phe6\_get}
pro práci s pakety IPv6.

Tyto funkce očekávají jako první argument ukazatel na vstupní data a jako druhý parametr
ukazatel na pole enumů typu \texttt{phe\_item}. Způsob zpracování je navržen takový
že všechny položky budou ukládány do největší položky daného enumu a je pak na programátorovy
využívající volání těchto funkcí aby věděl, jaké velikosti je daná položka ve struktuře paketu
a podle toho přistupoval ke správným položkám enumu \texttt{phe\_item}, případně phe6\_set,
která pouze rozšiřuje položku ip adresy na velikost potřebnou pro uložení IPv6 adresy

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/phe/phe.h}


\section{Použití knihovny} % #####################################################################################
Celou knihovnu je možné sestavit příkazem \texttt{make all} v hlavním adresáři knihovny.
Při tomto příkazu bude celá knihovna sestavena s definovaným NDEBUG, což má za následek vypuštění všech
volání funkce assert, která slouží pro ověřovaní správné funkčnosti.

Dalšími Cíly pro program \texttt{make} jsou

\begin{itemize}
	\item{\texttt{test} - spustí automatické testování všech částí knihovny}
	\item{\texttt{bech} - spustí benchmarky všech částí knihovny}
	\item{\texttt{doc} - vygeneruje programovou dokumentaci ke všem částem knihovny}
	\item{\texttt{clean} - smaže všechny soubory vytvořené překladem}
\end{itemize}

\section{Rozšíření knihovny} % #####################################################################################

Pro rozšíření knihovny je nutné přidat knihovnu implementující danou operaci
do adresáře \texttt{lib/src} a upravit příslušný soubor \texttt{Makefile} v daném adresáři.
Dále je vhodné vytvořit testovací program a sadu testů, kterou je možné automatizovaně spouštět a vyhodnocovat.
Tyto soubory pak umístit do adresáře \texttt{lib/test/<operace>}.
Další vhodnou součástí knihovny operace je benchmark pro vyhodnocení rychlosti/paměťové náročnosti jednotlivých
implementací dané operace.



\chapter{Výsledky}\label{chapter:results} % ##########################################################################
Tato kapitula shrnuje a vizualizuje dosažené výsledky při implementaci jednotlivých knihoven.
Benchmarky pro architekturu Intel proběhly na operačním systému Archlinux \footnote{https://www.archlinux.org/} s procesorem Intel(R) Core(TM) i3-2310M CPU @ 2.10GHz.

\section{Hledání nejdelšího shodného prefixu - Longest prefix matching}\label{section:results-lpm} % ####################################################################

Hledání nejdelšího shodného prefixu bylo testováno na celkem pěti vstupních sadách dat, které
byly převzaty z volně dostupných dat RIPE\footnote{https://www.ripe.net/}.
Informace o testovaných sadách dat jsou zobrazeny v tabulce \ref{tab:lpm-input}.

\begin{table}[!htbp]
	\center
	\label{tab:lpm-input}
    \begin{tabular}{|l|l|l|l|}
    \hline
    Počet adres & Nejkratší prefix & Nejdelší prefix & Verze IP \\ \hline
    $1000$ & 13 & 31 & IPv4 \\ \hline
    $10000$ & 8 & 32 & IPv4 \\ \hline
    $100000$ & 8 & 32 & IPv4 \\ \hline
    $1000$ & 23 & 128 & IPv6 \\ \hline
    $10000$ & 19 & 128 & IPv6 \\ \hline
    \end{tabular}
	\caption{Informace v routovací tabulce pro benchmarky}
\end{table}

Důvod proč není benchmark pro IPv6 se 100 000 záznamy ve směrovací tabulce je ten, že se mi nepovedlo
sehnat směrovací tabulku takové velikosti
Vyhledávání pak bylo testováno oproti sadě velikost $1000$ odpovídající verze IP, která je podmnožinou každé
rozsáhlejší sady dat.

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=1]{fig/lpm-ipv4.pdf}
	\caption{Benchmark pro IPv4}
\end{figure}\label{fig:lpm-ipv4}

Testováno bylo jak TreeBitmap ve všech variantách velikosti střídy, tedy $1-8$.
Jak je vidět na následujících grafech, tak nejlepších výsledků bylo dosaženo pro TreeBitmap s velkostí
střídy nastavenou na $5$ bitů a to jak pro IPv4 tak i pro IPv6.

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=1]{fig/lpm-ipv6.pdf}
	\caption{Benchmark pro IPv6}
\end{figure}\label{fig:lpm-ipv4}

Pro testování algoritmu Binary search on prefix length byla zvolena velikost hašovací tabulky
stejná jako velikost směrovacích dat. Tento přístup byl zvolen z důvodu významného vlivu
velikosti hašovací tabulky na rychlost samotného vyhledávání. V nejhorším případě, tedy při
velikosti hašovací tabulky $100$ byl algoritmus pomalejší pro hledání v tabulce se $100 000$ záznamy pomalejší
$400\times$.
U algoritmu bspl je doba vyhledání prefixu velice závislá na velikosti hašovací tabulky a proto je vhodné odhadnout počet záznamů tabulky alespoň řádově a dle toho pak nastavit velikost konstantu {\tt \_HTABLE\_SIZE} v souboru bspl.h na hodnotu, která alespoň řádově odpovídá předpokládané velikosti hašovací tabulky.

Dalším důležitým faktorem pro efektivnost implementace je velikost datových struktur, která je znázorněna v následující tabulce.

\begin{table}[!htbp]
	\center
	\label{tab:lpm-input}
    \begin{tabular}{|l|l|l|l|}
    \hline
    Velikost střídy & počet bytů \\ \hline
    1 & 24 \\ \hline
    2 & 24 \\ \hline
    3 & 24 \\ \hline
    4 & 24 \\ \hline
    5 & 32 \\ \hline
    6 & 40 \\ \hline
    7 & 64 \\ \hline
    8 & 112 \\ \hline
    \end{tabular}
	\caption{Velikosti datových struktur pro TreeBitmap}
\end{table}

Pro Binary search on prefix length pak bude velikost jednoho prvku stromu činit $48B$.
Pokud by došlo k rozdělení datových struktur pro jednotlivé verze IP protokolu
tak verze pro IPv4 by měla velikost $36B$.

Jak je vidět ve výše uvedené tabulce tak i přestože nejrychlejší implementací je TreeBitmap s střídou 5,
tak v případě omezené paměti by bylo vhodnější zvolit kompromis mezi rychlostí a paměťovou náročností v podobě
TreeBitmap s velikostí střídy 4. Dalším ovlivňujícím faktorem je odhadovaný počet záznamů směrovací tabulky, protože
nejrychlejší TBM-5 při existenci všech struktur na všech úrovních bude činit rozdíl zabraného místa oproti TBM4
celých $TODO dopočítat KB$, což je v kontextu FPGA případně ASIC implementace nezanedbatelné množství.

Také je důležité zmínit že z počtu očekávaných vstupních pravidel má také vliv na velikost struktury.
Do 256 záznamů zabírá pravidlo pouze 1byte, do 65536 záznamů pak 2 byty a pro více než 65536 pak celé čtyři byty pro uložení právě jednoho pravidla. Při uložení $65536$ adres to bude rozdíl mezi uložením $65537$ bude rozdíl činit
$200KB$


\section{Hledání řetězců - Pattern matching} % #####################################################################################
Jak je možné vyčíst z grafu \ref{fig:pm} tak klíčová slova s vyšším výskytem společných písmen
mají delší dobu procházení. To vyplývá principu reakce na nenalezený další znak klíčového slova,
kdy dochází k cyklickému procházení tzv. failure přechodů dokud není nalezena cesta, kterou se je
možno vydat. To je v nejhorším případě právě kořen klíčových slov, který obsahuje cestu
pro každý symbol vstupní abecedy. V případě že takovým symbol není první písmeno
existujícího klíčového slova dojde k přechodu sám do sebe, což umožňuje zpracovat
právě jeden znak ze vstupních dat.

Dopsat na jakých datech byl benchmark proveden
\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=0.7]{fig/pm.pdf}
	\caption{Benchmark pro knihovnu pm}
\end{figure}\label{fig:pm}

\section{Hledání regulárních výrazů - Regular expression matching} % ###############################################################################

Jak je vidět na v grafu \ref{fig:regex} tak hledání regulárních výrazů pomocí deterministického
konečného automatu je řádově pomalejší. Toto zpomalení je způsobené opakovaným generování
epsilon přechodů pro všechny vstupní stavy. Vstupní stavy jsou na začátku procházení
startovní stavy všech výrazů, které byly předány do funkce \texttt{regex\_construct\_nfa}.

Procházení založené na deterministickém konečném automatu tímto problémem netrpí,
neboť při zpracování každého vstupního symbolu dojde k přechodu do dalšího stavu v případě
vstupního symbolu, který se může vyskytnou v aktuálním stavu automatu nebo do počátečního stavu
pokud vstupní symbol nejde zpracovat v rámci regulárního výrazu.

Dopsat na jakých datech byl benchmark proveden

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=0.7]{fig/regex.pdf}
	\caption{Benchmark pro knihovnu regex}
\end{figure}\label{fig:regex}

\chapter{Závěr}\label{chapter:conclusion} % ########################################################################
Cílem této práce bylo popsat a navrhnout aplikační programové rozhraní časově kritické operace v oblasti počítačových sítí,
konkrétně vyhledání nejdelšího shodného prefixu za využití algoritmů Binary search on prefix length
a TreeBitmap. Operace používané na směrovačích pro zjištění jakou cestou směrovat přicházející pakety.
Dalšími operacemi jsou hledání řetězců a hledání regulárních výrazů v paketech a jejich datech.
Pro operaci hledání řetězců je to konkrétně algoritmus Aho-Corasick \cite{aho} umožňují v
při jednom průchodu vstupními daty vyhodnotit zda se v datech nacházejí specifikovaná klíčová slova
a poté hledání regulárních výrazů. Obě zmíněné operace jsou používané v paketových filtrech,
které tvoří jádro systémů pro detekci útoků (IDS) a prevenci útoků (IPS). Do skupiny těchto
systémů patří firewally jak softwarové tak hardwarové. Mezi další operace operace pak patří
analýza a extrakce hlaviček paketů a obecná klasifikace paketů.

Dále je to pak implementace operací hledání nejdelšího shodného prefixu, hledání řetězců
a hledání regulárních výrazů. Při implementaci bylo dosaženo rychlosti zpracování N paketů za sekundu
při velikosti $100000$ záznamů routovací tabulky pro IP adresy verze 4 a N paketů/sekunda při velikosti
routovací tabulky $10000$ pro IP adresy verze 6. Pro operaci hledání podřetězců bylo
do dosaženo rychlosti zpracování N paketů za sekundu v závislosti na počtu shodných písmen
při lineární náročnosti v závislosti na velikost dat v paketech. Experimentování bylo prováděno
na vzorku dat odchycených ze standardního síťového provozu jednoho osobního počítače. Jako vzorek
testovaných klíčových slov bylo využito klíčových definovaných pro HTTP\footnote{Hyper-text transfer protocol}.
Pří experimentování s regulárními výrazy byly jako vstupní data použita stejná data jako pro hledání řetězců,
ale jako regulární výraz byly použity matchování URL\footnote{Uniform resource locator} adres.

Jako kroky navazující na tuto práci je možné implementovat zbývající operace, které implementovány nebyly.
Těmito operacemi je klasifikace paketů a analýza a extrakce hlaviček paketů.

Ze specifikace požadavků na implementaci knihovny v nízkoúrovňovém jazyce C je zřejmé,
že knihovna bude používána i na vestavěných systémech disponujících omezenou pamětí a z toho
důvodu by jedním z dalších kroků mohlo být formální testování s nedostatkem paměti.
To by mohlo dát rozsahem na celou další práci. Je nutné ověřit, že knihovna bude
reagovat správným způsob a nezpůsobí pád systému v rámci kterého je spouštěna.

zmínit někde vláknové zpracování
