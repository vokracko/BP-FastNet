%=========================================================================

\chapter{Úvod} % #####################################################################################

Žijeme v době kdy se internet stal nedílnou součástí každodenního života a s internetem už nepracují
pouze klasické počítače, ale do popředí se také dostávají mobilní zařízení, které meziročně
zaznamenávají více než $50\%$ nárůst. Dalším druhem zařízení jež se začínají připojovat
jsou vestavěné systémy patřící do trendu nazývaného internet věcí.
S rychlostí jakou přibývají zařízení vyžadující přístup k internetu ale i s jeho rozšiřováním
do zemí zatím nedotčených se neustále zvyšují požadavky na rychlost, se kterou data prochází počítačovými
sítěmi a z toho vyplývající požadavky na rychlost zpracování síťového provozu a to zejména na zařízeních
starajících se o řízení internetového provozu na páteřních linkách. Mezi tyto
zařízení lze zařadit směrovače (routery), které řídí datové toky mezi jednotlivými sítěmi,
přepínače (switche) starající se o řízení toků dat uvnitř autonomních sítí a
systémy pro detekci (IDS\footnote{Intrusion detection system}) a prevenci (IPS\footnote{Intrusion prevention system})
síťových útoků, které analyzují obsah každého paketu procházejícího sítí.

Páteřní spoje v době psaní této práce dosahují rychlostí v řádech desítek gigabitů
za sekundu a z toho vyplývají požadavky na rychlost zpracování síťových dat. Při těchto rychlostech
jsou tradiční procesory schopny vykonat pouze desítky instrukcí, což nestačí na provedení všech potřebných
operací. Nicméně je důležité aby stejné rychlosti zpracování dosahovaly všechna zařízení na páteřních spojích,
protože počítačová sít je pouze tak rychlá, jak rychlá je její nejpomalejší část, tzv. úzké hrdlo.

Z těchto vlastností vycházejí požadavky na stále efektivnější algoritmy zpracovávající časově kritické operace.
Časově kritické operace jsou takové operace, jež při zpracování síťového provozu trvají nejdelší dobu a rozbor
těchto operací je součástí této práce. Z těchto operací jsou vybrány a rozvedeny operace
hledání řetězců a regulárních výrazů, analýza a extrakce hlaviček paketů a klasifikace paketů, speciálně pak jednodimenzionální klasifikace dle cílové IP adresy, hledání nejdelšího shodného prefixu.

Přínosem této knihovny je vlastní implementace zmíněných časově kritických operací, která bude
využita výzkumnou skupinou ANT na Fakultě Informačních technologií Vysokého učení technického v Brně
pro vytváření bezpečnostních aplikací a systémů.
Pro knihovnu je navržen a implementován obecný princip vláknového zpracování použitelný pro všechny
zmíněné operace, který umožňuje řetězit požadavky na zpracování do vyrovnávacích pamětí a jednotlivé operace
provádět plynule za sebou bez nutnosti zasahovat do datových struktur nebo toku řízení.

V kapitole \ref{chapter:theoretical} jsou popsány síťové modely a vrstvy těchto modelů,
nad nimiž jsou operace této knihovny implementovány, dále jsou popsány časově kritické operace prováděné
prvky v počítačových sítích. Kapitola \ref{chapter:api} popisuje návrh veřejného rozhraní vytvořené knihovny
pro operace zmíněné v kapitole \ref{chapter:theoretical}, způsoby použití této knihovny a možnosti rozšíření
o další časově kritické operace. V kapitole \ref{chapter:results} jsou vizualizovány a diskutovány
výsledky, jichž se podařilo dosáhnout v implementaci této knihovny a to na dvou hlavních platformách, Intel a ARM.
Kapitola \ref{chapter:conclusion} shrnuje dosažené výsledky a nastiňuje další možný vývoj této knihovny
a to jak z hlediska rozšiřování repertoáru implementovaných operací tak i z pohledu dalších optimalizací
a testování ve scénářích odpovídajících používání knihovny v reálných systémech.

\chapter{Teoretický rozbor}\label{chapter:theoretical} % ###########################################################

Tato kapitola poskytuje teoretické informace ze kterých vychází další kapitoly.
V první části je popsán síťový model ISO/OSI a jeho vrstvy důležité z pohledu této práce.
V druhé části jsou pak podrobněji rozebrány jednotlivé časově kritické operace a největší důraz je
kladen na jednodimenzionální klasifikaci paketů, vyhledání nejdelšího shodného prefixu.


\section{Síťové modely}\label{section:models} % #######################################################################
Zpracování dat síťového provozu je rozděleno do několika úrovní. Tyto úrovně jsou popsány síťovými modely.
Základním modelem je ISO/OSI, který slouží pro abstraktní rozdělení operací zpracování síťových dat a využití
našel pouze v akademické sféře. V reálných počítačových sítích pak dominuje model TCP/IP, který má oproti
ISO/OSI modelu menší počet vrstev. Model ISO/OSI je rozdělen na sedm vrstev. V pořadí od nejnižší úrovně to
jsou vrstvy fyzická, linková, síťová, transportní, relační, prezentační a aplikační. Pro tuto práci jsou
podstatné pouze první čtyři vrstvy. Ty jsou detailněji popsány v následující části. Na obrázku \ref{fig:layers} je
znázorněn průchod jednoho datového paketu odeslaného ze stanice A s cílovou adresou stanice B jednotlivými vrstvami modelu ISO/OSI. Jak je z obrázku patrné tak různé druhy síťových zařízení pracují s různými vrstvami.

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=.25]{fig/layers.pdf}
	\caption{Znázornění průchodu dat počítačovou sítí v modelu ISO/OSI}
    \label{fig:layers}
\end{figure}

\begin{description}
\item[Fyzická vrstva / Vrstva síťového rozhraní]\label{layers:physical} % ##################################
je nejnižší vrstva ISO/OSI modelu a pracuje s daty na úrovni bitů. Stará se o
jejich přenos po přenosovém médiu. Protokoly této vrstvy definují signály reprezentující data
a tudíž jde o protokoly implementované již v hardware síťových zařízení.

\item[Linková vrstva]\label{layers:link} % ###################################################################
je druhá nejnižší ISO/OSI modelu. Tato vrstva se stará o datovou komunikaci
obecně mezi několika uzly, které jsou přímo spojeny. Spojení může být jak fyzickým vodičem tak i
bezdrátovou technologií. Nejrozšířenější technologií pro fyzické spoje je Ethernet IEEE 802.3 a pro bezdrátové spoje
je to standard IEEE 802.11. Datová jednotka na linkové vrstvě se nazývá rámec a nese v sobě kromě
zapouzdřených dat vyšších vrstev také informace o kontrolním součtu dat a adresování pomocí MAC adres.
MAC adresa je adresa fyzického zařízení, které pracuje na této vrstvě.
Adresování MAC adresou slouží pro identifikaci zařízení, které se nacházejí ve stejné počítačové síti
a za hranici této sítě se již používá IP adresace, která je vysvětlena v následujícím odstavci.
Síťová zařízení pracující na této vrstvě se nazývají přepínače (angl. \textit{switch}).
Úkolem přepínačů je odeslat vstupní data portem, který vede k cílovému zařízení.

\item[Síťová vrstva]\label{layers:network} % ###############################################################
se stará o adresaci zařízení připojených do internetu pomocí síťových adres a o směrování paketů.
Nejrozšířenějším protokolem této vrstvy je protokol IP, jež existuje ve dvou verzích a to IPv4 a IPv6.
Síťová vrstva umožňuje komunikovat zařízením, které nejsou spojeny přímo, ale existuje mezi nimi jedna nebo více cest.
Prvky pracující na této vrstvě jsou nazývány směrovače (angl. \textit{router}) a pracují s datovou strukturou zvanou
datagramy, jež obsahují právě IP adresy jednoznačně určující zdrojové a cílové zařízení. Směrování paketů
je věnována kapitola \ref{section:lpm}

\item[Transportní vrstva]\label{layers:transport} % #########################################################
umožňuje adresovat aplikace zodpovědné za přenášená data. Datová struktura této vrstvy
je nazývána segment. Mezi dominujíci protokoly patří TCP a UDP. Hlavním rozdílem mezi těmito protokoly
je zaručení spolehlivého doručení a vytváření trvanlivých spojení, které poskytuje pouze TCP.
UDP naopak spolehlivé doručení negarantuje, ale díky tomu je tento protokol jednudušší.
Situace ve kterých pozitiva jako
nižší režie přebijí zápory je hlavně přenos dat v reálném čase. To je například streamování videa,
přenos hlasu technologie VoIP nebo přenos informací do online her.
Zpracování dat na úrovni transportní vrstvy a všech vyšších vrstev není implementováno na síťových
zařízeních starajících se přenos dat po síti. Jediná zařízení, které implementují zpracování
dat těchto vrstev jsou koncová zařízení.

\end{description}

\section{Časově kritické operace} % ############################################################################
Pod pojmem časově kritické operace se rozumí takové operace, které zabírají nejvíce výpočetního
času při zpracování jednoho paketu a typicky je nutné provádět je na více síťových zařízeních.
Těmito zařízeními mohou být směrovače, přepínače, firewally a také systémy
oddělené od řízení síťového provozu jako například sondy pouze monitorující síťový provoz nebo analyzátory,
které mohou hledat signatury útoků v datových tocích.

Mezi časově kritické operace rozebrané v této práci patří klasifikace paketů a velký důraz je kladen na
jednodimenzionální klasifikaci dle cílové IP adresy, vyhledávání nejdelšího shodného prefixu.
Tato operace je využívána pro prohledávání směrovací tabulky směrovačů pro určení nejvhodnější cesty jakou
bude paket pokračovat při své cestě k cílovému zařízení.
Další z operací je analýza a extrakce hlaviček paketů, která je využívána v již zmíněné klasifikaci,
kde je nutné z hlavičky paketu extrahovat všechny informace dle kterých bude paket klasifikován.
Dalšími z rozebíraných operací je hledání řetězců a hledání regulárních výrazů.
Poslední dvě zmíněné operace slouží především pro detekci útoků v systémech IDS (z angl. \textit{intrusion detection system})
a pro prevenci útoků v systémech IPS (z angl. \textit{intrusion prevention system}). Jedná se o operace sloužící
pro hloubkové prohledávání paketů (angl. \textit{Deep Packet Inspection}). Toto prohledávání na rozdíl od ostatních operací
pracuje s datovým obsahem paketů a ne jenom s hlavičkami paketu. Z toho vychází časová náročnost,
neboť místo vyhodnocení hlavičky paketu jež čítá 19 bytů pro IPv4 a 40 bytů pro IPv6 je nutno
projít veškerá data, jejichž velikost se typicky pohybuje v rozmezí $1 - 1500B$.

\subsection{Klasifikace paketů}

Klasifikace paketů je operace rozhodující o dalším zpracování paketu.
Výsledkem klasifikace pak může být rozhodnutí, zda daný paket může projít do
dalšího vyhodnocování nebo zda pochází nebo směřuje do sítě jež není dovolena.
Této klasifikace se využívá například pro povolení pouze určitého rozsahu zdrojových IP adres
pro omezení přístupu do podnikové sítě nebo pro blokování paketů snažících se přistupovat
ke službám jež jsou zakázány.

Data využívané pro klasifikaci se skládají z ntice položek hlavičky paketu, pravidla a priority.
Nejčastěji využívanou klasifikací je klasifikace skládající se z pětice položek IP hlavičky
a to zdrojové adresy, cílové adresy, zdrojového portu, cílového portu a protokolu transportní vrstvy.
Obsahem klasifikačních pravidel pak mohou být přesně specifikované hodnoty, rozsahy nebo prefixy.
Prefixy jsou obecnějším zápisem specifických hodnot i rozsahů, neboť rozsah lze přepsat v nejhorším
případě na $2N - 2$ prefixů \cite{clasification-prefix}, kde N odpovídá počtu bitů reprezentující rozsah. V případě specifické hodnoty
je to prefix pouze jeden o bitové délce stejné jako reprezentovaná hodnota.

Klasifikace je prováděna jako vyhledání každé definované položky v množině reprezentující hodnoty
této položky a poté výběr pravidla s nejvyšší prioritou z kartézského součinu těchto množin.

Tato práce se zabývá pouze jednodimenzionální klasifikací založenou na cílové IP adrese, hledání
nejdelšího shodného prefixu, operace sloužící pro prohledávání směrovacích tabulek směrovačů,
rozvedené v následující kapitole.

\subsection{Hledání nejdelšího shodného prefixu}\label{section:lpm} % #######################################
Problém hledání nejdelšího shodného prefixu se rozumí jednodimenzionální klasifikace paketů dle
jejich cílové IP adresy, která může být jak verze 4, tak verze 6.
Hledání nejdelšího shodného prefixu je operace, která je prováděna
na síťových prvcích zvaných směrovače. Tyto prvky jsou umístěny na každém rozhraní dvou a více
počítačových sítích. Jejich cílem je nalézt nejvhodnější cestu, kterou směrovat příchozí paket.
Struktura reprezentující uložené směrovací informace se nazývá směrovací tabulka.
Tato tabulka ukládá informace o dostupných sítích (jejich prefixech), délce tohoto prefixu a rozhraní,
kterým se lze do odpovídající sítě dostat. Příklad směrovací tabulky je zobrazen v tabulce \ref{tab:routing-table}

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|}
    \hline
    Prefix        & Délka prefixu & Rozhraní \\ \hhline{|=|=|=|}
    147.228.0.0   & 14            & eth0       \\ \hline
    147.228.128.0 & 17            & eth0       \\ \hline
    \end{tabular}
    \caption{Příklad směrovací tabulky}
    \label{tab:routing-table}
\end{table}

S velkým rozmachem počítačových sítí v poslední dekádě dochází k velkému nárůstu směrovacích informací a
pro zmenšení směrovacích tabulek byl navržen takzvaný supernetting, který agreguje směrovací záznamy
sdílející stejné rozhraní a mající společnou část prefixu do jednoho záznamu.
Pokud vezmeme v úvahu výše uvedenou tabulku tak při použití supernettingu by byly oba záznamy sloučeny
v jeden, který by vypadal takto: $147.228.0.0/14, eth0$.
Tím je dosaženo zmenšení směrovacích tabulek, nicméně i s využitím supernettingu zůstává hledání nejdelšího shodného
prefixu časově kritickou operací.
Pro snadnější porozumění bude v následující části používán binární zápis prefixů.

Prefix ve směrovací tabulce je reprezentován jako posloupnost nul a jedniček s hvězdičkou na konci,
která značí že všechny adresy, jejichž začátek je shodný s částí před hvězdičkou, odpovídají tomuto prefixu.
Jako příklad mějme prefix $A = 1001*$ jež odpovídá adresám začínajícím $1001$, tedy $10010*$ i $10011*$.
Nicméně ve směrovací tabulce může být uložen i prefix B $10010*$, který sdílí první čtyři bity své adresy
s výše uvedeným prefixem A a v případě, že přijde paket začínající hodnotou $10010$ je z pohledu směrování
nutno vyhodnotit prefix B jako nejdelší shodný a poté paket správně směrovat. V případě $10011$ je však nejdelším
shodným prefixem pravidlo A a tudíž nesmí dojít k vyhodnocení prefixu B jako nejdelšího.
Z toho důvodu je nutné ve směrovací tabulce uchovávat i informace o délce prefixu.
Tato informace poté slouží pro rozhodnutí, jaké pravidlo směrovací tabulky odpovídá nejdelšímu shodnému prefixu.
Délka prefixu může nabývat hodnot $1-32$ pro adresy typu
IPv4 a $1-128$ pro adresy typu IPv6.
Z výše uvedených informací a příkladů vyplývá,
že je nutné rozlišovat zda existující prefix reprezentuje adresu verze IPv4 nebo IPv6,
jinak by mohlo docházet k vyhodnocení nejdelšího shodného prefixu pro adresu IPv4
jako jiný prefix verze IPv6, což by mělo za následek nevalidní směrování paketů.
Jako příklad může sloužit následující směrovací tabulka, ve které je první pravidlo
verze IPv4 a druhé IPv6 a při vyhledání by nebylo možné určit jaké pravidlo je to správné.
Pro rozlišení o jaký druh prefixu se jedná je možno použít dva přístupy, rozlišením na úrovni
záznamů směrovacích tabulek nebo rozlišením na úrovni směrovacích tabulek.

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|l|}
    \hline
    Prefix & Délka prefixu & Rozhraní \\ \hhline{|=|=|=|=|}
    $100*$ & 3 & eth0 \\ \hline
    $100*$ & 3 & eth3 \\ \hline
    \end{tabular}
    \caption{Příklad směrovací tabulky}
\end{table}

Pro hledání nejdelšího shodného prefixu existuje velké množství algoritmů, které jsou popsány v \cite{tbm}.
Většina z nich je založena na procházení stromové struktury. Každý algoritmus má jiné paměťové nároky
a dosahuje jiných rychlostí. Z toho důvodu je při výběru vhodného algoritmu nutné
volit kompromis mezi rychlostí a paměťovou náročností.
V případě že jde o implementaci na architektuře FPGA bude důraz pravděpodobně kladen na paměťovou náročnost
a to z důvodu, že tyto čipy mají omezenou kapacitu paměti. Na architekturách vycházejících z x86 je naopak kladen důraz
na rychlost zpracování z důvodu obecných procesorů, které nejsou specializovány na zpracování těchto operací
a dosahují tak delší doby zpracování.

První algoritmus hledání nejdelšího shodného prefixu byl založen na naivním procházení lineárního
seznamu. Doba vyhledávání pomocí tohoto algoritmu byla závislá na počtu uložených prefixů a její
časová složitost byla $O(N)$, což při dnešních rychlostech spojů umožňuje procházet směrovací tabulku
obsahující pouze malý počet záznamů.

Algoritmy rozebrané v této kapitole vycházejí z obecně n-árního stromu,
jež je rozšířením binárního stromu na více než dva potomky.
Těmito algoritmy je binární vyhledávání na délce prefixu a TreeBitmap.
Binární vyhledávání na délce prefixu používá binární strom pro interní reprezentaci směrovacích
informací a pro vyhledávání využívá struktury hašovací tabulky, ve které jsou uloženy všechny existující uzly
binárního stromu.
TreeBitmap je algoritmus založený na obecném n-árním stromu a vyznačuje se tím,
že pro uložení prefixu využívá zakódované bitmapy, umožňuje procházet stromem
po více než jednom bitu a dosahuje tak menší paměťových nároků.
Dosažené výsledky pro různé n jsou vizualizovány v kapitole \ref{section:results-lpm}.


\subsubsection{TreeBitmap} % #####################################################################################

Algoritmus TreeBitmap je založen na datové struktuře n-ární stromu, v němž jsou uloženy směrovací informace.
Hlavní myšlenkou je uložení potomků jednoho uzlu na jednom paměťovém místě, což znamená že stačí uchovávat pouze jednu
adresu reprezentující paměťové místo, kde se uzly nacházejí, a index pro určení jaký uzel se má vybrat. Právě
hodnota indexů je zakódovaná do bitmap.
Výhodou tohoto zakódování informací je zmenšení paměťových nároků pro uložení každého uzlu stromové struktury.
Další specifickou vlastností algoritmu TreeBitmap je zpracování několika bitů adresy v jednom kroku.
Počet zpracovaných bitů je nazýván střída a právě velikost střídy je stupněm n-árního stromu.

Každý uzel stromové struktury obsahuje dvě bitmapy, interní a externí, které slouží pro zakódování indexů.
Interní bitmapa slouží pro zakódování informací, jaké prefixy se nacházejí v aktuálním uzlu.
Externí bitmapa pak uchovává informace o existujících cestách do nižších vrstev stromové struktury.
Příklad zakódovaných bitmap pro střídu 2 je zobrazen v tabulce \ref{tab:tbm-bitmaps}.
Dalšími položkami uzlu je ukazatel na pole následujících uzlů a ukazatel na pole obsahující směrovací pravidla,
jež odpovídají adresám reprezentovaných tímto uzlem.

\begin{table}
	\center
    \begin{tabular}{|l||c|c|c|c|c|c|c|}
    \hline
    Prefix & $*$ & $0*$ & $1*$ & $00*$ & $01*$ & $10*$ & $11*$ \\ \hhline{|=#=|=|=|=|=|=|=|}
    Interní bitmapa & 0 & 1 & 0 & 0 & 0 & 1 & 1 \\ \hline
    \multicolumn{4}{|l|}{Externí bitmapa} & 1 & 0 & 1 & 0 \\ \hline
    \end{tabular}
    \caption{Příklad bitmap algoritmu TreeBitmap}
    \label{tab:tbm-bitmaps}
\end{table}

Algoritmus vyhledávání spočívá v procházení stromu od kořenu a zjišťování, zda
existuje prefix odpovídající zpracované části adresy. Částí adresy se rozumí N bitů, jež jsou brány postupně
od nejvýznamnějších bitů hledané adresy až po nejméně významné.
Jako první operace hledání nejdelšího shodného prefixu se extrahují bity adresy na pozici odpovídající
aktuální hloubce zanoření ve stromu a provede se operace zjištění, zda je pro část této adresy uloženo
směrovací pravidlo. To je zjištěno z interní bitmapy na pozici, jež odpovídá délce a hodnotě extrahovaných bitů.
Pozice v interní bitmapě je vypočítána jako $2^{N} - 1 + x$, kde $N$ reprezentuje hodnotu střídy a $x$
dekadickou reprezentací extrahovaných bitů.
Pokud se na této pozici
nachází hodnota "1", je uloženo pravidlo na indexu spočítatelným jako \texttt{ones(bitmap, position)} v poli pravidel.
Toto pravidlo pak reprezentuje dočasný nejlepší výsledek. Pokud je na vypočítaném
pozici v interní bitmapě hodnota "0" je opakován výpočet pozice s hodnotou $N$ sníženou o jedna a bitovou hodnotou
oříznutou o nejméně významný bit. Tato operace se opakuje tak dlouho, dokud není nalezena pozice
s hodnotou "1"
nebo dokud není N nulové. Jako druhá operace je provedeno hledání následovníků ve stromové struktuře
reprezentující specifičtější prefixy. To je provedeno jako zjištění přítomnosti hodnoty "1" v externí
bitmapě na pozici, jejíž hodnota je dekadickou reprezentací extrahovaných bitů. V případě přítomnosti
"1" na této pozici je proveden přechod do další úrovně stromové struktury a celý postup se opakuje.
Pokud je na této pozici hodnota "0" je vyhledávání ukončeno a jako výsledek je navrácena hodnota
dočasného nejlepšího výsledku, která odpovídá pravidlu jež patří k nejdelšímu shodnému nalezenému
prefixu. Celý algoritmus je popsán pseudokódem v algoritmu \ref{alg:treebitmap}.

Pro výpočet indexu do polí obsahující pravidla a následovníky se používá funkce
\texttt{ones(bitmap, position)}, jež
spočítá počet bitů s hodnotou "1" v dané bitmapě a to od pozice 0 do pozice \texttt{position}.

Jeden uzel stromu TreeBitmap je vizualizován na obrázku \ref{fig:tbm-node}. Uzly zbarvené černě
jsou uzly pro které je definováno směrovací pravidlo.

\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=.55]{fig/tbm.pdf}
    \caption{Jeden uzel algoritmu TreeBitmap}
    \label{fig:tbm-node}
\end{figure}

\begin{algorithm}[H]
	\KwData{tbm-root, ip}
	\KwResult{routing rule}
	node $\leftarrow$ tbm-root\;
	longest-match-node $\leftarrow$ tbm-root\;
	longest-match-index $\leftarrow$ 0\;
	position $\leftarrow$ 0\;
	\Repeat{BIT(parent.external, bits)}
	{
		bits $\leftarrow$ get-stride-bits(ip, position)\;
		position $\leftarrow$ position + STRIDE\;


		\If{internal-index(node.internal, bits)}
		{
			longest-match-node = node\;
			longest-match-index = internal-index(node.internal, bits)\;
		}

		index $\leftarrow$ ones(node.external, bits)\;
		parent $\leftarrow$ node\;
		node $\leftarrow$ node.external[index]\;
	}
	\Return longest-match-node.rule[logest-match-index]\;
	\caption{Hledání nejdelšího shodného prefixu algoritmem TreeBitmap}
    \label{alg:treebitmap}
\end{algorithm}

\subsubsection{Binární vyhledávání na délce prefixu} % ###########################################################

Algoritmus binárního vyhledávání na délce prefixu vychází z jednobitového binárního stromu a přidává
operaci propagování listů (angl. \textit{leaf-pushing}) a zavádí efektivnější prohledávání založené na hašovací
tabulce. Hodnota klíče uzlu v obecném binárním stromu není přímo zanesena do uzlu jako jedna z jeho položek,
ale odpovídá cestě stromem od kořene k aktuálnímu uzlu.

Struktura uzlu je rozšířena o položky prefix, délka prefixu a typ uzlu.
Typy uzlu jsou dva a to interní uzel a uzel reprezentující pravidlo.

Oproti binárnímu stromu používá tento algoritmus i hašovací tabulku, do které jsou zaneseny všechny uzly
stromu a jako hodnota pro hašovací funkci je použita hodnota prefixu v daném uzlu.

Tohle přepracovat, není to ůplně jasné %TODO
Vyhledávání v hašovací tabulce je vyhledání položky v hašovací tabulce reprezentující celou klasifikovanou
adresu. Pokud je vyhledání úspěšné a nalezený prvek je typu prefix, pak je pravidlo z tohoto uzlu navráceno
jako nejdelší shodný prefix. V případě že takový prvek není nalezen pak dojde ke snížení délky vyhledávané
adresy na polovinu a hledání je zopakováno. V případě že nalezený prvek je typu internal dojde ke zvýšení
délky prefixu o hodnotu XX
a je opakováno vyhledávání v hašovací tabulce. V případě neúspěšného vyhledávání dojde ke snížení délky hledaného prefixu a vyhledávání je opakováno.

Operace propagace listů zavádí pravidlo, že existují právě dva následovníci uzlu nebo neexistuje žádný.
Pokud dojde ke stavu, že existuje právě jeden následovník uzlu je operací propagování uzlů
vytvořen i druhý uzel je do něj zaneseno pravidlo, jež obsahuje přímo nadřazený uzel.
Ukázku stromu před operací propagace listů je možno vidět na obrázku \ref{bspl-not-pushed}
a po provedení této operace na obrázku \ref{bspl-pushed}.

\begin{figure}[!htbp]
	\begin{floatrow}
		\ffigbox{
		\includegraphics[scale = 0.5]{fig/bspl-not-pushed.pdf}}
			{\caption{Strom před leaf-pushingem}\label{bspl-not-pushed}}
		\ffigbox{\includegraphics[scale = 0.5]{fig/bspl-pushed.pdf}}
			{\caption{Strom po provedení leaf-pushingu}\label{bspl-pushed}}
	\end{floatrow}
\end{figure}

Algoritmus binary search on prefix length je založen binárním vyhledávání neboli na metodě
půlení intervalů. Vyhledávání půlením intervalů
se ve své první iteraci pokusí vyhledat shodný prefix celé délky, tedy 32 bitů pro IP adresu
verze protokolu IPv4 a 128 bitů pro IP verze 6.

Mějme směrovací tabulku obsahující tyto informace:

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|}
    \hline
    Prefix        & Délka prefixu & Pravidlo \\ \hhline{|=|=|=|}
    147.228.0.0   & 14            & P1       \\ \hline
    147.228.128.0 & 17            & P2       \\ \hline
    \end{tabular}
    \caption{Příklad směrovací tabulky}
\end{table}

Vyhledávání směrovací cesty pro adresu 147.228.128.54 bude procházet následujícími kroky

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|r|l|r|l|}
    \hline
    Prefix & Délka & Uzel & Změna délky & Výsledek \\ \hhline{|=|=|=|=|=|}
    147.228.128.54 & 32 & Nenalezen & -16 &  \\ \hline
    147.228.0.0 & 16 & Interní & +8 &  \\ \hline
    147.228.128.0 & 24 & Nenalezen & -4 &  \\ \hline
    147.228.128.0 & 20 & Nenalezen & -2 &  \\ \hline
    147.228.128.0 & 18 & Nenalezen & -1 &  \\ \hline
    147.228.128.0 & 17 & Prefix & 0 & P2 \\ \hline
    \end{tabular}
    \caption{Příklad vyhledání nejdelšího shodného prefixu}
\end{table}

Operace vyhledání nejdelšího prefixu při využití algoritmu binary search on prefix length má časovou
složitost $\log_2{N}$, kde \texttt{N} je počet bitů adresy. V případě IPv4 adresy je to 32 bitů a pro IPv6
adresu je to 128 bitů. Z principu algoritmu vyplývá, že nejhorší výsledky z časového hlediska bude dosahovat
při shodě prefixu, který byl zadán s lichou délkou. V tomto případě bude nutné projít všemi kroky.
Počet kroků v případě IPv4 bude 5 a v případě IPv6 adresy to pak bude 7.
Zde je vidět že i v případě čtyřikrát delší adresy se počet kroků pro vyhledání prefixu zvedne pouze o dva,
což neplatí pro algoritmus TreeBitmap, který musí projít v nejhorším případě až čtyřikrát více
uzlů aby nalezl odpovídající prefix.
\cite{bspl}

\begin{algorithm}
	\KwData{bspl-root, hash-table, ip, ip-length}
	\KwResult{routing rule}
	prefix-length $\leftarrow$ ip-length\;
	prefix-change $\leftarrow$ ip-length\;
	\Repeat{prefix-change $>$ 0}
	{
		bits $\leftarrow$ get-prefix-bits(ip, prefix-length)\;
		item $\leftarrow$ hash-table.get(bits)\;
		prefix-change $\leftarrow$ prefix-change $\gg$ 1\;

		\lIf{item == NULL}{prefix-length $\leftarrow$ prefix-length - prefix-change}
		\lElseIf{item.type == PREFIX}{prefix-length $\leftarrow$ prefix-length + prefix-change}
		\lElse{break}
	}
	\lIf{item == NULL}{\Return bspl-root.default-rule}
	\caption{Hledání nejdelšího shodného prefixu algoritmem Binary search on prefix length}
\end{algorithm}

\subsection{Hledání řetězců} % ###################################################################

Jednu z častých operací při zpracování síťového provozu je hledání řetězců, jež je využíváno pro detekci
signatur útoků na počítačové sítě, detekci malware a blokování dat obsahujících zakázaná klíčová slova.

Hledání řetězců je ověřování, zda se jedno a více definovaných klíčových slov vyskytuje ve vstupních
datech. V případě počítačových sítí se vstupními daty rozumí obsah datových paketů.

Pokud se oprostíme od počítačových sítí, tak dalším využitím hledání řetězců může být
vyhledávání klíčových slov v textových dokumentech, což byl prvotní impuls pro vznik
algoritmu autorů Aho a Corasickové, kteří tímto způsobem zrychlili prohledávání
textových dokumentů až $5\times$. Alternativou k algoritmu Aho-Corasick může být požadován
algoritmus autorů Rabin–Karp \cite{rabin-karp}, který má ovšem horší průměrnou časovou složitost, $O(m+n)$,
zatímco Aho-Corasick je tato složitost nejhorší možná. Algoritmem postaveným na Aho-Corasick
a Boyer–Moore \cite{boyer-moore}
je Commentz-Walter \cite{walter}, jehož časová složitost však v nejhorším případě dosahuje $O(m*n)$

Algoritmem na nějž se soustředí část této práce je právě Aho-Corasick.
Tento algoritmus používá pro zjištění shody s podřetězcem konceptu konečného automatu.
V každém kroku algoritmu dojde ke zpracování právě jednoho vstupního symbolu.

Konstrukce konečného automatu reprezentujícího klíčová slova je prováděna postupně a to tím způsobem,
že je v automatu hledána již existující prefix vkládaného klíčového slova. Od výsledku tohoto hledání
se pak vychází v dalších krocích, jež jsou následující:

\begin{description}
    \item[Vstup  $\leq$ Existující] v tomto případě je pouze přidělena další pravidlo k danému uzlu.

    \item[Vstup $>$ Existující] v tomto případě je rozšířena již existující cesta a do konečného
    uzlu této cesty je přiřazeno odpovídající pravidlo.
    \item[Prefix $<$ Existující] pak je vytvořena další cesta z posledního shodného uzlu a neexistující uzly jsou vytvořeny
\end{description}

Po dokončení operace přidávání klíčových slov je provedeno generování tzv. failure cest.
Failure cesta je mapováním dalšího přechodu, který je proveden v případě, že pro vstupní symbol neexistuje
přechod z aktuálního stavu. Failure cesta pak reprezentuje prefix klíčových slov,
která lze nalézt v podřetězec klíčového slova aktuálně procházeného.
Generování failure cesty je definováno iterativně a to následujícím způsobem:

Pro startovací uzel je failure cesta definována jako přechod do sebe sama.
Pro každý uzel v úrovni 1 je failure cesta definována jako přechod do startovního stavu.
Pro každou další úroveň je pak failure cesta definována jako uzel v hloubce o jedna menší než je aktuální hloubka

procházení failure cestou předchozího uzlu a zkoušení zda existuje validní před pro znak stavu, ze kterého

Další používanou funkcí je funkce goto, která rozhoduje o další stavu z aktuálního stavu a aktuálně
zpracovaného symbolu. Goto funkce je definována jako cyklus dokud
je přechod ze stavu s při symbolu a fail tak dej s = s->failure
a potom přejdi z s při zpracování symbolu a.

Příkladem procházení automatu a hledání slov může sloužit následující příklad reprezentovaný tabulkami
\ref{tab:pm-keywords} a \ref{tab:pm-match} při vstupních datech \textit{ship}.
Symbol $[]$ reprezentuje počáteční stav a $[xyz]$ reprezentuje posloupnost stavů odpovídající cestě od
počátečního symbolu do aktuální cesty.

\begin{table}[!htbp]
    \center
    \begin{tabular}{|l|l|}
    \hline
    Klíčové slovo & Pravidlo \\ \hhline{|=|=|}
    she & 1  \\ \hline
    hi & 2 \\ \hline
    \end{tabular}
    \caption{Klíčová slova}
    \label{tab:pm-keywords}
\end{table}

Automat reprezentující tyto klíčová slova je zobrazen na obrázku \ref{fig:ac}.
Plnou čarou jsou znázorněny možné přechody, přerušovanou čarou failure přechody a zelenou
je znázorněn průchod automatem v pro vstupní data \textit{ship}.


\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=.55]{fig/ac.pdf}
    \caption{Automat obsahující klíčová slova \textit{she} a \textit{hi}}
    \label{fig:ac}
\end{figure}

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|}
    \hline
    Aktuální symbol & Akce automatu & Výsledek \\ \hhline{|=|=|=|}
    s & [] $\overset{s}{\rightarrow}$ [s] &  \\ \hline
    h & [s] $\overset{h}{\rightarrow}$ [sh] & \\ \hline
    i & $\nexists$ [sh] $\overset{i}{\rightarrow}$ [shi], [sh] $\overset{\epsilon}{\rightarrow}$ [h], [h] $\overset{i}{\rightarrow}$ [hi] & \texttt{hi} \\ \hline
    p & $\nexists$ [hi] $\overset{p}{\rightarrow}$ [hip], [hi] $\overset{\epsilon}{\rightarrow}$ [], [] $\overset{p}{\rightarrow}$ [] &  \\ \hline
    \end{tabular}
    \caption{Prohledávání algoritmem Aho-Corasick}
	\label{tab:pm-match}
\end{table}


Algoritmus procházení vstupních dat je rozepsán v \ref{alg:aho} a vychází z \cite{aho}.

\begin{algorithm}[!htbp]
	\KwData{start-state, text}
	\KwResult{keyword}
	state = start-state\;
	\For{position $\leftarrow$ 0 \KwTo text.length}
	{
		\lWhile{goto(state, text[position]) == FAIL}{state $\leftarrow$ state.failure}
		\lIf{state.isMatch}{\Return state.keyword}
	}
	\Return NOT-MATCH\;
	\caption{Algoritmus procházení textu a hledání podřetězců}
    \label{alg:aho}
\end{algorithm}

\subsection{Hledání regulárních výrazů} % ############################################

Hledání regulárních výrazů je, podobně jako hledání řetězců, operace sloužící pro detekci signatur
síťových útoků a detekci škodlivého software v obsahu datových paketů v systémech IDS a IPS.
Algoritmy pro hledání regulárních výrazů v rámci této práce jsou založeny na transformaci
regulárních výrazů, což je umožňuje díky ekvivalenci výpočetní síly regulárních výrazů a konečných automatů
v Chomského hierarchii.
V této práci jsou rozebrány deterministické a nedeterministické konečné automaty.

Než se dostaneme k popisuje jednotlivých druhů konečných automatů je potřeba definovat co je to regulární
výraz.

Regulární výrazy nad abecedou $\Sigma$ a jazyky které značí jsou definovány následovně
Nechť $r$ a $s$ jsou RV značící jazyky $L_R$ a $L_S$.

\begin{itemize}
    \item{$\emptyset$ je RV značící prázdnou množinu (prázdný jazyk)}
    \item{$\epsilon$ je RV značící jazyk ${\epsilon}$}
    \item{$a$, kde $a \in \Sigma$ je RV značící jazyk ${a}$}
    \item{$r.s$ je RV značící jazyk $L = L_R L_S$}
    \item{$r+s$ je RV značící jazyk $L = L_S \cup L_S$}
    \item{$r*$ je RV značící jazyk $L = L_{R*}$}
\end{itemize}

Časová složitost pro jednotlivé varianty je následující
nedeterministické konečné automaty $O(n*m)$
deterministické konečné automaty $O(n)$

Průchod deterministický konečným automatem je možné zpracovat právě jeden znak vstupu v
každé iteraci. Algoritmus se podívá, zda existuje přechod pro aktuální znak na vstupu z aktuálního stavu
a pokud existuje tak je proveden přechod. V případě že takový přechod neexistuje pak je nastaven
aktuální stav na počáteční stav konečného automatu a operace je provedena znovu.
Algoritmus procházení deterministickým konečným automatem je popsán v \ref{alg:dfa},
procházení nedeterministického automatu je popsán v \ref{alg:nfa}.

\begin{algorithm}
    \KwData{root - startovní stav konečného automatu, input - vstupní data, length - délka vstupních dat}
    \KwResult{vyhovuje/nevyhovuje}
    position $\leftarrow 0$
    state $\leftarrow$ root
    \While{length > position}
    {
        symbol $\leftarrow$ input[position]\;
        states.push(root)\;

        \While{state $\leftarrow$ states.pop()}
        {
            \lIf{state->key[symbol]}{states-new.push(state->next[symbol])}
            \lIf{state->next[symbol].accepting} {\Return state->next[symbol].rule}
        }

        swap(states, states-new)\;
        position $\leftarrow position + 1$\;
    }
    \caption{Algoritmus procházení pro deterministický konečný automat}
    \label{alg:dfa}
\end{algorithm}

\begin{algorithm}
    \KwData{root - startovní stav konečného automatu, input - vstupní data, length - délka vstupních dat}
    \KwResult{vyhovuje/nevyhovuje}
    position $\leftarrow 0$
    state $\leftarrow$ root
    \While{length > position}
    {
        symbol $\leftarrow$ input[position]\;
        states.push(root)\;

        \While{state $\leftarrow$ states.pop()}
        {
            \lFor{ i $\leftarrow$ 0 \KwTo i $<$ state.epsilon\_count}{states.push(state.epsilon[i])}
            \lIf{state->key[symbol]}{states-new.push(state->next[symbol])}
            \lIf{state->next[symbol].accepting} {\Return state->next[symbol].rule}
        }

        swap(states, states-new)\;
        position $\leftarrow position + 1$\;
    }
    \caption{Algoritmus procházení pro nedeterministický konečný automat}
    \label{alg:nfa}
\end{algorithm}

\subsection{Analýza a extrakce hlaviček paketů} % ###################################################

Extrakce hlaviček paketů je operace prováděná na každém síťovém zařízení,
neboť právě na základě hodnot položek hlavičky paketu je prováděno rozhodnutí,
jak má být paket zpracován.
V případě hledání nejdelšího shodného prefixu je potřeba nejprve provést extrakci
cílové adresy a až poté je možné zahájit vyhledávaní cesty, kterou bude paket směrován.
Z toho vyplývá přímá závislost rychlosti všech operací, pracující s položkami hlaviček na linkové, síťové a
transportní vrstvě.

Tato operace je celkem komplexní a to z důvodu různé délky jednotlivých hlaviček na vrstvách
linkové, síťové a transportní v závislosti na použitém protokou na dané vrstvě.
Vstupem operace analýza a extrakce hlaviček paketů je datový paket a výstupem je
množina hodnot, jež byly cílem analýzy a extrakce.

Analýzu a extrakci hlaviček lze provádět jak na úrovni softwarového řešení tak i na úrovní hardware,
jak předvedli autoři v \cite{phe}.

Operace je rozdělena na dva kroky. Prvním krokem je lokalizace požadované hlavičky ve vstupních datech
a druhým je pak extrakce této hodnoty.

Jedním ze způsobů jak extrahovat hlavičky paketů je použití orientovaných acyklických grafů,
kde vrcholy reprezentují typy hlaviček a hrany reprezentují posloupnost hlaviček.
Parsovací graf je převeden na konečný automat.

Operace je možné rozdělit na dvě paralelní zpracování,
kdy v prvním zpracování bude identifikován typ hlavičky a v druhé pak bude provedena extrakce
této hodnoty v závislosti na typu hlavičky a informací, kde se daná položka v hlavičce nachází.

\chapter{Návrh API knihovny}\label{chapter:api} % #################################################################

Cílem návrhu API knihovny \texttt{fastnet} je vhodně zapouzdřit implementované operace a to takovým způsobem,
aby je bylo možné používat bez znalosti využívaných algoritmů nebo znalosti
hlubší než je ůroveň vědět k čemu se to používá. Dalším cílem návrhu je připravit API tak,
aby bylo možné rozšiřovat množinu algoritmů implementující dané operace při zachování
současné struktury funkcí.

Je navrženo API pro operace klasifikace paketů \ref{api:pc}, hledání nejdelšího shodného prefixu
\ref{api:lpm}, hledání řetězců \ref{api:pm}, hledání regulárních výrazů \ref{api:regex} a analýzu a
extrakci hlaviček paketů.

V kapitole \ref{api:extension} je rozebrána možnost rozšíření této knihovny o další operace.
Kapitola \ref{api:usage} je popsáno jakým způsobem je možné sestavit celou knihovnu nebo její jednotlivé
části.

Každá knihovna umožňuje pracovat s více datovými strukturami reprezentující
data dané operace. Toho je dosaženo explicitním uváděním kořenu místo jeho implicitního uložení
uvnitř knihovny. To byl také jeden z požadavků při návrhu API. Kořenový prvek je
explicitně předáván do funkcí provádějící jednotlivé operace. Jedinou výjimkou
jsou inicializační funkce, které právě vytvářejí kořenovou strukturu pro další použití.

Knihovna \texttt{fastnet} je navržena jako množina menších knihoven, kde každá knihovna implementuje
jednu operaci používanou při zpracování síťového provozu.
Tímto návrhem je dosaženo snadné rozšiřitelnosti o další operace,
jako například extrakce informací z hlaviček paketů a klasifikaci paketů.

Další výhodou tohoto rozdělení je možnost snadno vytvořit a používat jednotlivé knihovny samostatně.
To se může hodit pro zařízení, která mají velmi limitované paměťové úložiště a jejich účelem
je řešit pouze jednu ze zmíněných operací.

Veřejné rozhraní celé knihovny se skládá z veřejných rozhraní jednotlivých knihoven.
Tyto rozhraní jsou popsány v následujících kapitolách.

Pro knihovnu je navržena struktura hlavičkových souborů pro jednotlivé knihovny a tato struktura
obsahuje následující soubory. Jako výchozí hlavičkový soubor je použit \texttt{types.h},
který obsahuje definice datových struktur pro všechny algoritmy v knihovně, které musí být
viditelné i z veřejného rozhraní. Dalším souborem je \texttt{types-precompiled.h},
který je generován z \texttt{types.h} při překladu když se vybírá používaný algoritmus.
Soubor \texttt{common.h} je hlavičkový soubor společný pro všechny algoritmy v knihovně a \texttt{<algorithm>.h}
pak obsahuje deklarace specifické pro právě jeden konkrétní algoritmus.
Soubor \texttt{<sublib.h>} je pak hlavičkový soubor, který tvoří veřejné rozhraní ke knihovním funkcím.

Závislost jednotlivých souborů je znázorněna na obrázku \ref{fig:header-dependecies}.

\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=.25]{fig/header-dependencies.pdf}
    \caption{Diagram závislostí hlavičkových souborů}
    \label{fig:header-dependecies}
\end{figure}


\section{Klasifikace paketů}\label{api:pc} % #######################################################

Pro klasifikaci paketů jsou navrženy čtyři základní funkce a jedna datová struktura.
Tato struktura je nazvána \texttt{set} a obsahuje položky \texttt{rule} pro uložení pravidla,
které bude odpovídat kombinaci ostatních položek, \texttt{dst} pro uložení cílové IP adresy,
\texttt{src} pro uložení zdrojové adresy, \texttt{protocol} pro uložení typu transportního protokolu,
tedy TCP nebo UDP a \texttt{port} pro uložení cílového portu.
Důvod proč jsou vybrány pouze tyto položky je to, že tato operace není implementována
a tyto položky jsou při klasifikaci používány nejčastěji.

Funkce pro práci se strukturou pro klasifikaci paketů jsou: \texttt{init} pro inicializaci
vyhledávacích struktur, \texttt{add} pro přidání klasifikačního pravidla, \texttt{update}
pro aktualizaci odpovídajícího pravidla, \texttt{remove} pro smazání odpovídajícího pravidla
a nakonec \texttt{destory} pro uvolnění veškeré paměti zabírané strukturami pro provádění klasifikace
paketů.

Všechny zmíněné funkce a jedna datové struktura jsou navrženy ve dvou verzích a to pro IPv4 a IPv6.
Tyto funkce se od sebe liší pouze prefixem, kde pro IPv4 je použit prefix \texttt{pc\_} a pro
IPv6 pak \texttt{pc6\_}. Důvodem proč jsou jednotlivé funkce a struktura rozděleny tímto
způsobem je odlišná velikost adres, čímž je docíleno menší paměťové náročnosti pro uložení jednotlivých položek
v případě IPv4 a nutnost rozlišovat pro jako verzi IP protokolu se klasifikace provádí,
neboť prefixy adres se mohou shodovat pro obě verze IP, ale mohou reprezentovat jiné adresy

Všechny funkce vyjma \texttt{init} očekávají jako první argument strukturu typu \texttt{root},
jež obsahuje veškeré informace a konkrétních klasifikačních pravidlech. Jako u ostatních operací
je tato struktura osamostatněna a to umožňuje vytvářet více klasifikátorů v jednom programu.

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/pc/pc.h}

\section{Vyhledání nejdelšího shodného prefixu}\label{api:lpm} %########################################

Pro operaci vyhledání nejdelšího shodného prefixu jsou připraveny funkce
\texttt{init}, \texttt{add}, \texttt{update}, \texttt{remove} a \texttt{destroy}.
Jako datové struktury jsou navrženy struktury pro uložení každého uzlu datového stromu.
Pro binární vyhledávání na délce prefixu to je struktura \texttt{\_bspl\_node} a pro
algoritmus TreeBitmap \texttt{\_tbm\_node}.

Funkce \texttt{init} slouží pro vytvoření kořenového uzlu datových struktur a
nastavení defaultního pravidla, které je vybráno pokud není nalezen žádný odpovídající prefix.
Návratovou hodnotou této funkce je ukazatel na kořen datové struktury, jež je parametrem
všech ostatní funkcí provádějící operace v rámci vyhledání nejdelšiho shodného prefixu.
Funkce \texttt{add} slouží pro přidání prefixu a pravidla odpovídajícímu tomuto prefixu.
Funkce \texttt{update} slouží pro aktualizaci pravidla daného prefixu.
Funkce \texttt{remove} odstraňuje zvolený prefix z vyhledávací struktury.
Funkce \texttt{destroy} slouží pro uvolnění paměti alokované všemi výše zmíněnými funkcemi
a po provedení této funkce již není možné provádět další operace nad danou strukturou.

Funkce pro vložení, smazání a aktualizaci pravidel a prefixů také obsahují parametr
prefix, který je buď IPv4 nebo IPv6 adresa. Dalším parametrem těchto funkcí je délka prefixu,
aby bylo možné odlišit jednotlivé prefixy od sebe. Tam může dojít ke kolizi pokud existuje
prefix $1*$ o délce jedna a prefix $10000*$ o délce pět, neboť tyto prefixu budou reprezentovány stejným
číslem, neboť v binární kódu máme pouze dvě hodnoty a není možné určit třetí stav jako X,
nezajímá nás/není důležité.

Funkce pro vložení prefixu pracuje s pouze s jedním prefixem a je prováděna okamžitě.
Tento návrh vychází z předpokladu, že knihovna bude používána i v prostředí s dynamickými routovacími
protokoly jako například RIP, OSPF nebo BGP, které při změně směrovacích informací v případě BGP
zasílají aktualizace s novými informacemi na všechny sousední směrovače nebo jsou tyto změny
zasílány periodicky v případě protokolu RIP.

Hašovací funkce je v této implementaci použita Jenkins \cite{jenkins}. Volba hašovací funkce
může mít vliv na rychlost vyhledávání. To je patrné z principu hašovací tabulky, kde se
kolizní záznamy uchovávají v lineárním seznamu a v případě kdy by hašovací funkce generovala
stejné hodnoty pro všechny vstupní hodnoty by bylo vyledávání omezeno na procházení
lineárního seznamu se složitostí v nejhorším případě $O(log_2{N}*M)$, kde $M$ odpovídá počtu záznamů uložených ve směrovací tabulce a $N$ velikosti IP adresy, tedy 32 nebo 128 bitů
namísto $O(\log_2{N})$, kde N reprezentuje délku IP adresy.

V implementaci obou algoritmů je řešena i reakce na nedostatek paměti,
kdy je nastavena globální proměnná \texttt{errno} a záznam není přidán.

Volbu algoritmu lze volit při sestavení knihovny pro vyhledání nejdelšího shodného prefixu
zapsáním následujícího příkazu \texttt{make ALG=<alg>}, kde hodnota \texttt{<alg>} může nabývat
hodnot \texttt{tbm} pro volbu TreeBitmap a \texttt{bspl} pro binární vyhledávání na délce prefixu.
V případě sestavování celé knihovny je možné zapsat \texttt{make LPM=<alg>} v příslušném adresáři.

Při volbě algoritmu TreeBitmap je pak volitelný parametr \texttt{STRIDE=<N>}, jež určuje velikost
střídy. Tuto volbu je možné použít v obou příkazech.

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/lpm/lpm.h}
Specifikaci datových struktur lze nalézt v soubor \texttt{/lib/src/lpm/types.h}


\section{Hledání řetězců}\label{api:pm} % ####################################################################

Pro hledání řetězců je navrženo několik datových struktur, mezi které patří
struktura pro uložení právě jednoho stavu konečného automatu \texttt{\_ac\_state},
struktura reprezentující jeden konečný automat \texttt{pm\_root} a struktura \texttt{pm\_keyword}
pro uložení klíčového slova, jeho délky a jemu odpovídající pravidlo.


Pro hledání řetězců jsou podobně jako pro vyhledání nejdelšího shodného prefixu navrženy a implementovány
následující funkce.

\begin{itemize}
    \item{\texttt{pm\_init} pro inicializaci datových struktur}
    \item{\texttt{pm\_match} pro hledání prvního klíčové slova vyskytujícího se ve vstupních datech}
    \item{\texttt{pm\_match\_next} pro hledání dalších klíčových slov}
    \item{\texttt{pm\_add} pro vložení množiny klíčových slov}
    \item{\texttt{pm\_update} pro změnu pravidla odpovídající danému klíčovému slovu}
    \item{\texttt{pm\_remove} pro smazání klíčového slova}
    \item{\texttt{pm\_destroy} pro uvolnění veškeré alokované paměti touto operací}
\end{itemize}

Všechny výše zmíněné funkce vyjma \texttt{pm\_init} a \texttt{pm\_match\_next} očekávají jako první parametr strukturu typu \texttt{pm\_root},
která je základním prvkem pro vyhledávání a právě do této struktury
jsou uložena všechna klíčová slova a jejich pravidla.

Hledání řetězců funkcí \texttt{pm\_match} skončí svůj průchod konečný automatem v momentě nálezu první shody
s libovolným řetězcem zadaným při volání \texttt{pm\_add}.
V případě, že není nalezena žádná shoda
s definovanými klíčovými slovy v řetězci je vrácen výsledek \texttt{false}.

Čtvrtým parametrem funkce \texttt{pm\_match} může být hodnota \texttt{NULL} nebo odkaz na datovou strukturu
\texttt{pm\_result}. V případě \texttt{NULL} argumentu již nelze procházet textem a hledat další shody.
Pokud je zadán odkaz na existující strukturu \texttt{pm\_result} je možné procházet celým textem a ukládat
všechny nalezené shody s řetězci funkcí \texttt{pm\_match\_next}.

Jednotlivé položky struktury \texttt{pm\_result} pro veřejné použití jsou

\begin{itemize}
    \item{\texttt{rule} - pole obsahující všechny nalezená klíčová slova}
    \item{\texttt{count} - počet nalezených klíčových slov}
    \item{\texttt{position} - pozice kde bylo nalezen výskyt klíčového slova}
\end{itemize}

Pro práci se strukturou \texttt{pm\_result} jsou v navrženy a implementovány následující operace:

\begin{itemize}
    \item{\texttt{pm\_result\_init} pro vytvoření této struktury}
    \item{\texttt{pm\_result\_destroy} pro uvolnění paměti alokované pro tuto strukturu}
\end{itemize}


Funkce \texttt{pm\_add} očekává jako druhý parametr pole struktur \texttt{pm\_keyword}, kde každá struktura
obsahuje položky vstupního klíčové slova v binární podobě, délku tohoto slova a pravidlo odpovídající tomuto slovu, oproti kterým se budou porovnávat vstupní data. Důvodem proč je předáváno pole dat a ne jednotlivé položky
jako u hledání nejdelšího shodného prefixu je z důvodu neexistence synchronizační mechanismů
v prostředí IPS a IDS. Dalším důvodem pro tento návrh je časově náročná funkce generování
tzv. failure přechodů, které umožňují detekovat kratší klíčové slovo i v případě, že již je
zahájeno porovnávání delšího slova jak je možno vidět na následujícím příkladu. Tabulka \ref{tab:ac:substr}
obsahuje definovaná klíčová slova a obrázek \ref{fig:ac:substr} znázorňuje odpovídající konečný automat.

\begin{table}[!htbp]
    \center
    \begin{tabular}{|l|l|}
    \hline
    Klíčové slovo & Pravidlo \\ \hhline{|=|=|}
    she & 1  \\ \hline
    he & 2 \\ \hline
    \end{tabular}
    \caption{Klíčová slova}
    \label{tab:ac:substr}
\end{table}

\begin{figure}[!htbp]
    \centering
    \includegraphics[scale=0.7]{fig/ac-substr.pdf}
    \caption{Konečný automat reprezentující \ref{tab:ac:substr}}
    \label{fig:ac:substr}
\end{figure}

V implementaci je řešena reakce na nedostatek volné paměti, jež se sestává z nastavení
globální proměnné \texttt{errno} a smazání struktury zatím vytvořeného konečného automatu.
Tento přístup, narozdíl od neprovedení žádné operace v rámci LPM byl zvolen z neexistence
předpokladu na dynamické přidávání pravidel za běhu programu pracujícího s touto knihovnou.

Tak jak je hledání řetězců implementováno je case-sensitive, to je možné změnit
přidáním volání ischar a tolower při vytváření konečného automatu a při procházení vstupních dat.

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/pm/pm.h}
Specifikaci datových struktur lze nalézt v soubor \texttt{/lib/src/pm/types.h}

\section{Hledání regulárních výrazů}\label{api:regex}  % ##########################################################

Rozhraní pro hledání regulárních výrazů navržené a implementované v knihovně \texttt{fastnet:regex}
rozšřuje množinu operací prováděných regulárních výrazů zmíněných v \ref{regex} o následující zápisy operací.

\begin{itemize}
    \item{$[abc]$ je výčet znaků, které se na vstupu mohou vyskytnout a automat je v aktuální stavu dokáže zpracovat. Je to zkrácený tvar zápisu $(a|b|c)$}
    \item{$a+$ je definováno jako pozitivní iterace, tedy $1..N$ opakování}
    \item{$a?$ je definováno jako $0..1$ iterací}
\end{itemize}


Pro hledání regulárních výrazů jsou navrženy a implementovány dva způsoby hledání, a to
deterministický \texttt{dfa} a nedeterministický konečný automat \texttt{nfa}.

Z toho důvodu jsou odlišeny všechny funkce dle typu konečného automatu, který je použit.
Pro použití deterministického konečného automatu je to \texttt{dfa} a pro nedeterministický
je to \texttt{nfa}.
Oproti hledání nejdelšího shodného prefixu nejsou tyto implementace od sebe odlišeny
různými soubory neboť deterministické automaty vycházejí z nedeterministický a pouze používají
determinaci.

Narženy jsou následující funkce

\begin{itemize}
    \item{\texttt{regex\_<type>\_construct} pro vytvoření regulárního výrazu}
    \item{\texttt{regex\_<type>\_match} pro hledání regulárního výrazu ve vstupních datech}
    \item{\texttt{regex\_<type>\_destroy} a uvolnění paměti zabrané regulárním výrazem}
\end{itemize}
% REGEXDFA =================================================================================

Pokud se v definici regulárního výrazu vyskutuje jeden z řídících znaků regulárních výrazů
je nutno tento znak escapovat, to znamená přidat před něj zpětné lomítko.
Zpětné lomítko samotné se pak zapíše jako dvě zpětná lomítka.

Pro vytvoření regulárních výrazů je podobně jako u hledání podřetězců
použita pomocná struktura \texttt{regex\_pattern}, která je předávána do funkce \texttt{regex\_<type>\_construct}
a jež obsahuje pole regulárních výrazů z nichž se má vytvořit jeden konečný automat.
Výsledný konečný automat, ať už deterministický nebo nedeterministický je výsledek spojení jednotlivých
konečných automatů pro každý regulární výraz. Tím je umožněna detekce několika
regulární výrazů v jednom průchodu vstupními daty i s přesnou identifikací jaký regulární
výraz byl ve vstupních datech nalezen.

Důvodem proč jsou zvoleny obě možnosti pro regulární výrazy je až teoreticky exponinciální nárůst
počtu stavů konečného automatu, což může být ve specifických případech nežádoucí a je vhodnější
vyměnit rychlost deterministického konečného automatu za menší paměťové nároky.

%REGEX PATTERN =================================================================================

Při chybě alokace se smaže celá struktura regulárního výrazu, neexistuje předpoklad na
dynamické přidávání regulárních výrazů za běhu programu.

Tak jak jsou regulární výrazy implementovány tak jsou case-sensitive, to je možné změnit
přidáním volání ischar \& tolower při vytváření a procházení výrazů

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD v souboru \texttt{/lib/src/regex/regex.h}
Specifikaci datových struktur lze nalézt v soubor \texttt{/lib/src/regex/types.h}

\section{Analýza a extrakce hlaviček paketů}\label{api:phe} %#####################################################

V knihovně je již navrženo API pro operaci extrakci informací z hlaviček paketů. Tyto
funkce ovšem nejsou implementovány.

Pro tuto operaci byla navržena jedna funkce a jedna struktura.
Touto strukturou je \texttt{phe\_item}, jež je typu \texttt{enum}, jehož položky
se vzájemně překrývají a jeho velikost je stejná jako jeho největší položka a
položku, se kterou se pracuje pak vybírá sám programátor a to pouze určuje způsob reprezentace
dat uložených uvnitř. Důvodem pro tento návrh je ten, že každá proměnná bude obsahovat právě jednu hodnotu.

Navrženou funkcí je funkce \texttt{phe\_get}, jež jako první parametr očekává
vstupní data, jako druhý délku těchto dat, jako třetí ukazatel na pole \texttt{phe\_item},
kam se budou ukládat jednolivé extrahované hodnoty.

Funkce dokáže zpracovat variabilní počet argumentů.
Hodnotami pro variabilní argumenty jsou hodnoty typu \texttt{enum}, kde každá hodnot odpovídá
právě jedné položce hlavičky IP paketu a její číselná hodnota odpovídá počtu bytů
od začátku datové struktury IP paketu.

Pro efektivnější zpracování je vhodné volit pořadí těchto parametrů stejné jako je jejich reálná
posloupnost ve struktuře paketu.

Některé základní položky využívané při klasifikaci paketů a jejich vzdálenosti v bytech
jsou uvedeny v tabulce \ref{tab:phe}

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|}
    \hline
    Význam & Název & offset \\ \hhline{|=|=|=|}
    Verze & IP\_VERSION & 0 \\ \hline
    Zdrojová IP adresa pro IPv4 & IP\_SRC & 12 \\ \hline
    Cílová IP adresa pro IPv4 & 8 IP\_DST & 16 \\ \hline
    Cílový port pro IPv4 & PORT\_DST & 22 \\ \hline
    Protokol pro IPv4 & PROTO & 8 \\ \hline
    \end{tabular}
	\caption{Položky IP paketu a jejich pojmenování pro extrakci a analýzu}
    \label{tab:phe}
\end{table}

Přesnou specifikaci rozhraní je možné nalézt v přiloženém CD ve složce \texttt{/lib/src/phe/phe.h}


\section{Použití knihovny} % #####################################################################################
Celou knihovnu je možné sestavit příkazem \texttt{make all} v hlavním adresáři knihovny.
Při tomto příkazu bude celá knihovna sestavena s definovaným NDEBUG, což má za následek vypuštění všech
volání funkce assert, která slouží pro ověřovaní správné funkčnosti.

Dalšími Cíly pro program \texttt{make} jsou

\begin{itemize}
	\item{\texttt{test} - spustí automatické testování všech částí knihovny}
	\item{\texttt{bech} - spustí benchmarky všech částí knihovny}
	\item{\texttt{doc} - vygeneruje programovou dokumentaci ke všem částem knihovny}
	\item{\texttt{clean} - smaže všechny soubory vytvořené překladem}
\end{itemize}

\section{Rozšíření knihovny} % #####################################################################################

Pro rozšíření knihovny je nutné přidat knihovnu implementující danou operaci
do adresáře \texttt{lib/src} a upravit příslušný soubor \texttt{Makefile} v daném adresáři.
Dále je vhodné vytvořit testovací program a sadu testů, kterou je možné automatizovaně spouštět a vyhodnocovat.
Tyto soubory pak umístit do adresáře \texttt{lib/test/<operace>}.
Další vhodnou součástí knihovny operace je benchmark pro vyhodnocení rychlosti/paměťové náročnosti jednotlivých
implementací dané operace.



\chapter{Výsledky}\label{chapter:results} % ##########################################################################
Tato kapitula shrnuje a vizualizuje dosažené výsledky při implementaci jednotlivých knihoven.
Benchmarky pro architekturu Intel proběhly na operačním systému Archlinux \footnote{https://www.archlinux.org/} s procesorem Intel(R) Core(TM) i3-2310M CPU @ 2.10GHz.

\section{Hledání nejdelšího shodného prefixu}\label{section:results-lpm} % ####################################################################

Hledání nejdelšího shodného prefixu bylo testováno na celkem pěti vstupních sadách dat, které
byly převzaty z volně dostupných dat RIPE\footnote{https://www.ripe.net/}.
Informace o testovaných sadách dat jsou zobrazeny v tabulce \ref{tab:lpm-input}.

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|l|}
    \hline
    Počet adres & Nejkratší prefix & Nejdelší prefix & Verze IP \\ \hhline{|=|=|=|=|}
    $1000$ & 13 & 31 & IPv4 \\ \hline
    $10000$ & 8 & 32 & IPv4 \\ \hline
    $100000$ & 8 & 32 & IPv4 \\ \hline
    $1000$ & 23 & 128 & IPv6 \\ \hline
    $10000$ & 19 & 128 & IPv6 \\ \hline
    \end{tabular}
	\caption{Informace v routovací tabulce pro benchmarky}
    \label{tab:lpm-input}
\end{table}

Důvod proč není benchmark pro IPv6 se 100 000 záznamy ve směrovací tabulce je ten, že se mi nepovedlo
sehnat směrovací tabulku takové velikosti
Vyhledávání pak bylo testováno oproti sadě velikost $1000$ odpovídající verze IP, která je podmnožinou každé
rozsáhlejší sady dat.

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=1]{fig/lpm-ipv4.pdf}
	\caption{Benchmark pro IPv4}
    \label{fig:lpm-ipv4}
\end{figure}

Testováno bylo jak TreeBitmap ve všech variantách velikosti střídy, tedy $1-8$.
Jak je vidět na následujících grafech, tak nejlepších výsledků bylo dosaženo pro TreeBitmap s velkostí
střídy nastavenou na $5$ bitů a to jak pro IPv4 tak i pro IPv6.

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=1]{fig/lpm-ipv6.pdf}
	\caption{Benchmark pro IPv6}
    \label{fig:lpm-ipv4}
\end{figure}

Pro testování algoritmu Binary search on prefix length byla zvolena velikost hašovací tabulky
stejná jako velikost směrovacích dat. Tento přístup byl zvolen z důvodu významného vlivu
velikosti hašovací tabulky na rychlost samotného vyhledávání. V nejhorším případě, tedy při
velikosti hašovací tabulky $100$ byl algoritmus pomalejší pro hledání v tabulce se $100 000$ záznamy pomalejší
$400\times$.
U algoritmu bspl je doba vyhledání prefixu velice závislá na velikosti hašovací tabulky a proto je vhodné odhadnout počet záznamů tabulky alespoň řádově a dle toho pak nastavit velikost konstantu {\tt \_HTABLE\_SIZE} v souboru bspl.h na hodnotu, která alespoň řádově odpovídá předpokládané velikosti hašovací tabulky.

Dalším důležitým faktorem pro efektivnost implementace je velikost datových struktur, která je
závislá na velikosti střídy pro algoritmus TreeBitmap a také na počtu směrovacích pravidel.
Jednotlivé velikost jsou zapsány v tabulce \ref{tab:lpm-input}.

Velikost struktury na závislosti v počtu směrovací pravidel je ovlivněna následujícím způsobem:
Do 256 záznamů zabírá pravidlo pouze 1byte, do 65536 záznamů pak 2 byty a pro více než 65536 pak celé čtyři byty pro uložení právě jednoho pravidla. Při uložení $65536$ adres to bude rozdíl mezi uložením $65537$ bude rozdíl činit
$200KB$

Velikost pravidle lze nastavit změnou definice pro LPM\_RULE.
Jako defaultní je nastaveno \texttt{uint8\_t}. Další hodnoty mohou být \texttt{uint16\_t} a \texttt{uint32\_t}.

\begin{table}[!htbp]
	\center
    \begin{tabular}{|l|l|l|l|l|}
    \hline
    & & \multicolumn{3}{l|}{Velikost pro počet směrovacích pravidel} \\ \hline
    Algoritmus & Velikost střídy & $< 256$ & $< 65536$ & $\geq 65536$\\ \hhline{|=|=|=|=|=|}
    TBM & 1 & 24 & 25 & 28 \\ \hline
    TBM & 2 & 24 & 25 & 28\\ \hline
    TBM & 3 & 24 & 25 & 28\\ \hline
    TBM & 4 & 24 & 25 & 28\\ \hline
    TBM & 5 & 32 & 33 & 36\\ \hline
    TBM & 6 & 40 & 41 & 44\\ \hline
    TBM & 7 & 64 & 65 & 68\\ \hline
    TBM & 8 & 112 & 113 & 116\\ \hline
    BSPL & --- & 48 & 49 & 52\\ \hline
    \end{tabular}
	\caption{Velikosti datových struktur v závislosti na počtu směrovacích pravidel a velikosti střídy}
    \label{tab:lpm-input}
\end{table}

Jak je vidět ve výše uvedené tabulce tak i přestože nejrychlejší implementací je TreeBitmap se střídou 5,
tak v případě omezené paměti by bylo vhodnější zvolit kompromis mezi rychlostí a paměťovou náročností v podobě
TreeBitmap s velikostí střídy 4. Dalším ovlivňujícím faktorem je odhadovaný počet záznamů směrovací tabulky, protože
nejrychlejší TBM-5 při existenci všech struktur na všech úrovních bude činit rozdíl zabraného místa oproti TBM4
celých $TODO dopočítat KB$, což je v kontextu FPGA nezanedbatelné množství.

\section{Hledání řetězců} % #####################################################################################
Benchmark pro hledání řetězců byl proveden na dvou vstupních testovacích sadách,
kde první sada \texttt{fallbacks} obsahuje slova s výskytem stejných písmen, tutíž při tvorbě konečného automatu bude
docházet ke generování failure přechodů, jež budou poté procházeny. Druhá testovací sada \texttt{no-fallbacks}
obsahuje slova, které nemají stejná písmena. Výsledky dosažené pro jednotlivé testovací sady jsou
vyzualizovány v grafi \ref{fig:pm}.

Dopsat na jakých datech byl benchmark proveden
\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=0.7]{fig/pm.pdf}
	\caption{Benchmark pro knihovnu pm}
    \label{fig:pm}
\end{figure}

Velikost každého stavu konečného automatu je v této implementaci $48B$
a podobně jako LPM je závislá na počtu vložených pravidel.

\section{Hledání regulárních výrazů} % ###############################################################################

Jak je vidět na v grafu \ref{fig:regex} tak hledání regulárních výrazů pomocí deterministického
konečného automatu je řádově pomalejší. Toto zpomalení je způsobené opakovaným generování
epsilon přechodů pro všechny vstupní stavy. Vstupní stavy jsou na začátku procházení
startovní stavy všech výrazů, které byly předány do funkce \texttt{regex\_construct\_nfa}.

Procházení založené na deterministickém konečném automatu tímto problémem netrpí,
neboť při zpracování každého vstupního symbolu dojde k přechodu do dalšího stavu v případě
vstupního symbolu, který se může vyskytnou v aktuálním stavu automatu nebo do počátečního stavu
pokud vstupní symbol nejde zpracovat v rámci regulárního výrazu.

Dopsat na jakých datech byl benchmark proveden

\begin{figure}[!htbp]
	\centering
	\includegraphics[scale=0.7]{fig/regex.pdf}
	\caption{Benchmark pro knihovnu regex}
    \label{fig:regex}
\end{figure}

Velikost datových struktur pro jednotlivé stavy konečného automato pro deterministický a nedeterministický
automat je znázorněna v tabulce \ref{tab:regex-size}.

\begin{table}[!htbp]
    \center
    \begin{tabular}{|l|l|}
    \hline
    Typ automatu & Velikost stavu\\ \hhline{|=|=|}
    deterministický  & 24\\ \hline
    nedeterministický & 40\\ \hline
    \end{tabular}
    \caption{Velikosti stavů konečného automatu}
    \label{tab:regex-size}
\end{table}

\chapter{Závěr}\label{chapter:conclusion} % ########################################################################
Cílem této práce bylo popsat a navrhnout aplikační programové rozhraní časově kritické operace v oblasti počítačových sítí,
konkrétně vyhledání nejdelšího shodného prefixu za využití algoritmů Binary search on prefix length
a TreeBitmap. Operace používané na směrovačích pro zjištění jakou cestou směrovat přicházející pakety.
Dalšími operacemi jsou hledání řetězců a hledání regulárních výrazů v paketech a jejich datech.
Pro operaci hledání řetězců je to konkrétně algoritmus Aho-Corasick \cite{aho} umožňují v
při jednom průchodu vstupními daty vyhodnotit zda se v datech nacházejí specifikovaná klíčová slova
a poté hledání regulárních výrazů. Obě zmíněné operace jsou používané v paketových filtrech,
které tvoří jádro systémů pro detekci útoků (IDS) a prevenci útoků (IPS). Do skupiny těchto
systémů patří firewally jak softwarové tak hardwarové. Mezi další operace operace pak patří
analýza a extrakce hlaviček paketů a obecná klasifikace paketů.

Dále je to pak implementace operací hledání nejdelšího shodného prefixu, hledání řetězců
a hledání regulárních výrazů. Při implementaci bylo dosaženo rychlosti zpracování N paketů za sekundu
při velikosti $100000$ záznamů routovací tabulky pro IP adresy verze 4 a N paketů/sekunda při velikosti
routovací tabulky $10000$ pro IP adresy verze 6. Pro operaci hledání podřetězců bylo
do dosaženo rychlosti zpracování N paketů za sekundu v závislosti na počtu shodných písmen
při lineární náročnosti v závislosti na velikost dat v paketech. Experimentování bylo prováděno
na vzorku dat odchycených ze standardního síťového provozu jednoho osobního počítače. Jako vzorek
testovaných klíčových slov bylo využito klíčových definovaných pro HTTP\footnote{Hyper-text transfer protocol}.
Pří experimentování s regulárními výrazy byly jako vstupní data použita stejná data jako pro hledání řetězců,
ale jako regulární výraz byly použity matchování URL\footnote{Uniform resource locator} adres.

Jako kroky navazující na tuto práci je možné implementovat zbývající operace, které implementovány nebyly.
Těmito operacemi je klasifikace paketů a analýza a extrakce hlaviček paketů.

Ze specifikace požadavků na implementaci knihovny v nízkoúrovňovém jazyce C je zřejmé,
že knihovna bude používána i na vestavěných systémech disponujících omezenou pamětí a z toho
důvodu by jedním z dalších kroků mohlo být formální testování s nedostatkem paměti.
To by mohlo dát rozsahem na celou další práci. Je nutné ověřit, že knihovna bude
reagovat správným způsob a nezpůsobí pád systému v rámci kterého je spouštěna.

zmínit někde vláknové zpracování
