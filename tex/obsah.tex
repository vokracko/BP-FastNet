%=========================================================================

\chapter{Úvod}
Žijeme v době kdy se internet stal nedílnou součástí každodenního života.
 Také se stávají populární mobilní zařízení schopná internetové komunikace a na vzestupu je trend
internetu věcí. Internetem věcí se rozumí vestavěná zařízení schopná komunikace po internetu.
S rychlostí jakou přibývají zařízení vyžadující přístup k internetu ale i s rozšiřováním internetu
do zemí internetem nedotčených se neustále zvyšují požadavky na rychlost, se kterou data prochází počítačovými
sítěmi a zejména na zařízeních starajících se o řízení internetového provozu na páteřních linkách
počítačových sítí. Páteřní spoje v době psaní této práce dosahují rychlosti desítky gigabitů
za vteřinu a z toho vyplívají požadavky na rychlost zpracování síťových dat. Při těchto rychlostech
však tradiční procesory stihnou vykonat pouze několik instrukcí. Nicméné je důležité
aby rychlosti zpracování dosahovaly všechny zařízení na páteřních spojích jinak by došlo ke
spomalení veškerého provozu a toto zařízení by se stalo tzv. úzkým hrdlem. Z těchto vlastností vychází
požadavky na stále efektivnější algoritmy zpracovávající tyto operace.
Tyto operace se nazývají časově kritické operace a jejich rozbor je jedním z témat této práce.
Dalším tématem této práce je návrh aplikačního programovatelného rozhraní knihovny, která bude implementovat
právě tyto operace. Z časově kritických operací jsou vybrány a rozvedeny operace hledání nejdelšího shodného prefixu,
využívaných pro směrování dat v počítačových sítích, prohledávání vstupních dat na přítomnost
definovaných slov pomocí vyhledávání řetězců nebo hledání regulárních výrazů, analýza a extrakce hlaviček paketů,
operace používané napříč téměř všemy časově kritickými operacemi a klasifikace paketů,

Přínosem této knihovny je vlastní implementace zmíněných operací, která může sloužit jako vzor
pro hardwarovou implementaci nekritičtějším částí zmíněných operací.

V kapitole \ref{chapter:theoretical} jsou popsány síťové modely, nad nimiž jsou operace této knihovny implementovány,
formální prostředky pro implementaci zvolených algoritmů a samotné algoritmy. Kapitola \ref{chapter:api} popisuje
veřejné rozhraní vytvořené knihovny pro operace zmíněné v kapitole \ref{chapter:theoretical},
způsoby použití a možnosti rozšíření. V kapitole \ref{chapter:results} jsou vizualizovány a popsány
výsledky implementace. Kapitola \ref{chapter:conclusion} shrnuje dosažené výsledky a nastiňuje možné směry,
kterými se může vývoj knihovny dále odvíjet.

\paragraph{Co zmínit}
- všchny prvky musí pracovat na stejných rychlostech
- zvyšuje se rychlost -> nutná optimalizace, fpga
- požadavky na monitorování a blokování
- ipv4, ipv6, velikost adresového prostoru
- pomalé procesory -> směř fpga, jak je na to knihovna přpravena
- koncept multithreadingu
- hlavní síťové prvky
- páteřní sítě
- pakety
- půlstrana motivace proč je to důležité
- přínos knihovny a operace

\chapter{Teoretický rozbor}\label{chapter:theoretical}

\paragraph{Co zmínit}
- složitost síťového provozu, proto vrstvy
- něco o kritických operacích
- proč jsou důležité
- popsat další kapitoly

\section{Síťové modely}

Zpracování dat síťového provozu je rozděleno do několika úrovní. Tyto úrovně jsou popsány síťovými modely.
Základním modelem je ISO/OSI, který slouží pro abstraktní rozdělení operací zpracování síťových dat a jeho použití je
pouze pro akademické účely. V reálných počítačových sítích pak dominuje model TCP/IP, který má oproti
ISO/OSI modelu menší počet vrstev. Modelu ISO/OSI je rozdělen na sedm vrstev. V pořadí od nejnižší úrovně to
jsou vrstvy fyzická, linková, síťová, transportní, relační, prezentační a aplikační. Pro tuto práci jsou
podstatné pouze první čtyři vrsty. Ty jsou detailněji popsány v kapitolách \ref{layers:physical},
\ref{layers:link}, \ref{layers:network} a \ref{layers:transport}. Na obrázku \ref{fig:layers} je
znázorněn průchod dat jednotlivými vrstvamy modelu ISO/OSI. Jak je z obrázku patrné tak ne všechny síťové
zařízení pracují na stejných vrstvách.

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=.25]{fig/layers.pdf}
	\caption{Znázornění průchodu dat počítačovou sítí v modelu ISO/OSI}
\end{figure}\label{fig:layers}

\subsection{Fyzická vrstva / Vrstva síťového rozhraní}\label{layers:physical}
Nejnižší vrstva ISO/OSI modelu pracuje s daty na úrovni bitů a stará se o
jejich přenos po přenosovém médiu. Protokoly této vrstvy definují signály, které reprezentují data
a tudíž jde o protokoly implementované již v hardware síťových zařízení.

\subsection{Linková vrstva}\label{layers:link}
Linková vrstva je druhá nejnižší ISO/OSI modelu. Tato vrstva se stará o datovou komunikaci
obecně mezi několika uzly, které jsou přímo spojeny. Spojení může být jak fyzickým vodičem tak i
bezdrátovou technologií. Nejrozšířenější technologií pro fyzické spoje je Ethernet IEEE 802.3, pro bezdrátové spoje
je to standard IEEE 802.11. Datová jednotka na linkové vrstvě se nazývá rámec a nese v sobě kromě
zapouzdřených dat vyšších vrstev také informace o kontrolním součtu dat a adresování pomocí MAC adres.
MAC adresa je adresa fyzického zařízení, které pracuje na této vrstvě.
Adresování MAC adresou slouží pro identifikaci zařízení, které se nacházejí ve stejné počítačové síti
a za hranici této sítě se již používá IP adresace, které je vysvětleno v necházející kapitole \ref{layers:network}
Síťová zařizení pracující na této vrstvě se nazývaji switche. Úkolem switchů je zjistit MAC adresu cílové stanice a přeposlat je portem, který vede k tomuto zařízení.

\subsection{Síťová vrstva}\label{layers:network}
Na této vrstvě probíhá komunikace za využití IP adres. Prvky používané na této vrstvě jsou nazývaný routery.
Účelem těcho zařízení je směrování paketů procházejících sítí. K tomu využívají směrovací tabulku.
Právě pro problém vyhledání nejdelšího shodného prefixu v routovací tabulce směrovače jsou v této knihovně
implementovány dva algoritmy, \texttt{Binary search on prefix length} \ref{} a \texttt{TreeBitmap} \ref{}.
Datové struktury jsou pojmenované pakety. Pakety obsahují imformace o datovém toku a také zrojové a cílové adresy (IPv4 nebo IPv6) právě tohoto paketu.

\subsection{Transportní vrstva}\label{layers:transport}
Transportní vrstva pracuje s datovou strukturou zvanou segmenty.
Obsahují informace jako je kontrolní součet pro zjištění integrity dat,
pořadové číslo rámce pro spojení dat, která byla na cestě k cíli rozdělena na více částí a také obsahuje čísla portů
pro určení uživatelských aplikací, která data odeslala a která je na druhém konci má přijmout.
Na transportní vrstvě se používají dva protokoly a to TCP a UDP. UDP má nižší režii ale zase je nespolihvé.
To znamená že paket do cílového zařízení nemusí vůbec dorazit a nebo můžé dorazit v jiném pořadí než byl ze
zdrojové stanice odeslán. Situace ve kterých pozitiva jako nižší režie přebyjí zápory je hlavně přenos dat v
reálném čase. To je například streamování videa, přenost hlasu technologie VoIP a přenos informací do online her.
Spolehlivý protokol TCPzaručuje, že všechna data budou přenesena a v cílové stanici se seřadí do
stejné posloupnosti v jaké byla odeslána. Důvodem proč se data mohou rozdělit je nestabilní cesta,
po které jsou data v síti směrována. Při přenosu jednoho toku dat se může stát že se jedna cesta po které se
již poslala část dat stane nedostupnout a místo toho se data začnou směrovat přes jiná zařízení.

Zpracování dat na úrovni transportní vrstvy a všech vyšších vrstev není implementováno na síťových
zařízeních starajících se přenost dat po síti. Jediná zařízení, které implementují zpracování
dat těchto vrstev jsou koncová zařízení.

\section{Časově kritické operace}
Pod pojmem časově kritické operace se rozumí takové operace, které je typicky nutné provádět
na více síťových zařízeních. Těmito zařizeními mouhou být routery, switche firewally a také systémy
oddělené od řízení síťového provozu jako například sondy pouze monitorující síťový provoz
nebo analyzátory, které mohou hledat signatury útoků v datových tocích.
Mezi časově kritické operace rozebrané v této práci patří klasifikace paketů a velký důraz je kladen specielně na
jednodimenziální klasifikaci dle cílové IP adresy, vyhledávání nejdelšího shodného prefixu.
Tato operace je využívána pro směrování na routerech.
Dalšími z operací je hledání podřetězců a hledání regulárních výrazů. Poslední dvě zmíněné operace
slouží především pro detekci útoků v systémech IDS (intrusion detection system) a pro prevenci útoků v systémech
IPS (intrusion prevention system).

\paragraph{Co zmínit}
- co jsou tyto operace
- na čem staví algoritmy
- proč jsou kritické
- zvyšování požadavků
- rychlost zpracování
- počet instrukcí při  různých rychlostech

\subsection{Hledání nejdelšího společného prefixu - Longest prefix matching}
Problém hledání nejdelšího shodného prefixu se rozumí klasifikace paketů dle jejich cílové IP adresy,
která může být jak verze 4, tak verze 6.

Tato operace je základním stavebním kamenem v počítačových sítích a bez ní by bylo téměř nemožné dosahovat
efektivity jaké se dosahuje teď. Hledání nejdelšího shodného prefixu je operace, která se provádí
na síťových prvcích zvaných směrovače. Tyto prvky jsou umístěny na každém rozhraní dvou a více
počítačových sítích. Jejich cílem je nalézt nejvhodnější cestu, kterou směrovat příchozí paket.
Struktura reprezentující uložené směrovací informace se nazývá routovací tabulka. Tato tabulka ukládá
informace o dostupných sítích (jejich prefixech), délce tohoto prefixu a rozhraní, kterým se lze
do odpovídající počítačové sítě dostat. S velkým rozmachem počíačových sítí v poslední dekádě
dochází k velkému nárustu routovací informací a proto se tímto směrem začal ubírat akademický výzkum.
Pro zmenšení routovacích tabulek byl navržen takzvaný supernetting, který sdružuje sítě se stejným
prefixem o jiných délkách a stejnou cestou do jedné sítě. Tím je dosaženo zmenšení routovacích tabulek,
nicméně i tak je potřeba v routovacích tabulkách vyhledávat efektivně.

Nejdelší shodný prefix se zapisuje jako $1001*$ a tento zápis reprezentuje všechny IP adresy,
které v binární podobě začínají právě na hodnotou $1001$. Nicméně v routovací tabulce
může být uložen i prefix $10010*$, který sdílí první čtyři bity své adresy s výše uvedeným příkladem,
a přípaďě, že přijde paket začínající hodnotou $10010$ je z pohledu směrování vyhodnotit prefix B jako
nejdelší a poté paket správně směrovat. V případě $10011$ je však nejdelším shodným prefixem pravidlo A
a tudíž nesmí dojít k vyhodnocení prefixu B jako nejdelšího. Z toho důvodu je nutné ve směrovací tabulce
uchovávat i informace o délce prefixu. Tato informace poté slouží pro rozhodnutí, jaký pravidlo
routovací tabulky má nejdelší shodný prefix. Délká prefixu může nabývat hodnot $1-32$ pro adresy typu
IPv4 a $1-128$ pro adresy typu IPv6. Z výše uvedených tvrzení je zřejmé, že pro každý typ
IP adres musí existovat samostatná, oddělená routovací tabulka, jinak by mohlo docházet k nevalidním
vyhodnocení nejdelšího shodného prefixu mezi IPv4 a IPv6 adresami. Jako příklad může sloužit následující
situace

100* 3 R1 IPv4\
100* 3 R7 IPv6\

Teoreticky by bylo možné ukládat různé typy prefixů do stejných datových struktur pro algoritmus
Binary search on prefix length, nicméně by bylo nutné explicitně rozlišovat o jaký typ IP adresy se
jedná a to by mělo negativní vliv na rychlost vyhledávání. To je právě kritický paramter, který
se snažíme minimalizovat.

Pro hledání nejdelšího shodného prefixu existuje velké množství algortimů, které jsou popsány v \cite{}
Většina z nich je založena na procházení stromové struktury. Každý algoritmus má jiné paměťové nároky
a dosahuje jiných rychlostí. Je nutné zvolit kompromis mezi rychlostí a paměťovou náročností.
V připadě že jde o implementaci na architektuře FPGA důraz bude pravděpodobně kladen na paměťovou náročnost
a to z důvodu, že tyto čipy mají specializované paměti. Tady bych zmínil asociativní paměť, kterou
lze přímo použít pro vyhledávání. Na architekturách vycházejících z x86 je naopak kladen důraz
na rychlost zpracování z důvodů obecných procesorů, které nejsou specializovány na tyto operace
ale naopak zase disponují standardními paměťmy, které jsou lehce škálovatelné a dosahují kapacit
řádově převyšující nároky jednotlivých algoritmů.

Algoritmy rozehrané v této kapitole vycházejí z obecně n-árního stromu,
což je rozšíření binárního stromu na více než dva potomky. Těmito algoritmy jsou
\texttt{Binary search on prefix length}, jehož data jsou uložena v binárním stromu, ale pro vyhledávání
je využito výhod hašovací tabulky, a \texttt{TreeBitmap}, který je n-árním stromem, kde n je volitelné.
Dosažené výsledky pro různé n jsou vizualizovány v kapitole \ref{}.

První algoritmus hledání nejdelšího shodného prefixu byl založen na naivním procházení lineárního
seznamu a byl publikován v knížce X v roce Z. Jak si čtenář může dovtípit do vyhledání
byla závislá na počtu uložených prefixů a její časová složitost byla $O(N)$.
Algoritmy popsané a implementované v rámci této práce se minimalizují dobu vyhledávání v závislosti
na počtu prefixů v routovací tabulce. V případě binary search on prefix length je tato závislost
omezená vlastnostmi hašovací funkce. Pokud je zvolena špatná hašovací funkce bude docházet ke kolizím
a v případě nefunkční hašovací funkce (generuje stejný výsledky pro řůzné prefixy)
ořezán na prosté procházení lineárního seznamu.


\paragraph{Co zmínit}
- jaké jsou známené algoritmy
- hašovací funkce
- výhody/nevýhody těchto algoritmů
- první algoritmus
- směrovací protokoly
- co obsahuje směrovací tabulka
- jedna adresa může odpovídat více záznamům
- příklad směrovací tabulky s stejnými adresami a různou délkou
- délka je počet bitů adresy sítě
- umísťění zařízení má vliv na velikost tabulky - nějaký příklad?
- sekvenční vyhledávání v seznamu
- TCAM, asociativní paměť?
- trie struktura?
- binární trie
- multibitový trie
- klíč je určen implicitně pozicí ve stromu a ne explicitně


\subsubsection{TreeBitmap}

Algoritmus TreeBitmap cy

Interní bitmapa zahrnuje všechny všechny prefixy, které je možné vyjádřit na N bitech střídy.
Jako příklad může posloužit velikost střidy 2 bity.
Proto je nutné uložit všechny tyto kombinace: $0*$, $1*$, $00*$, $01*$, $10*$ a $11*$.
Z toho lze odvodit vzorec pro počet bitů nutných pro reprezentaci všeh možný stříd.
$$2^{N + 1}$$
kde N je velikost střídy.

a velikost externí bitmapy jako
$$2^N$$
kde N je velikost střídy.


Struktura pro uložení prefixu se skládá z položek interní bitmapy, externí bitmapy, ukazatele na potomky
a ukazatele na pravidla.

Interní bitmapa slouží pro zjištění, kolik pravidel existuje v tomto uzlu.
To se zjistí zavolání funkce \texttt{ones(internal-bitmap, end)}. kde end pozice, která odpovídá
části prefixu o délce střídy.
To znamená že pokud po vykousnutí střídy z prefixu dostaneme bity
$11$ pozice end bude stanovena na decimální reprezentaci tohoto čísla, v tomto případě $3$.
Následuje zjištění, zda se na dané pozici interní bitmapy vykytuje jednička nebo nula.
V případě, že je tam nula se neděje nic a algoritmus pokračuje zjišťováním, zda existuje
cesta stromem dál z externí bitmapy jak je vysvětleno v následujícím odstavci.

Pokud je tam jednička tak algoritmus spočítá funkci ones na interní bitmapě a uloží si vypočítanou
hodnotu. Dále si také uloží odkaz do tabulky pravidel.

Pokud tam není jednička, tak se postupně odebírají méně významné bity vykousnuté v prefixu a v cyklu se provádí
zjišťování zda je tam jednička nebo ne. Tento cyklus je ukončen v případě, že se narazí na nultou pozici
nebo je nalezena jednička.

V přípaďě že již neexisuje další cesta stromem je algoritmus vyhledávání ukončen a jako výsledek
je navrácena hodnota uložená ukazateli na nejlepší pravidla s index, který je uložen také.

Externí bitmapa slouží pro zjíštění, zda existuje cesta ve stromu, která odpovídá vyzobnutému prefixu.
Index do pole následovníků je vypočítán jako \texttt{ones(external-bitmap, end)}. V případě,
že pro vyzobnuté bity neexistuje následovník je navráceno pravidlo, které bylo zjištěno z interní bitmapy.

Funkce \texttt{ones(bitmap, end)} spočítá všechny bity, které jsou nastaveny na jedničku v rozmezí $<0, end)$.
Toto je implementuje jako bitová operace \texttt{AND} a maskou, která reprezentuje právě počet pozic, které se
mají vypočítat. Samotné zjištění počtu jedniček lze řešit několika způsoby, v implementaci této knihovny
je zvoleno volání vestavěné funkce překladače \texttt{popcount}, které se při překladu převede na nejefektivnější
instrukce cílové platformy.

Algoritmus v pseudokódu je možné vidět v \ref{alg:treebitmap}.

Příklad bitmap pro uložení prefixů:

\begin{table}
	\center
	\label{tab:tbm-internal}
    \begin{tabular}{|l||c|c|c|c|c|c|c|}
    \hline
    Prefix & $*$ & $0*$ & $1*$ & $00*$ & $01*$ & $10*$ & $11*$ \\ \hline
    Pravidlo & 0 & 0  & 1  & 0   & 0   & 1   & 1   \\ \hline
    \end{tabular}
    \caption{Příklad interní bitmapy}
\end{table}

\begin{table}
	\center
	\label{tab:tbm-external}
    \begin{tabular}{|l||c|c|c|c|}
    \hline
    Prefix & $00*$ & $01*$ & $10*$ & $11*$ \\ \hline
    Pravidlo & 1 & 0 & 1 & 0 \\ \hline
    \end{tabular}
    \caption{Příklad externí bitmapy}
\end{table}

\begin{algorithm}
	\label{alg:treebitmap}
	\KwData{tbm-root, ip, ip-length}
	\KwResult{routing rule}
	node $\leftarrow$ tbm-root\;
	position $\leftarrow$ 0\;
	\Repeat{BIT(parent.external, bits)}
	{
		bits $\leftarrow$ get-stride-bits(ip, position, prefix-length)\;
		position $\leftarrow$ position + STRIDE\;

		\If{isRule(node.internal, bits)}
		{
			longest-match = node\;
		}

		index $\leftarrow$ ones(node.external, bits)\;
		parent $\leftarrow$ node\;
		node $\leftarrow$ node.external[index]\;
	}
	\Return longest-match\;
	\caption{Hledání nejdelšího shodného prefixu algoritmem TreeBitmap}
\end{algorithm}

Treebitmap je šetrný k paměti a alokuje si pouze tolik prvků pole ať už pro uložení pravidel
nebo pro uložení následovník kolik jich je opravdu potřeba.

Z \cite{tbm} vyplívá, že je vhodné nastavit velikost střídy v rozmezí 2 - 8 bitů. Což je také rozmezí,
na které je sousředěna a otestována implementace TreeBitmap v této knihovně. Experimentálně bylo zjišténo,
že tato implementace je funkční až do velikost střídy 13bitů.

\paragraph{Co zmínit}
- procházení interních a externích bitmap, struktura interní a externí bitmapy
- alokace všech násldovníků a pravidel na jednou v jednom místě
- funkce jedniček

\subsubsection{Binary search on prefix length}

Operace vyhledání nejdelšího prefixu při využití algoritmu binary search on prefix length má časovou
složitost $\log{2}{N}$, kde \texttt{N} je počet bitů adresy. V případě IPv4 adresy je to 32 bitů a pro IPv6
adresu je to 128 bitů. Z principu algoritmu vyplívá, že nejhorší výsledky z časového hlediska bude dosahovat
při shodě prefixu, který byl zadán s lichou délkou. V tomto případě bude nutné projít všemy kroky.
Počet kroků v případě IPv4 bude 5 a v případě IPv6 adresy to pak bude 7.
Zde je vidět že i v připadě čtyřikrát delší adresy se počet kroků pro vyhledání prefixu zvedne pouze o dva,
což neplatí pro algoritmus TreeBitmap, který musí projít v nejhorším případě až čtyřikrát více
uzlů aby nalezl odpovídající prefix.
\cite{bspl}

\begin{algorithm}
	\KwData{bspl-root, hash-table, ip, ip-length}
	\KwResult{routing rule}
	prefix-length $\leftarrow$ ip-length\;
	prefix-change $\leftarrow$ ip-length\;
	\Repeat{prefix-change > 0}
	{
		bits $\leftarrow$ get-prefix-bits(ip, prefix-length)\;
		item $\leftarrow$ hast-table.get(bits)\;
		prefix-change $\leftarrow$ prefix-change \texttt{>>} 1\;

		\If{item == NULL}{prefix-length $\leftarrow$ prefix-length - prefix-change\;}
		\ElseIf{item.type == PREFIX}{prefix-length $\leftarrow$ prefix-length + prefix-change\;}
		\lElse{break}
	}
	\lIf{item == NULL}{\Return bspl-root.default-rule}
	\caption{Hledání nejdelšího shodného prefixu algoritmem Binary search on prefix length}
\end{algorithm}

\paragraph{Co zmínit}
- leaf-pushing?

\subsection{Hledání řetězců}
V počítačových sítích je často vyžadováno hledání řetězců v síťovém provozu ať už z důvodu monitorování
nebo blokování provozu, který obsahuje určité řetězce. Blokování může probíhat na úrovni obsahu, například
blokování určitých webových stránek ať už z důvodů rodičovské kontroly nebo například omezení provozu
netýkajícího se výuky ve školních sítích. Nebo může jít o blokování určitého druhu síťového provozu,
který obsahuje nedovolené nebo podezřelé signatury. Pokud se vzdálí ze síťového provozu tak
důvodem pro vznik těchto algoritmů je hledání v textových datech. I z tohoto důvodu vznikl
algoritmus Aho-Corasick, který je v této knihovně implementován a původně byl navržen
právě pro hledání klíčových slov v odborných publikacích.

Pro hledání řetězců je implementován algoritmus autorů Aho a Corasicové. Tento algoritmus používá pro zjištění shody s podřetězcem konceptu konečného automatu. Při každé iteraci algoritmu se provede přechod o jeden znak.

Algoritmus procházení vstupních dat je rozepsán v \ref{alg:aho} a vychází z \cite{aho}.

\begin{algorithm}
	\KwData{start-state, text}
	\KwResult{keyword}
	state = start-state\;
	\For{position $\leftarrow$ 0 \KwTo text.length}
	{
		\lWhile{goto(state, text[position]) == FAIL}{state $\leftarrow$ state.failure}
		\lIf{state.isMatch}{\Return state.keyword}
	}
	\Return NOT-MATCH\;
	\caption{Algoritmus procházení textu a hledání podřetězců}
\end{algorithm}\label{alg:aho}

Při chybě alokace se smaže celá struktura konečeného automatu, neexistuje předpoklad na dynamické přidávání pravidel za běhu programu

\subsection{Hledání regulárních výrazů}

Regulární výrazy slouží pro popis operací nad jazykem.
Jazek je definovaný jako iterace nad vstupní abecedou.
Iterace může  být neutrální nebo kladná.
V neutrální iteraci jazyka je oproti pozitivní iteraci zahrnut i symbol $\epsilon$,
který reprezentuje prázdný znak/řetězec.
Iterace jazyka se označuje jako $L^n$ kde \texttt{n} je označení iterace jazyka.
iterace $L^0$ obsahuje pouze jeden symbol a tím je $\epsilon$
$\epsilon$ také reprezentuje prázdný řetězec. Prázdný řetězec se může skládat z nekonečné posloupnosti $\epsilon$
Vstupní abeceda je množina symbolů.

Regulární výrazy jsou poté operace nad regulárními jazyky.
Regulární výrazy mají stejnou  vyjadřovací schopnost jako konečné automaty a pro digitální zpracování
regulárních výrazů se vždy používají konečné automaty.

Operace regulárních výrazů jsou následující

\begin{itemize}
	\item{$\emptyset$ je regulární výraz reprezentující prázdnou množinu}
	\item{$\epsilon$ je regulární výraz reprezentující $\{\epsilon\}$}
	\item{$a, a \in \Sigma$ je regulární výraz reprezentující $\{a\}$}
	\item{$(r \cdot s)$ je regulární výraz reprezentující $RS$}
	\item{$(r | s)$ je regulární výraz reprezentující $R \cup S$}
	\item{$(r*)$ je regulární výraz reprezentující R*}
 % todo zdroj https://books.google.cz/books?id=s7gEErax71cC&vq=determinization&hl=cs&source=gbs_navlinks_s
\end{itemize}

Znak operace konkatenace % TODO přidat referenci na item nahoře
se čast vynechává a je uvažován implicitně.

Regulární výrazy implementované v této knihovně rozšiřují množinu operací tři nové druhy zápisu,
které jsou pouze pohodlněji zapsatelná a nijak nerozšiřují výrazové možnosti regulárníčh výrazů.

\begin{itemize}
	\item{$[abc]$ je výčet znaků, které se na vstupu mohou vyskytnout a automat je v aktuální stavu dokáže zpracovat. Je to zkrácený tvar zápisu $(a|b|c)$}
	\item{$a+$ je definováno jako pozitiní iterace, tedy $1..N$ opakování}
	\item{$a?$ je definováno jako $0..1$ iterací}
\end{itemize}

Regulární jazyky se podobně jako \ref{section:pm} používají pro monitorování a blokování dat procházejících
počítačovými sítěmi. Zařizení využívající těchto operací jsou typicky firewally, a to jak hardwarové tak i jejich
softwarové implementace.

Při chybě alokace se smaže celá struktura regulárního výrazu, neexistuje předpoklad na
dynamické přidávání regulárních výrazů za běhu programu.


\subsection{Analýza a extrakce hlaviček paketů - Header parsing}

Extrakce hlaviček paketů je velmi častá operace.
V případě hledání nejdelšího shodného prefixu je potřeba nejprve provést extrakci
cílové adresy a až poté je možné zahájit vyhledávaní cesty, kterou bude packet směrován.
Z toho vyplívá přímá závislost rychlosti všech operací pracující s položkami hlavičky jak paketů
na úrovní síťové vrstvy \ref{layers:network} tak i rámců na úrovni linkové vrstvy \ref{layers:link}
a segmentů na úrovni transportní vrstvy \ref{layers:transport}.

V rámci výzkumu byly navrženy způsoby hardwarové akcelerace na zařízeních typu FPGA \ref{} na publikaci
z ANT.

V rámci LPM je stačí extrahovat pouze jednu položku IP hlaviček,
nicméně v obecné klasifikaci paketů jsou potřeba i další položky jako zdrojová adresa,
cílový port, typ transportního protokolu.



\chapter{Návrh API knihovny}\label{chapter:api}
Knhovna \texttt{fastnet} je navržena jako množina menších knihoven, kde každá knihovna implementuje
jednu operaci používanou při zpracování síťového provozu.
Tímto návrhem je dosaženo snadné rozšiřitelnosti o další operace, jako například extrakce informací z hlaviček paketů
\i{packer header extraction} nebo klasifikace paketů \texttt{packet clasification}.
Mezi implementované operace patří vyhledání nejdelšího shodného prefix \texttt{longest prefix match} \ref{},
hledání podřetězeců \texttt{pattern matching} a regulární výrazy \texttt{regular expressions}.
Pro vyhledání nejdelšího shodného prefixu jsou implementovány algoritmy
\texttt{Binary search on prefix length}\ref{bspl} a \texttt{Tree Bitmap}\ref{tbm}.
Hledání podřetězců je implementováno algoritmem \texttt{Aho-Corasick}\ref{ac}.
Regulární výrazy jsou řešeny nedeterministickým i deterministickým konečným automatem.

Další výhodou tohoto rozdělení je možnost snadno vytvořit a používat jednotlivé podknihovny samostatně.
To se může hodit pro zařízení, která mají velmi limitované paměťové ůložiště a jejich účelem
je řešit pouze jednu ze zmíněných operací.

Veřejné rozhraní knihovny se skládá z veřejných rozhraní jednotlivých podknihoven.
Tyto rozhraní jsou popsány v následujících podkapitolách.

\section{Vyhledání nejdelšího shodného prefixu}
Pro operaci vyhledání nejdelšího shodného prefixu jsou připraveny funkce pro inicializace datových struktur
\texttt{lpm\_init}, pro vložení nového prefixu \texttt{lpm\_add}, aktualizaci existujícího prefixu
\texttt{lpm\_update}, smazání existujícího prefixu \texttt{lpm\_remove} a zrušení všech alokovaných
datových struktur \texttt{lpm\_destroy}. Jak již bylo zmíněno je nutno uchovávat zvlášť tabulky
pro IPv4 a IPv6 adresay a z toho důvodu jsou existují všechny výše uvedené funkce i ve variantě
pro IPv6. Jediným rozdílem pak je že je všechny funcke a datové struktury mají místo prefixu
\texttt{lpm\_} prefix \texttt{lpm6\_}.

Všechny funkce kromě \texttt{lpm\_init} pracují s paramterem typu \texttt{lpm\_root}, který reprezentuje
celou datovou strukturu. Tato implementace vychází z požadavku mít možnost využívat více routovací
tabulek nebo tyto struktury využít pro jiné typy klasifikace.

Funkce pro vložení, smazání a aktualizci pravidel a prefixů také obsahují parametr
prefix, který je buď IPv4 nebo IPv6 adresa. Dalším parametrem těchto funkcí je délka prefixu,
aby bylo možné odlišit jednotlivé prefixy od sebe. Tam může dojít ke kolizi pokud existuje
prefix $1*$ o délce jedna a prefix $10000*$ o délce pět, neboť tyto prefixu budou reprezentovány stejným
číslem, neboť v binární kódu máme pouze dvě hodnoty a není možné určit třetí stav jako X,
nezajímá nás/není důležité.


Hašóvací funkce je v této implementaci použita henkins \ref{}. Volba správné hašovací funkce
má má velký vliv na rychlost vyhledávání. V případě kolizí je to omezeno zase na procházení lineárního
seznamu a z časové složitosti $O(\log{2}{N}$, kde N reprezentuje délku adresy, tedy 32 nebo 128 bitů,
se stává $O(N)$, kde N reprezentuje počet záznumů routovací tabulky.

% LPM IPV4 =================================================================================
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{lpm\PYZus{}root} \PY{o}{*} \PY{n+nf}{lpm\PYZus{}init}\PY{p}{(}\PY{n}{\PYZus{}LPM\PYZus{}RULE} \PY{n}{default\PYZus{}rule}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{\PYZus{}Bool} \PY{n+nf}{lpm\PYZus{}add}\PY{p}{(}\PY{n}{lpm\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k}{struct} \PY{n}{in\PYZus{}addr} \PY{o}{*} \PY{n}{prefix}\PY{p}{,} \PY{k+kt}{uint8\PYZus{}t} \PY{n}{prefix\PYZus{}len}\PY{p}{,} \PY{n}{\PYZus{}LPM\PYZus{}RULE} \PY{n}{rule}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{lpm\PYZus{}update}\PY{p}{(}\PY{n}{lpm\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k}{struct} \PY{n}{in\PYZus{}addr} \PY{o}{*} \PY{n}{prefix}\PY{p}{,} \PY{k+kt}{uint8\PYZus{}t} \PY{n}{prefix\PYZus{}len}\PY{p}{,} \PY{n}{\PYZus{}LPM\PYZus{}RULE} \PY{n}{rule}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{lpm\PYZus{}remove}\PY{p}{(}\PY{n}{lpm\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k}{struct} \PY{n}{in\PYZus{}addr} \PY{o}{*} \PY{n}{prefix}\PY{p}{,} \PY{k+kt}{uint8\PYZus{}t} \PY{n}{prefix\PYZus{}len}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{lpm\PYZus{}destroy}\PY{p}{(}\PY{n}{lpm\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{)}\PY{p}{;}
\PY{n}{\PYZus{}LPM\PYZus{}RULE} \PY{n+nf}{lpm\PYZus{}lookup}\PY{p}{(}\PY{n}{lpm\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k}{struct} \PY{n}{in\PYZus{}addr} \PY{o}{*} \PY{n}{key}\PY{p}{)}\PY{p}{;}
\end{Verbatim}

% LPM IPV6 =================================================================================
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{lpm6\PYZus{}root} \PY{o}{*} \PY{n+nf}{lpm6\PYZus{}init}\PY{p}{(}\PY{n}{\PYZus{}LPM\PYZus{}RULE} \PY{n}{default\PYZus{}rule}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{\PYZus{}Bool} \PY{n+nf}{lpm6\PYZus{}add}\PY{p}{(}\PY{n}{lpm6\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k}{struct} \PY{n}{in6\PYZus{}addr} \PY{o}{*} \PY{n}{prefix}\PY{p}{,} \PY{k+kt}{uint8\PYZus{}t} \PY{n}{prefix\PYZus{}len}\PY{p}{,} \PY{n}{\PYZus{}LPM\PYZus{}RULE} \PY{n}{rule}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{lpm6\PYZus{}update}\PY{p}{(}\PY{n}{lpm6\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k}{struct} \PY{n}{in6\PYZus{}addr} \PY{o}{*} \PY{n}{prefix}\PY{p}{,} \PY{k+kt}{uint8\PYZus{}t} \PY{n}{prefix\PYZus{}len}\PY{p}{,} \PY{n}{\PYZus{}LPM\PYZus{}RULE} \PY{n}{rule}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{lpm6\PYZus{}remove}\PY{p}{(}\PY{n}{lpm6\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k}{struct} \PY{n}{in6\PYZus{}addr} \PY{o}{*} \PY{n}{prefix}\PY{p}{,} \PY{k+kt}{uint8\PYZus{}t} \PY{n}{prefix\PYZus{}len}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{lpm6\PYZus{}destroy}\PY{p}{(}\PY{n}{lpm6\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{)}\PY{p}{;}
\PY{n}{\PYZus{}LPM\PYZus{}RULE} \PY{n+nf}{lpm6\PYZus{}lookup}\PY{p}{(}\PY{n}{lpm6\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k}{struct} \PY{n}{in6\PYZus{}addr} \PY{o}{*} \PY{n}{key}\PY{p}{)}\PY{p}{;}
\end{Verbatim}

Proměnné datových typů \texttt{lpm\_root} a \text{lpm6\_root} reprezentují právě jeden kořen
všech datových struktur. Tím je možné odlišit několik routovací tabulek.


\section{Hledání podřetězců}
Pro hledání podřetězců jsou implementovány následující funkce.

%PM API =================================================================================
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pm\PYZus{}root} \PY{o}{*} \PY{n+nf}{pm\PYZus{}init}\PY{p}{(}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{\PYZus{}Bool} \PY{n+nf}{pm\PYZus{}match}\PY{p}{(}\PY{n}{pm\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k+kt}{char} \PY{o}{*} \PY{n}{input}\PY{p}{,} \PY{k+kt}{unsigned} \PY{n}{length}\PY{p}{,} \PY{n}{pm\PYZus{}result} \PY{o}{*} \PY{n}{result}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{\PYZus{}Bool} \PY{n+nf}{pm\PYZus{}match\PYZus{}next}\PY{p}{(}\PY{n}{pm\PYZus{}result} \PY{o}{*} \PY{n}{result}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{\PYZus{}Bool} \PY{n+nf}{pm\PYZus{}add}\PY{p}{(}\PY{n}{pm\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{n}{pm\PYZus{}keyword} \PY{n}{keywords}\PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{k+kt}{unsigned} \PY{n}{size}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{pm\PYZus{}destroy}\PY{p}{(}\PY{n}{pm\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{\PYZus{}Bool} \PY{n+nf}{pm\PYZus{}remove}\PY{p}{(}\PY{n}{pm\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k+kt}{char} \PY{o}{*} \PY{n}{text}\PY{p}{,} \PY{k+kt}{unsigned} \PY{n}{length}\PY{p}{)}\PY{p}{;}
\end{Verbatim}

Proměnné datového typ \texttt{pm\_root} a reprezentují právě jeden kořen konečného automatu a
díky tomu je možné uchovávat několik odlišných strktur sloužících každá pro jiné účely.

Hledání podřetězců \texttt{pm\_match} skončí svůj průchod konečný automatem v momentě nálezu první shody
s libovolným podřetězcem zadaným při volání \texttt{pm\_add}. Vpřípadě, že není nalezena žádná shoda
se vstupními podřetězci je vrácen výsledek \texttt{false}.

Čtvrtým parametrem funkce \texttt{pm\_match} může být \texttt{NULL} nebo odkaz na datovou strukturu
\texttt{pm\_result}. V případě \texttt{NULL} argumentu již nelze procházet textem a hledat další shody.
Pokud je zadán odkaz na existující strukturu \texttt{pm\_result} je možné procházet celým textem a ukládat
všechny nalezené shody s podřetězci. Jednotlivé položky struktury \texttt{pm\_result} jsou.

% PM_RESULT =================================================================================
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{typedef} \PY{k}{struct}
\PY{p}{\PYZob{}}
	\PY{n}{PM\PYZus{}RULE} \PY{o}{*} \PY{n}{rule}\PY{p}{;}
	\PY{k+kt}{unsigned} \PY{n}{size}\PY{p}{;}
	\PY{k+kt}{unsigned} \PY{n}{count}\PY{p}{;}
	\PY{k+kt}{unsigned} \PY{n}{position}\PY{p}{;}
	\PY{k+kt}{char} \PY{o}{*} \PY{n}{input}\PY{p}{;}
	\PY{k+kt}{unsigned} \PY{n}{length}\PY{p}{;}
	\PY{n}{\PYZus{}ac\PYZus{}state} \PY{o}{*} \PY{n}{state}\PY{p}{;}
\PY{p}{\PYZcb{}} \PY{n}{pm\PYZus{}result}\PY{p}{;}
\end{Verbatim}

Pro použití programátorem jsou určeny pouze položky

\begin{itemize}
	\item{count - počet nalezených pravidel}
	\item{position - pozice v textu, na které došlo k první shodě}
	\item{rule - pole s uloženými čísly vyhovujících pravidel}
\end{itemize}

Pro uložení výsledků procházení textu je možné používat různé proměnné typu \texttt{pm\_result}
a je jen na programátory konkrétní aplikace jaký postup zvolí.
V knihovně \texttt{pm} jsou implementovány funkce pro vytvoření a zničení této struktury.

% PM_RESULTAPI =================================================================================
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pm\PYZus{}result} \PY{o}{*} \PY{n+nf}{pm\PYZus{}result\PYZus{}init}\PY{p}{(}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{pm\PYZus{}result\PYZus{}destroy}\PY{p}{(}\PY{n}{pm\PYZus{}result} \PY{o}{*} \PY{n}{result}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


Pro vkládání podřetězců je vytvořena vlastní datová struktura, a pole těchto struktur je předáváno do funkce
\texttt{pm\_add}. Důvodem pro tuto implementaci namísto přidávání jednotlivých podřetězců samostatně
je relativně časově náročné procházení stavového automatu a generování tzv. failure přechodů,
které je nutné provést po každé změně datové struktury.

% PM_KEYWORD =================================================================================
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{typedef} \PY{k}{struct}
\PY{p}{\PYZob{}}
	\PY{k+kt}{char} \PY{o}{*} \PY{n}{content}\PY{p}{;}
	\PY{k+kt}{unsigned} \PY{n}{length}\PY{p}{;}
	\PY{n}{PM\PYZus{}RULE} \PY{n}{rule}\PY{p}{;}
\PY{p}{\PYZcb{}} \PY{n}{pm\PYZus{}keyword}\PY{p}{;}
\end{Verbatim}

\section{Regulární výrazy}
Knihovna \texttt{regex} implementující regulární výrazy nabízí dvě možnosti pro procházení
vstupních dat a to deterministický \texttt{dfa} a nedeterministický konečný automat \texttt{nfa}.
Z toho důvodu jsou odlišeny všechny funkce dle typu konečného automatu, který je použit.
Oproti hledání nejdelšího shodného prefixu \ref{} nejsou tyto implementace od sebe odlišeny
různými soubory neboť deterministické automaty vycházejí z nedeterministický a pouze používají
determinizaci.

Pro nedeterministické konečné automaty to jsou následující funkce.

% REGEXNFA =================================================================================
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{regex\PYZus{}nfa} \PY{o}{*} \PY{n+nf}{regex\PYZus{}construct\PYZus{}nfa}\PY{p}{(}\PY{n}{regex\PYZus{}pattern} \PY{n}{patterns}\PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{k+kt}{unsigned} \PY{n}{count}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{int} \PY{n+nf}{regex\PYZus{}match\PYZus{}nfa}\PY{p}{(}\PY{n}{regex\PYZus{}nfa} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k+kt}{char} \PY{o}{*} \PY{n}{input}\PY{p}{,} \PY{k+kt}{unsigned} \PY{n}{length}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{regex\PYZus{}destroy\PYZus{}nfa}\PY{p}{(}\PY{n}{regex\PYZus{}nfa} \PY{o}{*} \PY{n}{root}\PY{p}{)}\PY{p}{;}
\end{Verbatim}

Pro deterministické konečné automaty jsou to tyto funkce.
% REGEXDFA =================================================================================
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{regex\PYZus{}dfa} \PY{o}{*} \PY{n+nf}{regex\PYZus{}construct\PYZus{}dfa}\PY{p}{(}\PY{n}{regex\PYZus{}pattern} \PY{n}{patterns}\PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{k+kt}{unsigned} \PY{n}{count}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{int} \PY{n+nf}{regex\PYZus{}match\PYZus{}dfa}\PY{p}{(}\PY{n}{regex\PYZus{}dfa} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{k+kt}{char} \PY{o}{*} \PY{n}{input}\PY{p}{,} \PY{k+kt}{unsigned} \PY{n}{length}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{regex\PYZus{}destroy\PYZus{}dfa}\PY{p}{(}\PY{n}{regex\PYZus{}dfa} \PY{o}{*} \PY{n}{root}\PY{p}{)}\PY{p}{;}
\end{Verbatim}

Pro vytvoření regulárních výrazů je podobně jako u hledání podřetězců \ref{}
použita pomocná struktura \texttt{regex\_pattern}, která je předávána do funkcí \texttt{regex\_[nfa|dfa]\_construct}.
Výsledný konečný automat, ať už deterministický nebo nedeterministický je výsledek spojení jednotlivých
konečných automatů pro každý regulární výraz. Tím je umožněna detekce shody několika
regulární výrazů v jednom průchodu vstupními daty i s přesnou identifikací jaký regulární
výraz se shoduje se vstupními daty. To je také jedním z důvodů proč nejsou použity regulární výrazy ze standardní
knihovny jazyka C.
Další důvody pro vlastní implementaci regulární výrazů je možnost zvolit nejvhodnější algoritmus pro danou operaci.
Mějme na paměti že determinizací může dojít až k exponenciální nárustu stavů konečného automatu, což může problém
zvláště při použití specializovaných HW implementací, kde je možno narazit na paměťové limity.
Dalším důvodem je převod implementace do akcelerovaného hardware.

%REGEX PATTERN =================================================================================
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{typedef} \PY{k}{struct}
\PY{p}{\PYZob{}}
	\PY{k+kt}{unsigned} \PY{n}{length}\PY{p}{;}
	\PY{k+kt}{unsigned} \PY{k+kt}{char} \PY{n}{id}\PY{p}{;}
	\PY{k+kt}{char} \PY{o}{*} \PY{n}{input}\PY{p}{;}
\PY{p}{\PYZcb{}} \PY{n}{regex\PYZus{}pattern}\PY{p}{;}
\end{Verbatim}

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=.25]{fig/header-dependencies.pdf}
	\caption{Diagram závislostí hlavičkových souborů}
\end{figure}\label{fig:header-dependecies}

hlavičkové soubory jsou rozděleny na veřejné a privátní rozhraní, kde privátní rozhraní je používáno pouze uvnitř knihovny. Hierarchickou strukturu je možné vidět na obrázku \ref{fig:header-dependecies}.

Jako výchozí hlavičkový soubor je použit types.h, který obsahuje definice datových struktur pro všechny algoritmy v podknihovně, které musí být viditelné i z veřejného rozhraní. Dalším souborem je types-precompiled.h, který je generován z types.h při překladu když se vybírá používaný algoritmus. common.h je hlavičkový soubor společný pro všechny algoritmy v podknihovně a algortihm.h pak obsahuje deklarace právě pro jeden konkrétní algoritmus.
sublib.h je pak hlavičkový soubor, který tvoří veřejné rozhraní ke knihovním funkcím.

\section{Použití knihovny}
Celou knihovnu je možné sestavit příkazem \texttt{make all} v hlavním adresáři knihovny.
Při tomto příkazu bude celá knihovna sestavena s definovaným NDEBUG, což má za následek vypuštění všech
volání funkce assert, která slouží pro ověřovaní správné funkčnosti.

Dalšími cíly pro program \texttt{make} jsou

\begin{itemize}
	\item{\texttt{test} - spustí automatické testování všech částí knihovny}
	\item{\texttt{bech} - spustí benchmarky všech částí knihovny}
	\item{\texttt{clean} - smaže všechny soubory vytvořené překladem}
\end{itemize}

\section{Rošíření knihovny}

Pro rozšíření knihovny je nutné přidat knihovnu implementující danou operaci
do adresáře \texttt{lib/src} a upravit příslušný soubor \texttt{Makefile} v daném adresáři.
Dále je vhodné vytvořit testovací program a sadu testů, kterou je možné automatizovaně spouštět a vyhodnocovat.
Tyto soubory pak umístit do adresáře \texttt{lib/test/<operace>}.
Další vhodnou součástí knihovny operace je benchmark pro vyhodnocení rychlosti/paměťové náročnosti jednotlivých
implementací dané operace.

\subsection{Packer header extraction}
V knihovně je již navrženo API pro operaci extrakci informací z hlaviček paketů.

\texttt{pc\_set} je struktura typu union, kde jsou všechny položky uloženy na stejném paměťovém místě
a jejich interpretace je odvozená dle typu položky, ke které je přistoupeno.

\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{typedef} \PY{k}{union}
\PY{p}{\PYZob{}}
	\PY{k+kt}{uint32\PYZus{}t} \PY{n}{number}\PY{p}{;}
	\PY{k+kt}{uint16\PYZus{}t} \PY{n}{number16}\PY{p}{;}
	\PY{k+kt}{char} \PY{n}{character}\PY{p}{;}
	\PY{n}{in\PYZus{}addr} \PY{n}{addr}\PY{p}{;}
\PY{p}{\PYZcb{}} \PY{n}{phe\PYZus{}item}\PY{p}{;}

\PY{k}{typedef} \PY{k}{union}
\PY{p}{\PYZob{}}
	\PY{k+kt}{uint32\PYZus{}t} \PY{n}{number}\PY{p}{;}
	\PY{k+kt}{uint16\PYZus{}t} \PY{n}{number16}\PY{p}{;}
	\PY{k+kt}{char} \PY{n}{character}\PY{p}{;}
	\PY{n}{in6\PYZus{}addr} \PY{n}{addr}\PY{p}{;}
\PY{p}{\PYZcb{}} \PY{n}{phe6\PYZus{}item}\PY{p}{;}

\PY{k+kt}{\PYZus{}Bool} \PY{n+nf}{phe\PYZus{}get}\PY{p}{(}\PY{k+kt}{char} \PY{o}{*} \PY{n}{input}\PY{p}{,} \PY{n}{phe\PYZus{}item} \PY{o}{*} \PY{n}{items}\PY{p}{,} \PY{p}{.}\PY{p}{.}\PY{p}{.}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{\PYZus{}Bool} \PY{n+nf}{phe6\PYZus{}get}\PY{p}{(}\PY{k+kt}{char} \PY{o}{*} \PY{n}{input}\PY{p}{,} \PY{n}{phe6\PYZus{}item} \PY{o}{*} \PY{n}{items}\PY{p}{,} \PY{p}{.}\PY{p}{.}\PY{p}{.}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


\subsection{Packer clasification}
V knihovně je již navrženo API pro operaci klasifikace paketů.

\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{typedef} \PY{k}{struct}
\PY{p}{\PYZob{}}
	\PY{k+kt}{unsigned} \PY{n}{rule}\PY{p}{;}
	\PY{k}{struct} \PY{n}{in\PYZus{}addr} \PY{n}{dst}\PY{p}{;}
	\PY{k}{struct} \PY{n}{in\PYZus{}addr} \PY{n}{src}\PY{p}{;}
	\PY{k+kt}{\PYZus{}Bool} \PY{n}{protocol}\PY{p}{;}
	\PY{k+kt}{short} \PY{n}{port}\PY{p}{;}
\PY{p}{\PYZcb{}} \PY{n}{pc\PYZus{}set}\PY{p}{;}

\PY{k}{typedef} \PY{k+kt}{void} \PY{n}{pc\PYZus{}root}\PY{p}{;}

\PY{n}{pc\PYZus{}root} \PY{o}{*} \PY{n+nf}{pc\PYZus{}init}\PY{p}{(}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{pc\PYZus{}destroy}\PY{p}{(}\PY{n}{pc\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{\PYZus{}Bool} \PY{n+nf}{pc\PYZus{}add}\PY{p}{(}\PY{n}{pc\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{n}{pc\PYZus{}set} \PY{n}{set}\PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{k+kt}{unsigned} \PY{n}{count}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{\PYZus{}Bool} \PY{n+nf}{pc\PYZus{}update}\PY{p}{(}\PY{n}{pc\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{n}{pc\PYZus{}set} \PY{n}{old}\PY{p}{,} \PY{n}{pc\PYZus{}set} \PY{n}{new}\PY{p}{)}\PY{p}{;}
\PY{k+kt}{void} \PY{n+nf}{pc\PYZus{}remove}\PY{p}{(}\PY{n}{pc\PYZus{}root} \PY{o}{*} \PY{n}{root}\PY{p}{,} \PY{n}{pc\PYZus{}set} \PY{n}{set}\PY{p}{)}\PY{p}{;}
\end{Verbatim}



\chapter{Výsledky}\label{chapter:results}
Tato kapitula shrnuje a vizualizuje dosažené výsledky při implementaci jednotlivých knihoven.
Benchmarky pro architekturu Intel proběhly na operačním systému Archlinux \footnote{https://www.archlinux.org/} s procesorem Intel(R) Core(TM) i3-2310M CPU @ 2.10GHz.

\section{Hledání nejdelšího shodného prefixu}
U algoritmu bspl je doba vyhledání prefixu velice závislá na velikosti hešovací tabulky a proto je vhodné odhadnout počet záznamů tabulky alespoň řádově a dle toho pak nastavit velikost konstantu {\tt \_HTABLE\_SIZE} v souboru bspl.h na hodnotu, která alespoň řádově odpovídá předpodkládané velikosti hešovací tabulky.

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=1]{fig/lpm-ipv4.pdf}
	\caption{Benchmark pro IPv4}
\end{figure}\label{fig:lpm-ipv4}

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=1]{fig/lpm-ipv6.pdf}
	\caption{Benchmark pro IPv6}
\end{figure}\label{fig:lpm-ipv4}

\chapter{Závěr}\label{chapter:conclusion}
Cílem této práce bylo popsat a navrhnout aplikační programové rozhraní časově kritické operace v oblasti počítačových sítí,
konkrétně vyhledání nejdelšího shodného prefixu za využití algoritmů Binary search on prefix length
a TreeBitmap. Operace používané na směrovačích pro zjištění jakou cestou směrovat přicházející pakety.
Dalšími operacemi jsou hledání řetězců a hledání regulárních výrazů v paketech a jejich datech.
Pro operaci hledání řetězců je to konkrétně algoritmus Aho-Corasick \cite{aho} umožňují v
při jednom průchodu vstupními daty vyhodnit zda se v datech nacházejí specifikovaná klíčová slova
a poté hledání regulárních výrazů. Obě zmíněné operace jsou používané v paketových filtrech,
které tvoří jádro systémů pro detekci útoků (IDS) a prevenci útoků (IPS). Do skupiny těchto
systémů patří firewally jak softwarové tak hardwarové. Mezi další operace operace pak patří
analýza a extrakce hlaviček paketů a obecná klasifikace paketů.

Dále je to pak implementace operací hledání nejdelšího shodného prefixu, hledání řetězců
a hledání regulárních výrazů. Při implementaci bylo dosaženo rychlosti zpracování N paketů za sekundu
při velikosti $100000$ záznamů routovací tabulky pro IP adresy verze 4 a N paketů/sekunda při velikosti
routovací tabulky $10000$ pro IP adresy verze 6. Pro operaci hledání podřetězců bylo
do dosaženo rychlosti zpracování N paketů za sekundu v závislosti na počtu shodných písmen
při lineární náročnosti v závislosti na velikost dat v paketech. Experimentování bylo prováděno
na vzorku dat odchycených ze standardního síťového provozu jednoho osobního počítače. Jako vzorek
testovaných klíčových slov bylo využito klíčových definovaných pro HTTP\footnote{Hyper-text transfer protocol}.
Pří experimentování s regulárními výrazy byly jako vstupní data použita stejná data jako pro hledání řetězců,
ale jako regulární výraz byly použity matchování URL\footnote{Uniform resource locator} adres.

Část této práce pojednávající o hledání nejdelšího shodného prefixu vychází z publikací
\cite{tbm}, \cite{bspl}, a dalších. Hledání řetězců vychází z \cite{aho} a hledání regilárních výrazů
 z \cite{}.

\section{Další rozšíření}
Jako kroky navazující na tuto práci je možné implementovat zbývající operace, které implemetnovány nebyly.
Těmito operacemi je klasifikace paketů a analýza a extrakce hlaviček paketů.

\subsection{Optimalizace}
U implementace \texttt{Binary search on prefix length} je možné rozdělit strukturu \texttt{\_bspl\_node}
na dvě a to jednu pro každou verzi IP protokolu. Tím se dosáhne snížení paměťové náročnosti
pro implementaci IPv4 o 12B pro každý uzel. To s sebou nese nutnost upravit všechny funkce pracující
s položkou \texttt{prefix} v rámci této struktury.

Další optimalizací je přepsání leaf-pushing do iterativní průchod za použití Morrisova algoritmu \cite{morris},
který umožňuje průchod stromovou strukturou bez použití rekurze a zásobníku.

Dále je možné spojit položky \texttt{type} a \texttt{prefix\_length} struktury \texttt{\_bspl\_node}
do jednoho byte. To je možné z důvodu rozsahu \texttt{prefix\_length} $1-128$ a pouze dvou typů uzlu,
což je možné reprezentovat jedním bytem.

\subsection{Stress-testing}
Ze specifikace požadavků na implementaci knihovny v nízkoúrovňovém jazyce C je zřejmé,
že knihovna bude používána i na vestavěných systémech disponujících omezenou pamětí a z toho
důvodu by jedním z dalších kroků mohlo být formální testování s nedostatkem paměti.
To by mohlo dát rozsahem na celou další práci. Je nutné ověřit, že knihovna bude
reagovat správným způsob a nezpůsobí pád systému v rámci kterého je spouštěna.
